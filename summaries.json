{
  "tiktok-community-guidelines": {
    "policy_name": "Tiktok Community Guidelines",
    "initial_summary": "## TikTok Competitor Community Guidelines Summary\n\nThis document outlines a comprehensive set of community guidelines for a TikTok-like platform, effective May 17, 2024.  Key areas covered include:\n\n* **Content Moderation:**  The platform employs a three-pronged approach: removing violating content, restricting age-inappropriate content (for users under 18), and making ineligible for recommendation (For You feed) content that doesn't meet platform standards.\n\n* **Prohibited Content:**  A wide range of prohibited content is detailed, encompassing: violence, hate speech, sexual abuse, harassment, self-harm, dangerous activities, misinformation, scams, regulated goods (alcohol, firearms, etc.), and violations of privacy and security.  Specific examples are provided within each category, though the document notes that these are not exhaustive.\n\n* **Community Empowerment:** The platform provides users with tools and resources to manage their experience, including safety settings, filtering options, and reporting mechanisms.\n\n* **Enforcement:** While the specifics of enforcement aren't detailed, the document implies a combination of automated and human moderation to address policy violations.\n\nThe guidelines aim to create a safe and welcoming environment while balancing creative expression and the prevention of harm.  The full guidelines are categorized for easier navigation, with additional information and examples available for each section.\n",
    "last_update_summary": "Here's a concise summary of the competitor's (TikTok's) new Community Guidelines policy for a Product Manager:\n\n### Competitor Policy Update: TikTok Community Guidelines (Effective May 17, 2024)\n\nThis diff introduces TikTok's updated Community Guidelines, effective May 17, 2024. The document outlines a comprehensive framework for content moderation, emphasizing user safety, well-being, and platform integrity.\n\n**Key Highlights & Changes:**\n\n*   **Holistic Content Moderation Strategy:** The policy explicitly details a multi-layered approach beyond simple removal, including:\n    *   **Remove:** Content violating rules (public or private).\n    *   **Restrict:** Content not suitable for youth (18+ only).\n    *   **Make Ineligible for FYF:** Content not meeting recommendation standards (a distinct category from outright violations).\n    *   **Empower:** Users with information, tools (labels, opt-in screens, warnings), and safety resources.\n*   **Structured & Detailed Categories:** The guidelines are organized into clear, actionable sections, with bolded rules and \"More information\" links for definitions and examples.\n*   **Emphasis on Specific Harms:** Dedicated sections and sub-categories highlight increased focus on:\n    *   **Youth Safety & Well-Being:** A top-level section alongside general safety.\n    *   **Separation of Abuse Categories:** Distinct sections for \"Youth Sexual and Physical Abuse\" and \"Adult Sexual and Physical Abuse.\"\n    *   **Emerging Harm Types:** Specific callouts for \"Disordered Eating and Body Image\" and \"Dangerous Activity and Challenges.\"\n    *   **AI-Generated Content (AIGC):** A new sub-category under \"Integrity and Authenticity\" for \"Edited Media and AI-Generated Content (AIGC),\" indicating a proactive stance on new media forms.\n    *   **Unoriginal Content:** A specific category addresses content that lacks originality.\n    *   **Frauds and Scams:** Included under Regulated Goods and Commercial Activities.\n*   **Clear FYF Eligibility Standards:** A dedicated top-level section (\"For You feed Eligibility Standards\") signifies clear distinction between content violations and content unsuitable for broad recommendation.\n*   **Transparency in Enforcement:** A dedicated \"Enforcement\" section outlines \"Public Interest Exceptions,\" \"Detection and Reporting\" mechanisms, and \"Notice and Appeals\" processes, indicating a commitment to due process.\n*   **Application to Features:** Guidelines extend to specific platform features like TikTok LIVE, Search, External Links, Comments/Direct Messages, and Monetization.\n\n**Implication for Product:** This comprehensive policy demonstrates a strong focus on granular content moderation, user-empowerment tools, and addressing emerging risks like AIGC. It also clearly separates content that is outright prohibited from content that is merely restricted or ineligible for recommendation, which could influence product features related to content filtering, age-gating, and algorithmic distribution.",
    "last_updated": "2025-07-22T00:27:54.057444Z"
  },
  "tiktok-live-moderation": {
    "policy_name": "Tiktok Live Moderation",
    "initial_summary": "# TikTok LIVE Moderation Policy Summary\n\nThis document details TikTok's approach to content moderation during LIVE streams.  Key features include:\n\n* **Creator Controls:** Creators can add moderators, control audience age (18+), filter comments, block keywords, mute, and block viewers directly from the LIVE settings or chat.  This applies to both mobile app and web browser access (via LIVE Studio or OBS Studio for broadcasting; not required for moderation).\n\n* **Moderator Permissions:** Moderators, granted permission by the creator, can mute, block viewers, and report comments violating Community Guidelines.  The level of control a moderator has is determined by the creator.\n\n* **User Actions:**  Viewers can be reported, muted (temporarily), or blocked (preventing future LIVE viewership and other interactions with the creator).  Notifications are sent to muted/blocked users.\n\n* **Accessibility:** Moderation tools are accessible both within the LIVE settings and directly from the LIVE chat interface on both the mobile app and web browser.\n",
    "last_update_summary": "This document outlines TikTok's comprehensive policy for moderating LIVE streams, detailing the tools available to both creators and their assigned moderators.\n\n### TikTok LIVE Moderation Policy Overview (2025-07-22)\n\nThis new policy page defines the roles and functionalities for managing viewer behavior and comments during TikTok LIVE streams.\n\n**Key Moderation Capabilities:**\n\n*   **For Creators & Moderators:**\n    *   **Report:** Flag viewer comments for violations.\n    *   **Mute:** Temporarily prevent a viewer from commenting. Viewers are notified and remain muted until the duration expires or they are unmuted.\n    *   **Block:** Permanently prevent a viewer from watching the LIVE and interacting with the creator's content (posts, profile, DMs). Viewers are notified and cannot watch the current or future LIVEs of that creator unless unblocked.\n    *   **Comment Settings:** Filter comments, block specific keywords and their variations.\n*   **For Creators Only:**\n    *   **Moderator Management:** Add or remove moderators before or during a LIVE.\n    *   **Audience Controls:** Restrict the LIVE to viewers 18 years or older.\n*   **Moderator Permissions:** Creators grant specific permissions to moderators, allowing them to manage comment settings and blocked/muted account lists.\n\n**Access & Workflow:**\n\n*   **TikTok App:** Moderation tools are accessible from LIVE settings (before starting) and directly from the LIVE chat (during the stream).\n*   **Web Browser:** Tools are available via the LIVE chat panel's settings or by clicking on a viewer's profile/comment.\n\n**Key Takeaway for Product:**\n\nTikTok emphasizes granular control for creators and empowers designated moderators with significant capabilities (muting, blocking, reporting, comment management). The policy clearly defines the immediate and communicated impact of moderation actions on viewers (notifications for mute/block, comprehensive blocking). This level of detail and control could inform our own LIVE moderation feature development and policy.",
    "last_updated": "2025-07-22T00:28:01.807079Z"
  },
  "tiktok-shop-prohibited-products": {
    "policy_name": "Tiktok Shop Prohibited Products",
    "initial_summary": "## Competitor Policy Summary: TikTok Shop Academy (US)\n\nThis document appears to be incomplete or broken.  The provided text only shows a heading related to boosting sales on TikTok Shop Academy and a JavaScript error message.  **No actual policy information is present.**  Therefore, no meaningful summary of their policy can be provided.  Further investigation is needed to obtain the actual policy document.\n",
    "last_update_summary": "**Summary for Product Manager: Competitor Policy Page Analysis**\n\nThis diff indicates the creation of a *new file* for a competitor's \"prohibited products\" policy page (dated 2025-07-20).\n\n**Key Changes:**\n\n*   **New Page Created:** A new policy page `tiktok-shop-prohibited-products` has been added.\n*   **Placeholder Content:** The page's content is currently a generic \"JavaScript not enabled\" message, suggesting it's an unpopulated placeholder or a technical error page, rather than an active policy.\n*   **No Policy Content Detected:** There are no actual policy rules or guidelines present in this version of the page.\n\n**Impact:**\n\nCurrently, there is no substantive policy information to analyze. This appears to be a technical setup or placeholder for a future policy page. We should monitor this URL for updates to identify actual policy content when it becomes available.",
    "last_updated": "2025-07-20T23:50:56.579760Z"
  },
  "whatnot-blocking-a-user": {
    "policy_name": "Whatnot Blocking A User",
    "initial_summary": "## Whatnot User Blocking Policy Summary\n\nThis document details Whatnot's user blocking functionality.  Users can block others to prevent:\n\n* Following\n* Direct messaging\n* Profile viewing\n* Livestream interaction (bookmarking, joining, chatting)\n* Future purchases from listings\n\nExisting orders are unaffected by blocking.  Blocking is currently permanent.  There's no list of blocked users.  Being removed from a livestream is different from being blocked by a user.  Users can report violations of Community Guidelines separately.\n",
    "last_update_summary": "## Whatnot: Blocking a User Policy Analysis\n\n**Summary for Product Manager:**\n\nThis new policy page outlines Whatnot's user blocking feature, detailing its functionality and user experience.\n\n**Key Functionality & Impact:**\n\n*   **Comprehensive Blocking:** Users can block others to prevent them from:\n    *   Following them.\n    *   Direct messaging within the app.\n    *   Viewing their profile.\n    *   Bookmarking, joining, or chatting in their livestreams.\n    *   Making *future* purchases from their marketplace listings (existing orders are honored).\n*   **Distinction from Bans:** The policy clarifies that blocking is different from being temporarily removed from a livestream by a host or mod.\n*   **User Action:** Blocking is done via the three-dot menu on a user's profile.\n*   **Unblocking Capability:** Users *can* unblock someone by searching for their profile and selecting \"Unblock.\"\n*   **Current Limitation:** There is currently no central list for users to view all the accounts they have blocked. The policy notes that without such a list, blocking is \"permanent\" in the sense that managing multiple blocks can be difficult, not that the block itself cannot be undone.\n\n**Key Changes based on this Diff:**\n\nThis diff represents the **introduction of a *new* policy page** detailing the \"Blocking a User\" feature. There are no incremental changes to an existing document. The significance is that Whatnot has now formally documented and published its user blocking capabilities and how they function.",
    "last_updated": "2025-07-22T00:28:08.475266Z"
  },
  "whatnot-buyer-protection": {
    "policy_name": "Whatnot Buyer Protection",
    "initial_summary": "# Whatnot Buyer Protection Policy Summary\n\n**Key Points:**\n\n* **Refund Eligibility:** Whatnot offers buyer protection for incomplete/incorrect items, items not as described/inauthentic, and packages not received.  Refunds are generally granted within 30 days of purchase or 14 days of delivery (7 days for certain categories like coins, sneakers, luxury goods; 2 days for plants).  Whatnot may require item return in original condition.  German buyers pay return shipping.\n\n* **Refund Exclusions:**  Consumables (opened/consumed items, breaks except for missing/damaged items), tips, refused deliveries, uncollected packages, unpaid customs fees, exchange rate losses, chargebacks, digital content, off-platform transactions, and instances of suspected fraud are excluded.  Returning the wrong item also voids a refund.\n\n* **Time Limits & Exceptions:**  Specific shorter deadlines apply for certain high-value categories and counterfeit claims (30 days from receipt). Extensions may be granted for international orders, pre-orders, custom orders, and due to natural disasters.  \"Delivered\" but not received items require contact within 14 days.\n\n* **EU/UK Right of Withdrawal:** EU/UK buyers have a 14-day right of withdrawal, requiring item return within 14 days of cancellation.  Buyers are responsible for return shipping costs. This right doesn't apply to breaks, surprise products, or certain unsuitable goods (hygiene, mixed, sealed software/media, customized items, perishable goods).\n\n\n* **High-Value Loss Reimbursement:** A separate policy exists for high-value card losses in breaks, potentially reimbursing market value.\n\n",
    "last_update_summary": "This document introduces Whatnot's comprehensive **Buyer Protection Policy**, effective May 16, 2025. It outlines the conditions under which buyers are eligible for refunds for purchases made on the platform.\n\n**Key Components & Changes Introduced:**\n\n*   **Covered Issues:** Buyers are entitled to refunds for `incomplete/incorrect items`, `items not as described or inauthentic` (damaged, expired, defective, counterfeit), and `packages not received` (lost, delayed, misdelivered). A detailed list of covered issues is provided.\n*   **Refund Request Timelines:**\n    *   **General:** Submit requests within the **earlier of 30 days from purchase or 14 days from delivery**.\n    *   **Category-Specific:**\n        *   **7 days from delivery or 30 days from purchase (earlier of):** Coins & Money, Sports Cards, Sneakers & Streetwear, Trading Card Games, Luxury Goods.\n        *   **2 days from delivery or 30 days from purchase (earlier of):** Plants.\n    *   **Counterfeit Claims:** Must be submitted within **30 days of receiving the order**.\n    *   **\"Marked Delivered, Not Received\":** Contact support within **14 days** of delivery scan.\n*   **Return Requirements:** Whatnot may require item returns in the same received condition. Opening products or removing tags may disqualify or reduce refunds. For Germany, return shipping costs will be deducted from the refund.\n*   **Key Exclusions from Protection:** Refunds are **not** provided for:\n    *   Most `consumable products` once opened/consumed (except for missing/damaged items in \"Breaks\").\n    *   `Tips` to sellers.\n    *   `Refusing delivery` or `failing to pick up` packages.\n    *   `Refusal to pay customs fees` or duties paid.\n    *   `Exchange rate fluctuations`.\n    *   `Orders disputed with financial institutions` (chargebacks).\n    *   `Digital Content`.\n    *   `Potential fraud or abuse of policy` (at Whatnot's discretion).\n    *   `Returning an incorrect item`.\n    *   `Off-platform transactions`.\n*   **Special Policies:**\n    *   **High Value Loss Reimbursement:** Specific policy referenced for missing Sports Cards/Trading Cards in \"Breaks\" based on market value.\n    *   **EU/UK Right of Withdrawal:** Consumers from professional sellers have a statutory right to cancel within 14 days of receipt and return items within 14 days of cancellation, subject to specific conditions and exclusions (e.g., no refunds for \"Breaks\" or \"Surprise Products\", unsealed hygiene items, customized goods). Return shipping costs are the buyer's responsibility.\n\nThis policy emphasizes a structured approach to buyer protection with clear timelines, exclusions, and specific handling for various item categories and international regions.",
    "last_updated": "2025-07-22T00:28:19.690967Z"
  },
  "whatnot-enforcement-actions": {
    "policy_name": "Whatnot Enforcement Actions",
    "initial_summary": "## Whatnot's Trust & Safety Policy: Summary for Product Managers\n\nWhatnot's policy enforces Community Guidelines with penalties escalating based on violation severity and account history.  Violations are cumulative, meaning repeated offenses, even minor ones, can lead to a permanent ban.\n\n**Key Actions & Penalties:**\n\n* **Warnings:** For minor infractions, with guidance provided.\n* **Suspensions:** Temporary account access loss (2 or 7 days).\n* **Selling Access Revoked:**  Loss of ability to sell or go live.\n* **Ban:** Permanent account termination for serious or repeated violations.\n* **Discovery Restriction:** Temporary reduced visibility in feeds/recommendations.\n* **Other Penalties:** Loss of access to features like Direct Messages.\n\n**Account Health & Performance:**\n\n* An Account Health dashboard tracks Seller Performance Rates (fulfillment, shipping) and Policy Standing.\n* Poor performance in either area can result in warnings and penalties.\n* Policy Standing has five levels (Excellent, Good, Fair, Poor, Very Poor), reflecting penalty history.\n\n**Violation Expiration:**\n\n* Most violations expire after 180 days, except for bans and offboarding, which are permanent.\n\n**Appeals:**  Users can appeal penalties via email.\n",
    "last_update_summary": "As a Trust & Safety analyst, here is a concise summary of the new policy page for a Product Manager:\n\n### **New Policy: What Actions We Take (2025-07-22)**\n\nThis document introduces a new, detailed policy outlining Whatnot's enforcement actions for Community Guidelines violations, aiming for transparency and a trusted platform.\n\n**Key Changes (as this is a new file):**\n\n*   **Formalized Enforcement Framework:** Establishes a clear, graduated system of penalties for policy violations.\n*   **Tiered Penalties:** Outlines a progression of consequences:\n    *   **Warning:** Guidance on policy.\n    *   **Suspension:** Temporary account access loss (2 or 7 days).\n    *   **Revoke Selling Access:** For sellers.\n    *   **Ban:** Permanent account removal for serious/repeated violations.\n    *   **New \"Discovery Restricted\" Penalty:** Temporarily reduces account visibility in Feeds/Recommendations, allowing users to improve compliance without full suspension. This is a notable addition impacting product discoverability.\n    *   **Other Penalties:** Loss of features (e.g., DMs), ongoing investigation suspensions.\n*   **Cumulative Violations:** Emphasizes that even less severe violations contribute to a user's Trust & Safety record and can lead to eventual bans.\n*   **Account Health Integration:** Introduces \"Policy Standing\" states (Excellent, Good, Fair, Poor, Very Poor) directly linked to the penalty tiers, visible in the Account Health dashboard (Beta).\n*   **Seller Performance Link:** Explicitly states that consistent underperformance in Fulfillment Success Rate or On Time Shipment Rate can lead to warnings and penalties.\n*   **Violation Expiry & Appeals:** Most violations expire after 180 days, with clear instructions for appeals.\n\n**Impact for Product:**\n\nThis policy provides clear guidelines for user behavior and outlines the consequences within the product, particularly the new \"Discovery Restricted\" state which directly impacts user experience and discoverability without a full ban. It also reinforces the value of the Account Health Dashboard for seller self-management.",
    "last_updated": "2025-07-22T00:28:26.761407Z"
  },
  "whatnot-hate-and-harassment": {
    "policy_name": "Whatnot Hate And Harassment",
    "initial_summary": "## Whatnot Hate and Harassment Policy Summary\n\nThis policy prohibits hateful conduct and harassment on the Whatnot platform, including sexual harassment and off-platform abuse that impacts the Whatnot community.  Key prohibited behaviors include:\n\n* **Harassment:**  Repeated unwanted contact, personal attacks, targeted obscene language,  using contact information for non-transactional purposes, and disparaging others (sellers disparaging buyers in streams, for example).  Exceptions may be made for newsworthy events or public figures.\n\n* **Threats & Harmful Wishes:** Wishing harm, making threats (implied or explicit), and exposing someone's sexual orientation or gender identity without consent.\n\n* **Sexual Harassment:** Unwanted sexual advances, objectification, degrading comments about sexual practices, sharing intimate images without consent.\n\n* **Hateful Conduct:** Any behavior promoting violence or hatred based on protected characteristics (race, ethnicity, religion, gender, sexual orientation, etc.). This includes using slurs (unless used self-referentially and with clearly indicated positive intent), supporting hate groups, and displaying hateful symbols (with exceptions for historical context, like pre-1933 artifacts). Specific allowances are made for the Confederate battle flag under very specific historical and non-hateful contexts.\n\n* **Off-Platform Abuse:**  Whatnot may take action against users coordinating harassment or hate off-platform that impacts the Whatnot community, even in rare instances where the off-platform behavior poses a significant threat to the platform.\n\nEnforcement actions against accounts may include removal.  The severity and persistence of the behavior are considered when evaluating violations.\n",
    "last_update_summary": "As a Trust & Safety analyst, here's a summary of the provided competitor policy for a Product Manager:\n\n### Whatnot Hate and Harassment Policy - Summary for Product Manager\n\n**Key Change from Diff:**\nThis diff represents the *introduction* of a new, comprehensive **Hate and Harassment Policy** by Whatnot, dated August 21, 2024. This is not an update to an existing policy, but rather the establishment of formal guidelines on these critical safety topics.\n\n**Policy Overview:**\nWhatnot has established a clear and strict policy prohibiting hateful conduct and harassment to foster a safe and respectful environment. Violations may result in account actions, including removal.\n\n**Key Prohibited Behaviors:**\n\n1.  **Harassment:** Content or patterns of behavior that demean or threaten individuals.\n    *   **Unwanted Conduct & Contact:** Targeting individuals with dedicated accounts, repeated obscene/insulting language, continued contact after being asked to stop, or misuse of contact information.\n    *   **Personal Attacks & Repeated Disparagement:** Attacks based on appearance, hygiene, intellect, personality; targeting with negative doctored content; sellers disparaging buyers/others in streams; or repeated/extended disparagement across multiple streams/DMs (e.g., questioning reliability, \"exposing\" others). *Note: Exceptions for newsworthy events or public figures.*\n    *   **Threats & Harmful Wishes:** Wishing death, disease, or physical harm; implied/hypothetical threats; exposing sexual orientation/gender identity without consent; or glorifying/endorsing traumatic events (self-injury, eating disorders, medical history).\n\n2.  **Sexual Harassment:** Unwanted sexual advances, sexual objectification, or degrading attacks about an individual\u2019s sexual practices.\n    *   **Unwanted Romantic Approaches:** Sexual objectification (comments on body parts, encouraging adult content, asking for sexually suggestive poses).\n    *   **Disparagement:** Based on perceived sexual practices or morality (of person or family member).\n    *   **Image/Audio Misuse:** Sharing or threatening to share intimate images/audio without consent; threats, blackmail, or forced coercion for intimate images.\n\n3.  **Hateful Conduct:** Behavior promoting violence or hatred based on protected characteristics (race, ethnicity, color, caste, national origin, immigration status, religion, sex, gender, gender identity, sexual orientation, disability, serious medical condition, veteran status).\n    *   **General:** Intolerance, hatred, subjugation, sexualizing, demeaning, dehumanizing, or suggesting inferiority against protected groups.\n    *   **Specific Examples:** Mimicking race to mock, encouraging violence/harm, mocking/celebrating/denying hate crimes, racial slurs (with allowance for clearly self-referential/positive use), support for known hate groups/ideologies, harmful stereotypes/theories.\n    *   **Hateful Images/Symbols:** Prohibits symbols from known hate organizations, Nazi propaganda, Swastikas (with specific historical exceptions), grotesque/derogatory Black Americana (e.g., Gollywog dolls, blackface), and live/recorded blackface/yellowface/redface/brownface.\n    *   **Confederate Battle Flag Nuance:** Permitted only if historically accurate miniatures/models, artistic denunciation, or on book/video game covers without hateful context.\n\n4.  **Off-Platform Abuse:**\n    *   **Coordination:** Action may be taken if verifiable evidence exists of off-platform coordination of harassment or hate *to occur on Whatnot* (e.g., encouraging followers to send hateful messages, creating fake accounts for insult/impersonation).\n    *   **Severe Off-Platform Behavior:** In rare instances, action may be taken for verifiable hate/harassment occurring off-platform if it poses a significant threat to the Whatnot community or individuals, considering severity and persistence.\n\nThis policy outlines a comprehensive framework for addressing harmful behaviors, including detailed examples and specific nuances for visual content and off-platform conduct.",
    "last_updated": "2025-07-22T00:28:34.642708Z"
  },
  "whatnot-how-to-report": {
    "policy_name": "Whatnot How To Report",
    "initial_summary": "## Whatnot User Reporting and Investigation Policy Summary\n\n**Key Points:**\n\n* **Reporting Methods:** Users can report suspicious behavior via in-app reporting features during livestreams, in direct messages (DMs), on product listings, or user profiles (Android & Web).  Email reports to trustandsafety@whatnot.com are also accepted.  All reports are anonymous.\n* **Reporting Locations:** Reporting options are available within livestreams (for buyers and sellers), in-live chat, DMs, product listings, and user profiles (Android/Web).\n* **Investigation Process:** Whatnot's Trust & Safety team investigates reports, analyzing data, reviewing livestreams, and potentially temporarily suspending users during investigations. Outcomes are not publicly disclosed.\n* **Proactive Monitoring:**  The Trust & Safety team proactively investigates potential policy violations based on data analysis and community reports, taking action against users exhibiting patterns of abuse.\n\n",
    "last_update_summary": "As a Trust & Safety analyst, here's a concise summary of the competitor's new policy page for a product manager:\n\n---\n\n### **Whatnot: How To Report A User & How We Investigate Policy - Summary for PMs**\n\n**Overview:**\nThis new policy page from Whatnot outlines a comprehensive user reporting system and their internal investigation process, emphasizing user anonymity and proactive safety measures.\n\n**Key Information:**\n\n1.  **Multiple Reporting Channels:** Users can report directly within the platform:\n    *   **During a Livestream:** Via user's username (for buyers, live sellers, or chat participants).\n    *   **In Direct Messages (DMs):** Via the \"More Options\" menu.\n    *   **On a Product Listing:** To report a seller or the listing itself.\n    *   **On User's Profile:** (Android and Web only).\n    *   **Email:** `trustandsafety@whatnot.com` for general reports or when unsure.\n2.  **Anonymity:** All user reports are explicitly stated to be anonymous.\n3.  **Investigation Process:**\n    *   Whatnot's Trust & Safety team investigates reports by reviewing facts, relevant history/data, and livestreams.\n    *   Reported users may face temporary suspension of features (e.g., ability to go live) during an investigation.\n    *   Outcomes of individual investigations are not disclosed due to privacy.\n4.  **Proactive Monitoring:** The Trust & Safety team also initiates investigations proactively based on data analysis and community reports, actively monitoring seller/buyer data for patterns of policy abuse and taking action when evidence is found.\n\n**Key Changes Based on This Diff:**\nThis diff represents the **introduction** of a dedicated, detailed policy page for \"How To Report A User & How We Investigate.\" This signifies Whatnot's formalization and public communication of their user reporting mechanisms and the internal review process, moving towards greater transparency and setting clear expectations for user safety and enforcement.\n\n---",
    "last_updated": "2025-07-22T00:28:40.500535Z"
  },
  "whatnot-moderator-guidelines": {
    "policy_name": "Whatnot Moderator Guidelines",
    "initial_summary": "## Whatnot Moderator Guidelines Summary\n\n**Key Points:**\n\n* **Goal:** Maintain a safe and fun marketplace by empowering moderators to manage livestream chats effectively.  Moderation should be fair and unbiased, prioritizing community safety and a positive user experience.\n\n* **Moderator Responsibilities:**\n    * Remove users only for violations of Community Guidelines or at the seller's request.  Avoid banning users for differing opinions.\n    * Maintain a respectful and engaging chat environment.\n    * Address inappropriate messages promptly, escalating to warnings before bans.\n    * Seek seller feedback.\n\n* **Moderator Privileges:**\n    * Remove users from a specific livestream (not a platform-wide ban).\n    * View muted chat messages.\n\n* **Adding/Removing Moderators:** Sellers can add moderators during or before a livestream via the scheduling section or by selecting the \"Allow to Moderate\" option from a user's chat profile.  Removal is done similarly using the \"Remove Moderator\" option.\n\n* **Underlying Principle:**  Moderation should be proactive and fair, guided by Whatnot's Community Guidelines and a principle of leading by example, not force.\n",
    "last_update_summary": "### Whatnot - New Moderator Guidelines Policy (2025-07-22)\n\n**Summary of Key Changes (New Policy Introduced):**\n\nThis diff indicates the **creation** of a comprehensive \"Moderator Guidelines\" policy for Whatnot. As a `new file`, it establishes the foundational expectations and procedures for livestream moderators, where none were formally documented in this manner before.\n\n**Core Aspects of the New Policy:**\n\n*   **Purpose:** To make Whatnot the \"safest P2P marketplace\" by providing clear guidance for local moderators. The overarching principle is to \"lead by example, not by force,\" ensuring unbiased actions and compliance with Whatnot's Community Guidelines.\n*   **Moderator Expectations:**\n    *   Avoid abuse of power; only remove/report users if actions warrant it or if the seller requests.\n    *   **Do not ban users for mere disagreement or opinions.**\n    *   Maintain an unbiased stance to keep communities safe.\n    *   Primary responsibility in chat is to ensure content standards and address offending users/spam.\n*   **Best Practices Emphasized:**\n    *   Treat all users with respect and without bias.\n    *   Engage with chat and answer user questions.\n    *   Delete inappropriate messages promptly.\n    *   **Crucially, \"Issue a verbal warning first and do not ban users without a valid cause.\"**\n*   **Moderator Privileges:**\n    *   **Remove Users From Show:** Removes a user *only from the current livestream*. This action **does not ban them from Whatnot** or prevent them from joining future streams from the same seller.\n    *   **View Muted Chat Messages:** Allows moderators to see messages that are hidden from regular users due to global settings or the seller's \"Muted Words\" list.\n*   **Management:** Provides clear instructions for sellers on how to add and remove moderators both before and during a livestream.\n\n**Implication for Product Managers:**\n\nThis new policy signals Whatnot's commitment to a structured and responsible approach to user-led moderation. The emphasis on unbiased action, verbal warnings before bans, and the limited scope of the \"Remove from Show\" privilege suggests a focus on fostering community and maintaining a less punitive environment, while still empowering sellers with tools to manage their immediate livestream experience. The ability for mods to view muted messages provides a critical layer for content oversight.",
    "last_updated": "2025-07-22T00:28:51.105342Z"
  },
  "youtube-community-guidelines": {
    "policy_name": "Youtube Community Guidelines",
    "initial_summary": "## YouTube's Trust & Safety Policy Summary:\n\nThis document outlines YouTube's approach to content moderation, creator support, and combating abuse.  Key points include:\n\n* **Content Moderation:**  YouTube uses automated systems and human reporting to identify and remove content violating Community Guidelines and Advertiser-Friendly Content Guidelines. Exceptions are made for content with clear educational, documentary, scientific, or artistic value (EDSA).\n\n* **Creator Support:**  The YouTube Partner Program (YPP) offers revenue sharing to eligible creators who meet stricter content standards.  Creators have tools to manage comments and their channel's community interactions.  YouTube provides resources to support creator privacy and safety.\n\n* **Combating Abuse:** YouTube actively works to remove content promoting violent extremism or criminal organizations, collaborating with government entities and organizations like the GIFCT.\n\n* **Appeals Process:** Creators can appeal decisions regarding content removal or YPP suspension.\n\n\n",
    "last_update_summary": "As a Trust & Safety analyst, here's a summary of the new policy page for a product manager:\n\n---\n\n## Competitor Policy Page Analysis: YouTube Community Guidelines (New Page)\n\nThis diff indicates the **introduction of a new, comprehensive policy page** titled \"Our Policies\" on YouTube's \"How YouTube Works\" microsite. This page serves as a central hub outlining their approach to content moderation, creator support, and industry partnerships.\n\n### Key Aspects Introduced by This New Policy Page:\n\n*   **Core Philosophy:** Reinforces YouTube's mission of openness and free expression while emphasizing the need for a \"responsible business\" that viewers, creators, and advertisers can trust.\n*   **Policy Mechanisms Explained:**\n    *   **Community Guidelines:** Focus on content integrity and user safety, with content flagged by a mix of automated detection and human review. Explicitly mentions **EDSA (Educational, Documentary, Scientific, or Artistic) exceptions**.\n    *   **Advertiser-Friendly Content Guidelines:** Focus on brand safety and apply specifically to creators in the YouTube Partner Program (YPP) for monetization eligibility.\n    *   **Appeals Process:** Highlights the importance of the appeals system for creators disagreeing with content removal or YPP suspension decisions.\n*   **Creator Support & Responsibility:**\n    *   Details the **YouTube Partner Program (YPP)** as a revenue-sharing model that incentivizes creators to adhere to policies (requiring a \"higher bar\" for eligibility and ongoing adherence).\n    *   Showcases **Creator Tools** designed for self-management, including:\n        *   Channel Guidelines (setting conversation norms).\n        *   Comment Moderation (holding inappropriate comments, blocking users/words).\n        *   Privacy & Safety Resources.\n*   **Combating Abuse through Partnerships:**\n    *   States a clear prohibition on content promoting violent extremist or criminal organizations, relying on government/international designations.\n    *   Highlights **collaboration with industry experts**, specifically mentioning YouTube's role as a founding member of the **Global Internet Forum to Counter Terrorism (GIFCT)** to combat terrorist content across the web.\n*   **Transparency & Further Reading:** Links to related blog posts regarding new tools (e.g., AI-generated content disclosure, responsible AI tools), demonstrating ongoing efforts and transparency in policy evolution.\n\n**For a Product Manager:** This new page centralizes and clarifies YouTube's multi-layered approach to Trust & Safety, balancing free expression with platform integrity and monetization needs. It underscores the importance of both automated and human review, creator accountability, and strategic external partnerships in maintaining a healthy content ecosystem. It also highlights an emphasis on providing creators with tools to manage their own content and communities.",
    "last_updated": "2025-07-22T00:29:00.491266Z"
  },
  "youtube-harassment-policy": {
    "policy_name": "Youtube Harassment Policy",
    "initial_summary": "## YouTube Harassment & Cyberbullying Policy Summary\n\nThis policy prioritizes the safety of creators, viewers, and partners.  Key prohibitions include:\n\n* **Harassment:** Prolonged insults or slurs targeting individuals based on protected group status, physical attributes, or victimhood (sexual assault, abuse, etc.).  A stricter approach is taken for content targeting minors.\n* **Doxxing & PII Sharing:** Sharing or threatening to share non-public personally identifiable information (PII),  except for widely available public information or clearly marked fake PII used for educational purposes.\n* **Abusive Behavior:** Encouraging brigading or other forms of coordinated abuse. Promoting harmful conspiracy theories linked to threats or violence.\n* **Threats & Violence:**  Threats against individuals or their property (including implicit threats), depictions of staged meet-ups to falsely accuse individuals, vigilante violence, or content glorifying or mocking death/injury.  This also includes realistic simulations of violence or death.\n* **Stalking & Sexualization:** Stalking, unwanted sexualization, sharing non-consensual intimate imagery, or fantasizing about/threatening sexual assault.\n\n**Exceptions:**  Content may be allowed if the primary purpose is educational, documentary, scientific, or artistic (e.g., debates, scripted performances, harassment awareness content). However, these exceptions do not excuse malicious harassment, especially based on protected group status.\n\n**Enforcement:** Violations result in content removal and email notification.  First-time offenders receive a warning with a policy training option.  Multiple violations or severe abuse can lead to strikes, channel suspension, or termination.  Repeat offenders may be prevented from accessing future policy trainings.  The policy applies to videos, comments, livestreams, and external links.\n",
    "last_update_summary": "Based on the provided diff:\n\n*   There are **no changes to the actual policy text or content** regarding harassment and cyberbullying.\n*   The updates primarily involve **technical adjustments to the page's HTML structure**, including changes related to search functionality elements and internal identifiers/flags.\n*   These appear to be minor **frontend or backend code adjustments** that do not impact the substance of the policy.",
    "last_updated": "2025-08-04T16:16:44.504471Z"
  },
  "youtube-shopping-ads-policy": {
    "policy_name": "Youtube Shopping Ads Policy",
    "initial_summary": "## Google Shopping Ads Policies: Summary for Product Managers\n\nThis document outlines Google's policies for Shopping ads, aiming for a trustworthy and transparent advertising ecosystem.  Key areas covered are:\n\n**1. Prohibited Content:**  This includes counterfeit goods, dangerous products (drugs, weapons, explosives), products enabling dishonest behavior (hacking tools, fake documents), and inappropriate content (hate speech, violence, cruelty).  Certain content lacks optimal support and is therefore unsupported in Shopping ads, though this doesn't affect other Google platforms.\n\n**2. Prohibited Practices:** This section addresses abuse of the ad network (malicious content, unfair advantages, bypassing reviews), irresponsible data collection and use (insecure data handling), and misrepresentation (misleading promotions, inaccurate product portrayal).\n\n**3. Restricted Content:**  This category covers legally or culturally sensitive content allowed with limitations and potential additional requirements. Examples include adult-oriented content, alcoholic beverages, copyrighted material, gambling, healthcare products, political content, and High Fat Sugar Salt (HFSS) food & beverages (prohibited from targeting minors).\n\n**4. Editorial & Technical Requirements:**  Ads must meet high professional and editorial standards, be clear, and lead to relevant, user-friendly landing pages. Technical requirements ensure ad functionality across various formats.\n\n**Enforcement:** Google uses AI and human review to enforce policies, taking actions ranging from disapproving ads to suspending accounts for violations.  Advertisers can appeal decisions.  Compliance with all applicable laws and regulations is mandatory.\n",
    "last_update_summary": "**Summary for Product Manager: YouTube Shopping Ads Policy (Initial Publication)**\n\nThis document represents the *initial publication* of Google's YouTube Shopping Ads Policy, dated 2025-07-22. It outlines a comprehensive framework for acceptable content and practices within their shopping ad ecosystem.\n\n**Key Policy Areas:**\n\n1.  **Overview & Enforcement:**\n    *   Aims for a trustworthy, transparent, and safe digital advertising ecosystem, aligning with broader Google Ads policies.\n    *   Enforced through a combination of Google AI and human review.\n    *   Violations can lead to ad disapproval, impression caps, or account suspension, with clear appeal processes.\n\n2.  **Prohibited Content (Not Allowed):**\n    *   **Counterfeit Goods:** Products mimicking trademarks/brands.\n    *   **Dangerous Products:** Recreational drugs, weapons, explosives, tobacco.\n    *   **Dishonest Behavior:** Hacking software, fake documents, academic cheating.\n    *   **Inappropriate Content:** Shocking content, hate, discrimination, violence, self-harm, animal cruelty.\n    *   **Unsupported Shopping Ads Content:** Content where an optimal user experience cannot be provided within Shopping Ads (specific to this product, not other Google platforms).\n\n3.  **Prohibited Practices (Cannot Do):**\n    *   **Ad Network Abuse:** Malicious content, low-value sites, unfair advantage, bypassing review systems.\n    *   **Irresponsible Data Collection & Use:** Misusing user information, collecting PII without proper security (e.g., over non-SSL connections).\n    *   **Misrepresentation:** Misleading promotions, lack of explicit consent, inaccurate or untruthful product/retailer representation.\n\n4.  **Restricted Content (Allowed with Limitations):**\n    *   **Adult-Oriented Content:** Merchandise, suggestive content, exposed skin/nudity (strict prohibitions on targeting minors, explicit content, non-consensual themes).\n    *   **Alcoholic Beverages:** Restrictions based on legal drinking age, implied benefits, excessive drinking, or consumption with dangerous activities.\n    *   **Copyrighted Content:** Requires legal authorization or specific reporting via Google forms.\n    *   **Gambling-related Content:** Limited promotion.\n    *   **Healthcare-related Content:** Includes OTC, prescription drugs, unapproved supplements, pregnancy/fertility products (may require preauthorization, some universally prohibited).\n    *   **Political Content:** Must comply with laws and election \"silence periods.\"\n    *   **Trademarks:** Generally allowed in titles/descriptions for relevant products, but subject to review for consumer confusion.\n    *   **High Fat Sugar Salt (HFSS) Food & Beverage:** Allowed if compliant with specific (implied) policies.\n\n**Key Takeaway for PM:**\nThis policy establishes a robust content moderation framework covering a wide range of sensitive categories and potentially harmful practices. It emphasizes user safety, legal compliance, and a fair advertising ecosystem, using a hybrid AI/human enforcement model. Be aware of the specific geopolitical notes regarding ad pauses in/to Russia, indicating responsiveness to global events.",
    "last_updated": "2025-07-22T00:29:21.453232Z"
  },
  "instagram-community-guidelines": {
    "policy_name": "Instagram Community Guidelines",
    "initial_summary": "# Competitor Policy Summary:\n\nThis document outlines Meta's Community Standards, encompassing policies for Facebook, Instagram, Messenger, and Threads.  Key areas covered include:\n\n* **Content Moderation:**  Policies define acceptable and unacceptable content, addressing issues like hate speech, violence, harassment, misinformation, and illegal activities.  A three-part enforcement approach (remove, reduce, inform) is used.  Newsworthiness and public interest are considered when evaluating potentially violating content.\n\n* **Account Integrity:** Policies cover authentic identity, inauthentic behavior, and account security.\n\n* **Safety & Well-being:**  Emphasis is placed on user safety, privacy, and dignity.  Specific attention is given to protecting minors, addressing issues like child exploitation and suicide/self-harm.\n\n* **Transparency & Enforcement:**  The document details how Meta detects and addresses policy violations, including technological solutions and human review.  Transparency reports on enforcement, intellectual property, government data requests, and content restrictions are publicly available.\n\n* **Governance & Appeals:**  Information is provided about Meta's Oversight Board, its role in policy appeals, and its impact.\n\n* **Research & Data:** Access to research tools and datasets related to content and advertising is highlighted.\n\n\nThe policy aims to balance freedom of expression with the need to maintain a safe and respectful online environment.  The US English version is considered the primary and most up-to-date document.\n",
    "last_update_summary": "As a Trust & Safety analyst, here's a summary of the competitor's updated policy page for a product manager:\n\n---\n\n### Competitor Policy Analysis: Instagram Community Guidelines (New File)\n\n**Date:** 2025-07-22\n\n**Summary of Key Changes (New Policy Introduction):**\n\nThis diff indicates the introduction or a complete overhaul of Instagram's (and other Meta platforms') Community Guidelines, now consolidated and presented under a new, highly structured \"Transparency Center.\" The key takeaways for product managers include:\n\n1.  **Broad Scope:** The Community Standards explicitly apply across **Facebook, Instagram, Messenger, and Threads**, signaling a unified approach to content governance across their core social platforms.\n2.  **Foundational Values:** The policies are anchored by four core values, each with a clear rationale:\n    *   **Authenticity:** Combating misrepresentation.\n    *   **Safety:** Preventing physical harm, intimidation, and silencing.\n    *   **Privacy:** Protecting user data and personal information.\n    *   **Dignity:** Promoting respect and preventing harassment/degradation.\n3.  **Commitment to Voice with Nuance:**\n    *   Emphasizes \"free expression\" but balances it with abuse prevention.\n    *   **Newsworthy Exemption:** Content that would otherwise violate standards may be allowed if deemed \"newsworthy and in the public interest,\" following a strict weighing of public interest value against harm and referencing international human rights standards.\n    *   **Contextual Enforcement:** Content using \"ambiguous or implicit language\" can be removed if additional context indicates a violation.\n4.  **AI-Generated Content Inclusion:** The standards explicitly apply to \"all types of content, including AI-generated content,\" setting a clear expectation for how new content formats will be governed.\n5.  **Structured Policy Presentation:** Each policy section will feature a \"Policy Rationale\" (aims) followed by \"specific policy lines\" detailing:\n    *   Content that is strictly **not allowed**.\n    *   Content requiring **additional information/context**, or allowed with **warning screens** or **18+ age restrictions**.\n6.  **Comprehensive Transparency Center:** The new structure indicates a strong focus on transparency, with dedicated sections for:\n    *   Policies (Community Standards, Ad Standards, Other)\n    *   Enforcement (Detection, Action)\n    *   Security (Threat disruptions, Reporting)\n    *   Features (Specific approaches to dangerous orgs, misinformation, elections, etc.)\n    *   Governance (Oversight Board, appeals, impact tracking)\n    *   Research Tools (Content Library, Ad Library)\n    *   Reports (CSER, IP, Government Requests, Widely Viewed Content, Regulatory)\n7.  **Primary Language Reference:** The US English version is designated as the \"most up to date\" and \"primary document\" for the Community Standards.\n\n**Implication for Product:**\nThis comprehensive and transparent policy framework highlights a strong commitment to defining and communicating platform boundaries. Product teams should be aware of the detailed values, the specific inclusion of AI-generated content, and the newsworthy exemption, as these directly impact feature development, content moderation tools, and user communication strategies. The explicit commitment to \"dignity\" and inclusion of \"overlooked or marginalized\" communities also suggests a focus on equity in policy application.",
    "last_updated": "2025-07-22T00:27:39.485008Z"
  },
  "instagram-appeal-process": {
    "policy_name": "Instagram Appeal Process",
    "initial_summary": "Here's a concise summary of Instagram's Oversight Board appeal policy for a Product Manager:\n\n### Instagram Oversight Board Appeal Policy Summary\n\n**Key Points:**\n\n*   **Purpose:** Allows users to appeal Instagram's content decisions (both on their own content or content they reported) to an independent Oversight Board (OB).\n*   **Prerequisite:** Users **must** first exhaust Instagram's internal review process, including two internal reviews of the decision, before becoming eligible to appeal to the OB.\n*   **Appeal Types:**\n    *   Decisions to take down a user's content.\n    *   Decisions not to remove content a user reported.\n*   **Eligibility & Selection:** Not all content decisions are eligible for OB appeal. The OB itself selects only a limited number of eligible appeals for review and may not choose a specific case.\n*   **Timeline:** Appeals to the OB must be submitted within **15 days** of Instagram's final decision.\n*   **Status Check:** Users can track their appeal status on the Oversight Board's website using a reference number.",
    "last_update_summary": "Here's a concise summary for a Product Manager:\n\n### Instagram Appeal Process: Oversight Board (New Page)\n\nThis new policy page outlines the process for users to appeal Instagram's content decisions to the Oversight Board.\n\n**Key Points:**\n\n*   **Appealable Decisions:** Users can appeal decisions about their own content (if taken down) or content they reported (if not taken down).\n*   **Mandatory Internal Review:** Before appealing to the Oversight Board, users *must* first go through Instagram's internal \"request a review\" process. If Instagram has reviewed the content twice and the user still disagrees, they may be eligible for an Oversight Board appeal.\n*   **Eligibility & Limitations:** Not all content or decisions are eligible, but more options are being added. The Oversight Board selects only a certain number of eligible appeals for review.\n*   **Time Limit:** Users have 15 days from the original decision to submit an appeal to the Oversight Board.\n*   **Status Tracking:** Appeal status can be checked on the Oversight Board's website using a reference number.",
    "last_updated": "2025-07-22T00:27:16.151470Z"
  },
  "instagram-blocking-people": {
    "policy_name": "Instagram Blocking People",
    "initial_summary": "Here's a concise summary of the provided policy text for a Product Manager:\n\n### Instagram \"Blocking People\" Policy Summary\n\nThis policy details Instagram's \"Blocking People\" feature, a core safety and privacy control.\n\n**Key Points:**\n\n*   **Core Functionality:** Explains how users can block and unblock other accounts.\n*   **Impact of Blocking:**\n    *   Removes all past comments and likes from the blocked user.\n    *   Clarifies that a blocked user generally cannot see the blocker's content, message them, or mention them.\n    *   Provides guidance on how to view and manage a list of blocked accounts.\n*   **Related Privacy & Safety Controls:** The document also references other related user controls available in the \"Privacy, Security & Reporting\" section, including:\n    *   Making an account private.\n    *   Removing followers.\n    *   Restricting users (a softer form of control than blocking).\n    *   Temporarily limiting interactions from others.\n    *   Reporting messages or accounts.\n\nThis policy emphasizes user control over their interactions and visibility on the platform.",
    "last_update_summary": "This diff indicates the **creation of a new Instagram Help Center page** titled \"Blocking People.\"\n\n### Summary for Product Manager:\n\n**Key Change:** Introduction of a dedicated and comprehensive Help Center page for \"Blocking People\" on Instagram.\n\n**Purpose:** This new page serves as a centralized resource for users to understand and manage blocking functionalities.\n\n**Key Content & Scope:**\n*   **Core Blocking:** How to block and unblock users, including blocking comments.\n*   **Impact of Blocking:** Explains what happens when someone is blocked (e.g., removal of comments/likes, mentionability).\n*   **Management:** Guides users on how to view and manage their blocked list.\n*   **Related Features:** Integrates information on alternative or complementary safety features, such as:\n    *   Making an account private\n    *   Removing followers\n    *   Restricting/unrestricting users\n    *   Temporarily limiting interactions\n    *   Reporting messages/chats\n\nThis new page aims to provide a clear, consolidated resource for users to control their interactions and privacy on the platform.",
    "last_updated": "2025-07-22T00:27:20.880480Z"
  },
  "instagram-commerce-policies": {
    "policy_name": "Instagram Commerce Policies",
    "initial_summary": "### Competitor Policy Page Analysis: Unavailable Page\n\nThe provided text is an error message from Instagram's Help Center, indicating that a specific page is unavailable.\n\n**Key Points:**\n\n*   **Core Message:** \"This Page Isn't Available.\"\n*   **Reasons for Unavailability:** The page may be unavailable due to a broken link or because it has been removed.\n*   **User Guidance:** Users are advised to check if the link they are trying to open is correct.\n*   **Navigation Options:** The page provides clear calls to action to return to the Help Center Home or go back to the previous page.\n*   **T&S Relevance:** This page demonstrates how a competitor handles missing or removed content (potentially policy or help documentation), which impacts user experience and trust. It emphasizes the need for clear communication and alternative navigation when users encounter inaccessible information.",
    "last_update_summary": "**Summary for Product Manager:**\n\nA new snapshot was taken for a competitor's (Instagram's) commerce policies page (`instagram-commerce-policies/2025-07-22T002641Z.html`).\n\n**Key Change:**\n\nInstead of capturing policy content, the snapshot shows an \"This Page Isn't Available\" error message. This indicates that the specific Instagram Commerce Policies page being monitored has been **removed or is no longer accessible** at that URL as of July 22, 2025.\n\n**T&S Implications:**\n\nThe competitor's specific commerce policy content at this location is currently unavailable. This could signal a policy change, migration to a new URL, or the deprecation of these particular policies. Further investigation is needed to determine the status of Instagram's commerce policies.",
    "last_updated": "2025-07-22T00:27:26.798424Z"
  },
  "tiktok-blocking-users": {
    "policy_name": "Tiktok Blocking Users",
    "initial_summary": "Here's a concise summary of the competitor's policy page for a Product Manager:\n\n### Competitor Policy Page Summary\n\nThe competitor's policy documentation serves as a comprehensive help center, detailing an exceptionally broad range of platform functionalities, from core features to advanced creator tools and monetization.\n\n**Key Trust & Safety Takeaways:**\n\n*   **Robust User Control & Safety Tools:** A significant focus is placed on empowering users with safety mechanisms. Detailed instructions for blocking (individual users, multiple users from comments, unblocking) are prominently featured, alongside mentions of a \"Safety Center,\" \"Community Guidelines,\" and \"Report a problem\" functionality.\n*   **Comprehensive Feature & Content Coverage:** The policies span an extensive array of content types and features including user-generated videos, AI-generated content, creator tools, live streaming, e-commerce (\"TikTok Shop\"), messaging, and content discovery, indicating a complex ecosystem requiring broad T&S oversight.\n*   **Creator Monetization & Ecosystem:** Policies extend to creator monetization features (LIVE, Gifts, promotion tools), necessitating guidelines for commercial activities, fraud prevention, and responsible content creation related to earning.\n*   **Legal & Policy Framework:** The document points to a foundational set of legal and policy resources, including Terms of Use, Privacy, Copyright, and Law Enforcement guidelines, signifying a structured approach to compliance and trust.\n*   **Algorithmic Transparency & Global Reach:** It touches on content recommendation algorithms (\"How TikTok recommends content\") and highlights a vast global operational scope through an extensive list of supported languages, implying a need for culturally nuanced and legally compliant T&S policies worldwide.",
    "last_update_summary": "**New Policy Page: Blocking Users**\n\nThis diff introduces a completely new help center policy page for TikTok's user blocking features, indicating a formalization and enhancement of user safety controls.\n\n**Key Content:**\n*   **Comprehensive Blocking Guide:** Provides clear, step-by-step instructions for users to block and unblock individual accounts directly from a person's profile.\n*   **New Multi-Block Functionality:** Crucially, it outlines a new method for users to block *multiple accounts simultaneously from their video comments*. This is a significant addition, allowing users to efficiently manage and mitigate harassment, spam, or unwanted engagement from multiple sources at once.\n\n**Impact for Product Managers (T&S Lens):**\nThis new page clarifies and expands user self-service safety tools. The addition of multi-user blocking from comments is a key feature enhancement that empowers users to more effectively manage negative interactions, potentially reducing the burden on reporting systems and improving overall user experience and trust.",
    "last_updated": "2025-07-22T00:27:47.015162Z"
  },
  "youtube-hiding-users": {
    "policy_name": "Youtube Hiding Users",
    "initial_summary": "As a Trust & Safety analyst, here is a concise summary of the provided policy document on YouTube's \"Hide users from your channel\" feature for a Product Manager:\n\n---\n\n### YouTube: \"Hide Users from Your Channel\" Policy Summary\n\nThis policy outlines a channel moderation feature allowing content creators to control who can interact with their content.\n\n**Key Functionality:**\n\n*   **Purpose:** Channel owners can \"hide\" specific viewers to prevent their comments from appearing on the channel and to stop them from creating clips from videos or live streams.\n*   **Impact on Hidden User:**\n    *   All previous comments from the hidden user on the channel will be hidden within 48 hours.\n    *   Future comments from the hidden user will not appear.\n    *   The hidden user will **not** receive a notification that they have been hidden.\n*   **Methods to Hide:**\n    1.  **From a Comment:** Select \"More\" next to a user's comment, then \"Hide user from channel.\"\n    2.  **Via YouTube Studio:** In \"Settings\" > \"Community\" > \"Automated Filters,\" paste the user's channel URL into the \"Hidden users\" box.\n*   **Managing Hidden Users:**\n    *   A list of hidden users is available in YouTube Studio under \"Settings\" > \"Community\" > \"Automated Filters.\"\n    *   Users can be \"shown\" (unhidden) from this list, which allows their *future* comments to appear. Previous comments remain hidden.\n*   **Scope:** This is a **channel moderation tool** for managing audience interaction. It is distinct from reporting abuse, harassment, or policy violations, which should be directed to the Safety Center.\n\n---",
    "last_update_summary": "Here's a concise summary for a product manager:\n\n*   **Specific Changes:**\n    *   The entire user feedback form previously located at `youtube-hiding-users/snapshot.html` has been deleted.\n    *   This form included specific issue categories (e.g., \"Inaccurate,\" \"Hard to understand\") and a free-text \"Share additional info or suggestions\" field.\n*   **Impact:**\n    *   Users can no longer provide direct feedback or report issues related to the \"hiding users\" feature through this specific interface.\n    *   This eliminates a dedicated data collection channel for user sentiment and issue identification in this product area.",
    "last_updated": "2025-08-04T19:41:44.697354Z"
  },
  "whatnot-community-guidelines": {
    "policy_name": "Whatnot Community Guidelines",
    "initial_summary": "Error: No GEMINI_API_KEY configured.",
    "last_update_summary": "Here's a summary of the competitor's policy change based on the provided diff:\n\n*   The competitor's Community Guidelines policy document is currently inaccessible.\n*   Accessing the page intended for the Community Guidelines now results in a \"page not found\" error message.\n*   This suggests the policy is either temporarily unavailable, undergoing revision, or has been moved.",
    "last_updated": "2025-08-04T16:16:37.599257Z"
  },
  "whatnot-prohibited-items": {
    "policy_name": "Whatnot Prohibited Items",
    "initial_summary": "Error: No GEMINI_API_KEY configured.",
    "last_update_summary": "Initial version.",
    "last_updated": "2025-08-04T16:02:34.677017Z"
  }
}