{
  "tiktok-community-guidelines": {
    "policy_name": "Tiktok Community Guidelines",
    "initial_summary": "## TikTok Competitor Community Guidelines Summary\n\nThis document outlines a comprehensive set of community guidelines for a TikTok-like platform, effective May 17, 2024.  Key areas covered include:\n\n* **Content Moderation:**  The platform employs a three-pronged approach: removing violating content, restricting age-inappropriate content (for users under 18), and making ineligible for recommendation (For You feed) content that doesn't meet platform standards.\n\n* **Prohibited Content:**  A wide range of prohibited content is detailed, encompassing: violence, hate speech, sexual abuse, harassment, self-harm, dangerous activities, misinformation, scams, regulated goods (alcohol, firearms, etc.), and violations of privacy and security.  Specific examples are provided within each category, though the document notes that these are not exhaustive.\n\n* **Community Empowerment:** The platform provides users with tools and resources to manage their experience, including safety settings, filtering options, and reporting mechanisms.\n\n* **Enforcement:** While the specifics of enforcement aren't detailed, the document implies a combination of automated and human moderation to address policy violations.\n\nThe guidelines aim to create a safe and welcoming environment while balancing creative expression and the prevention of harm.  The full guidelines are categorized for easier navigation, with additional information and examples available for each section.\n",
    "last_update_summary": "As a Trust & Safety analyst, here's a summary of the provided competitor policy for a Product Manager:\n\n---\n\n### Competitor Policy Analysis: TikTok Community Guidelines (New/Overhauled)\n\nThis document represents the **entire content of a new or significantly overhauled version of TikTok's Community Guidelines**, effective May 17, 2024. This is not a partial update but a comprehensive release of their current policy framework.\n\n**Key Takeaways for Product Management:**\n\n1.  **Clear Tiered Moderation Framework:** TikTok explicitly outlines a multi-layered approach beyond simple \"remove/allow\":\n    *   **Remove:** Content violating core \"rules.\"\n    *   **Restrict:** Content not suitable for youth (18+ only), age-gating it.\n    *   **Make Ineligible for FYF:** Content not meeting recommendation standards, limiting discoverability without outright removal.\n    *   **Empower:** Providing users with tools (labels, opt-in screens, warnings, safety toolkit, account controls) for personalized experience management.\n    This tiered approach allows for nuance in content handling, addressing both platform-wide harms and user-specific preferences/sensitivities.\n\n2.  **Comprehensive Scope & Granularity:** The guidelines cover a broad range of content and behaviors, with detailed sub-categories, indicating a mature and granular policy structure. Notable categories include:\n    *   **Integrity & Authenticity:** Explicitly addresses **Edited Media and AI-Generated Content (AIGC)**, Civic and Election Integrity, Misinformation, Fake Engagement, and Unoriginal Content. This signals a strong focus on emerging integrity threats.\n    *   **Safety & Civility:** Detailed sections on Human Trafficking, Youth/Adult Sexual and Physical Abuse, Hate Speech, and Harassment/Bullying.\n    *   **Mental & Behavioral Health:** Specific policies on Suicide & Self-Harm, Disordered Eating, and **Dangerous Activity and Challenges.**\n    *   **Regulated Goods & Commercial Activities:** Covers Gambling, Alcohol/Tobacco/Drugs, Firearms, and critically, **Frauds and Scams**.\n\n3.  **Emphasis on User Experience & Transparency:**\n    *   The policy differentiates \"rules\" from \"standards\" (for FYF eligibility), improving clarity for users.\n    *   It highlights the availability of \"More information\" for definitions and examples, promoting user understanding.\n    *   The \"Empower\" pillar signifies a commitment to user control and self-moderation tools.\n    *   The Enforcement section outlines Public Interest Exceptions, Detection/Reporting, and Notice/Appeals processes.\n\n4.  **Competitive Implication:** TikTok is investing heavily in a sophisticated and transparent policy framework, particularly in areas like AI-generated content, dangerous challenges, and nuanced content restriction. This sets a high bar for industry standards and user trust. Our product strategy should consider how we communicate our moderation principles and tools with similar clarity and how we address these emerging content risks.\n\n---",
    "last_updated": "2025-07-21T00:27:11.710319Z"
  },
  "tiktok-live-moderation": {
    "policy_name": "Tiktok Live Moderation",
    "initial_summary": "# TikTok LIVE Moderation Policy Summary\n\nThis document details TikTok's approach to content moderation during LIVE streams.  Key features include:\n\n* **Creator Controls:** Creators can add moderators, control audience age (18+), filter comments, block keywords, mute, and block viewers directly from the LIVE settings or chat.  This applies to both mobile app and web browser access (via LIVE Studio or OBS Studio for broadcasting; not required for moderation).\n\n* **Moderator Permissions:** Moderators, granted permission by the creator, can mute, block viewers, and report comments violating Community Guidelines.  The level of control a moderator has is determined by the creator.\n\n* **User Actions:**  Viewers can be reported, muted (temporarily), or blocked (preventing future LIVE viewership and other interactions with the creator).  Notifications are sent to muted/blocked users.\n\n* **Accessibility:** Moderation tools are accessible both within the LIVE settings and directly from the LIVE chat interface on both the mobile app and web browser.\n",
    "last_update_summary": "## Competitor Policy Analysis: TikTok LIVE Moderation\n\n**Summary for Product Manager**\n\nThis document represents a **newly published policy page** (`new file mode`) from TikTok detailing their approach to LIVE stream moderation. It outlines comprehensive tools and responsibilities for both creators and designated moderators to manage content and viewers during live broadcasts.\n\n**Key Policy Elements:**\n\n*   **Dual Roles:** Explicitly defines capabilities for **Creators** (full control, including adding/removing moderators, audience age limits, comprehensive comment settings) and **Moderators** (granted permissions by creators to report, mute, block viewers, and manage comments).\n*   **Multi-Platform Access:** Provides moderation instructions for both the **TikTok app** and **web browser**, ensuring consistent control across platforms.\n*   **Pre- and In-LIVE Management:** Tools are available for setup *before* a LIVE (e.g., adding moderators, audience controls) and for dynamic management *during* the LIVE (e.g., muting/blocking from chat, adjusting comment settings).\n*   **Granular Moderation Actions:**\n    *   **Report:** Flag viewer comments.\n    *   **Mute:** Temporarily restrict a viewer from commenting (with user notification).\n    *   **Block:** Permanently prevent a viewer from watching the LIVE and interacting with the creator's content (with user notification).\n    *   **Comment Settings:** Creators can allow/filter comments, block keywords, and mute viewers.\n    *   **Audience Control:** Creators can limit LIVEs to viewers aged 18 and older.\n*   **Transparency:** Creators and moderators can view lists of muted and blocked accounts.\n\nThis new policy page underscores TikTok's emphasis on empowering creators with robust, real-time moderation capabilities to ensure a safer and more controlled LIVE environment.",
    "last_updated": "2025-07-21T00:27:21.050702Z"
  },
  "tiktok-shop-prohibited-products": {
    "policy_name": "Tiktok Shop Prohibited Products",
    "initial_summary": "## Competitor Policy Summary: TikTok Shop Academy (US)\n\nThis document appears to be incomplete or broken.  The provided text only shows a heading related to boosting sales on TikTok Shop Academy and a JavaScript error message.  **No actual policy information is present.**  Therefore, no meaningful summary of their policy can be provided.  Further investigation is needed to obtain the actual policy document.\n",
    "last_update_summary": "**Summary for Product Manager: Competitor Policy Page Analysis**\n\nThis diff indicates the creation of a *new file* for a competitor's \"prohibited products\" policy page (dated 2025-07-20).\n\n**Key Changes:**\n\n*   **New Page Created:** A new policy page `tiktok-shop-prohibited-products` has been added.\n*   **Placeholder Content:** The page's content is currently a generic \"JavaScript not enabled\" message, suggesting it's an unpopulated placeholder or a technical error page, rather than an active policy.\n*   **No Policy Content Detected:** There are no actual policy rules or guidelines present in this version of the page.\n\n**Impact:**\n\nCurrently, there is no substantive policy information to analyze. This appears to be a technical setup or placeholder for a future policy page. We should monitor this URL for updates to identify actual policy content when it becomes available.",
    "last_updated": "2025-07-20T23:50:56.579760Z"
  },
  "whatnot-blocking-a-user": {
    "policy_name": "Whatnot Blocking A User",
    "initial_summary": "## Whatnot User Blocking Policy Summary\n\nThis document details Whatnot's user blocking functionality.  Users can block others to prevent:\n\n* Following\n* Direct messaging\n* Profile viewing\n* Livestream interaction (bookmarking, joining, chatting)\n* Future purchases from listings\n\nExisting orders are unaffected by blocking.  Blocking is currently permanent.  There's no list of blocked users.  Being removed from a livestream is different from being blocked by a user.  Users can report violations of Community Guidelines separately.\n",
    "last_update_summary": "As a Trust & Safety analyst, here's a concise summary of the new Whatnot user blocking policy for a Product Manager:\n\n---\n\n### Whatnot: New User Blocking Policy Page\n\n**Summary of Change:**\nWhatnot has published a **new** Help Center article detailing its \"Blocking a User\" functionality. This isn't an update to an existing policy, but the introduction of a dedicated resource for this feature.\n\n**Key Policy & Functionality Highlights:**\n\n*   **Blocking Scope:** A blocked user is prevented from:\n    *   Following the blocker.\n    *   Direct messaging in the app.\n    *   Viewing the blocker's profile.\n    *   Bookmarking, joining, or chatting in the blocker's livestreams.\n    *   Making *future* purchases from the blocker's marketplace listings (existing orders are still honored).\n*   **Reporting vs. Blocking:** The policy clearly differentiates blocking (personal preference/nuisance) from reporting a user for Community Guidelines violations (handled by Trust & Safety).\n*   **How to Block:** Users can block others via their profile by tapping the three-dot icon and selecting \"Block User.\"\n*   **Unblocking & Limitations:**\n    *   Users *can* unblock someone by searching for their profile and selecting \"Unblock.\"\n    *   **Crucially, there is currently no centralized list of blocked users**, leading to the statement \"currently blocking is permanent!\" in terms of visibility and management.\n*   **Livestream Bans vs. User Blocking:** The policy clarifies that being removed from a livestream by a host/mod is *not* the same as being blocked by another user. Livestream bans are temporary for that stream, while user blocks are permanent unless individually reversed.\n\n**Trust & Safety Implication:**\nThis new page formalizes user control over their interactions and privacy, while still directing serious policy violations to the Trust & Safety team for investigation. The lack of a blocked user list is a notable UX limitation.",
    "last_updated": "2025-07-21T00:27:29.958023Z"
  },
  "whatnot-buyer-protection": {
    "policy_name": "Whatnot Buyer Protection",
    "initial_summary": "# Whatnot Buyer Protection Policy Summary\n\n**Key Points:**\n\n* **Refund Eligibility:** Whatnot offers buyer protection for incomplete/incorrect items, items not as described/inauthentic, and packages not received.  Refunds are generally granted within 30 days of purchase or 14 days of delivery (7 days for certain categories like coins, sneakers, luxury goods; 2 days for plants).  Whatnot may require item return in original condition.  German buyers pay return shipping.\n\n* **Refund Exclusions:**  Consumables (opened/consumed items, breaks except for missing/damaged items), tips, refused deliveries, uncollected packages, unpaid customs fees, exchange rate losses, chargebacks, digital content, off-platform transactions, and instances of suspected fraud are excluded.  Returning the wrong item also voids a refund.\n\n* **Time Limits & Exceptions:**  Specific shorter deadlines apply for certain high-value categories and counterfeit claims (30 days from receipt). Extensions may be granted for international orders, pre-orders, custom orders, and due to natural disasters.  \"Delivered\" but not received items require contact within 14 days.\n\n* **EU/UK Right of Withdrawal:** EU/UK buyers have a 14-day right of withdrawal, requiring item return within 14 days of cancellation.  Buyers are responsible for return shipping costs. This right doesn't apply to breaks, surprise products, or certain unsuitable goods (hygiene, mixed, sealed software/media, customized items, perishable goods).\n\n\n* **High-Value Loss Reimbursement:** A separate policy exists for high-value card losses in breaks, potentially reimbursing market value.\n\n",
    "last_update_summary": "This `diff` indicates the **introduction of a new policy document**, not a modification to an existing one. Therefore, the \"key changes\" are the establishment of this comprehensive Buyer Protection Policy itself and its specific terms.\n\n### Whatnot Buyer Protection Policy (New Implementation)\n\nThis document outlines Whatnot's newly established, comprehensive Buyer Protection Policy, detailing the conditions under which buyers are eligible for refunds and the process for obtaining them.\n\n**Key Policy Details for Product Managers:**\n\n*   **Scope:** Provides a framework for refunds covering issues such as incomplete/incorrect items, items not as described (damaged, defective, counterfeit, expired), and package not received (lost, delayed, misdelivered).\n*   **Refund Request Timelines:**\n    *   **General:** Earlier of **30 days from purchase or 14 days from delivery**.\n    *   **Category-Specific Shorter Windows:**\n        *   **7 days from delivery/30 days from purchase:** Coins & Money, Sports Cards, Sneakers & Streetwear, Trading Card Games, Luxury Goods.\n        *   **2 days from delivery/30 days from purchase:** Plants.\n    *   **Counterfeit Claims:** Must be submitted within **30 days of receipt**.\n    *   **\"Delivered\" but Not Received:** Buyers must contact support within **14 days** of the marked delivery date (refunds are discretionary).\n*   **Return Requirements:** Whatnot may require returns; items must be in the *same condition as received*. Opening consumable products or removing tags may disqualify or reduce the refund amount. German buyers are responsible for return shipping costs (deducted from refund).\n*   **Key Exclusions (No Refund Provided):**\n    *   **Consumable Products:** Generally, if consumed or opened in a way that changes value (except specific \"Breaks\" for missing/damaged items).\n    *   **Tips, Digital Content, Chargebacks, Exchange Rate Fluctuations.**\n    *   **Buyer Actions:** Refusing delivery, failing to pick up packages, or refusing to pay customs fees.\n    *   **Incorrect Item Returned** by the buyer.\n    *   **Off-platform transactions.**\n    *   **Policy Abuse/Fraud:** Whatnot reserves the right to refuse refunds at its discretion for suspected abuse.\n*   **EU/UK Right of Withdrawal:** Specific provisions for consumers in the EU/UK, allowing cancellation within 14 days of receipt from professional sellers, with buyers responsible for return shipping and specific exclusions (e.g., \"Breaks\", unsealed items, customized goods).\n*   **High Value Loss Reimbursement:** References a separate policy for missing high-value Sports/Trading Cards obtained in \"Breaks\", allowing refunds based on market value.",
    "last_updated": "2025-07-21T00:27:42.284105Z"
  },
  "whatnot-enforcement-actions": {
    "policy_name": "Whatnot Enforcement Actions",
    "initial_summary": "## Whatnot's Trust & Safety Policy: Summary for Product Managers\n\nWhatnot's policy enforces Community Guidelines with penalties escalating based on violation severity and account history.  Violations are cumulative, meaning repeated offenses, even minor ones, can lead to a permanent ban.\n\n**Key Actions & Penalties:**\n\n* **Warnings:** For minor infractions, with guidance provided.\n* **Suspensions:** Temporary account access loss (2 or 7 days).\n* **Selling Access Revoked:**  Loss of ability to sell or go live.\n* **Ban:** Permanent account termination for serious or repeated violations.\n* **Discovery Restriction:** Temporary reduced visibility in feeds/recommendations.\n* **Other Penalties:** Loss of access to features like Direct Messages.\n\n**Account Health & Performance:**\n\n* An Account Health dashboard tracks Seller Performance Rates (fulfillment, shipping) and Policy Standing.\n* Poor performance in either area can result in warnings and penalties.\n* Policy Standing has five levels (Excellent, Good, Fair, Poor, Very Poor), reflecting penalty history.\n\n**Violation Expiration:**\n\n* Most violations expire after 180 days, except for bans and offboarding, which are permanent.\n\n**Appeals:**  Users can appeal penalties via email.\n",
    "last_update_summary": "Here's a concise summary for a Product Manager based on the provided new policy page:\n\n## Trust & Safety Enforcement Policy: \"What Actions We Take\"\n\nThis new policy page outlines Whatnot's structured approach to enforcing Community Guidelines, focusing on transparency and user education.\n\n### Key Changes / New Policy Components:\n\n*   **Comprehensive Enforcement Framework**: Clearly defines a progressive system of penalties based on violation severity and a user's Trust & Safety record.\n*   **Cumulative Violations**: Emphasizes that even less severe, repeated violations will cumulatively lead to stronger penalties, including permanent bans.\n*   **Defined Penalty Tiers**: Introduces specific enforcement actions:\n    *   **Warning**: Guidance on policy.\n    *   **Suspension**: Temporary loss of access (2 or 7 days).\n    *   **Revoke Selling Access**: For sellers, prohibits going live or selling.\n    *   **Discovery Restricted**: Temporary reduction in algorithmic visibility (feeds/recommendations) for certain violations, allowing users time to comply.\n    *   **Ban**: Permanent account termination.\n    *   **Other Penalties**: Loss of features (e.g., DMs).\n    *   **Ongoing Investigation Suspensions**: Temporary account holds during serious reviews.\n*   **Violation Expiry & Appeals**: Most violations expire after 180 days (excluding bans). Users can appeal decisions by responding directly to notification emails.\n*   **Account Health Dashboard (Beta)**: A new transparency tool for sellers to monitor:\n    *   **Seller Performance Rates**: Tracks Fulfillment Success Rate (refunds/cancellations) and On Time Shipment Rate, with underperformance potentially leading to penalties.\n    *   **Policy Standing**: A five-state system (**Excellent, Good, Fair, Poor, Very Poor**) that progressively indicates a seller's compliance status, reflecting their accumulated warnings and suspensions, and predicting future enforcement actions.\n\n**Implication for Product:** This policy introduces a significant level of transparency regarding enforcement, particularly for sellers. The \"Account Health Dashboard\" suggests new product features for users to self-monitor their performance and policy compliance.",
    "last_updated": "2025-07-21T00:27:51.440675Z"
  },
  "whatnot-hate-and-harassment": {
    "policy_name": "Whatnot Hate And Harassment",
    "initial_summary": "## Whatnot Hate and Harassment Policy Summary\n\nThis policy prohibits hateful conduct and harassment on the Whatnot platform, including sexual harassment and off-platform abuse that impacts the Whatnot community.  Key prohibited behaviors include:\n\n* **Harassment:**  Repeated unwanted contact, personal attacks, targeted obscene language,  using contact information for non-transactional purposes, and disparaging others (sellers disparaging buyers in streams, for example).  Exceptions may be made for newsworthy events or public figures.\n\n* **Threats & Harmful Wishes:** Wishing harm, making threats (implied or explicit), and exposing someone's sexual orientation or gender identity without consent.\n\n* **Sexual Harassment:** Unwanted sexual advances, objectification, degrading comments about sexual practices, sharing intimate images without consent.\n\n* **Hateful Conduct:** Any behavior promoting violence or hatred based on protected characteristics (race, ethnicity, religion, gender, sexual orientation, etc.). This includes using slurs (unless used self-referentially and with clearly indicated positive intent), supporting hate groups, and displaying hateful symbols (with exceptions for historical context, like pre-1933 artifacts). Specific allowances are made for the Confederate battle flag under very specific historical and non-hateful contexts.\n\n* **Off-Platform Abuse:**  Whatnot may take action against users coordinating harassment or hate off-platform that impacts the Whatnot community, even in rare instances where the off-platform behavior poses a significant threat to the platform.\n\nEnforcement actions against accounts may include removal.  The severity and persistence of the behavior are considered when evaluating violations.\n",
    "last_update_summary": "This `diff` indicates the **creation of a new policy document** for Whatnot titled \"Hate and Harassment Policy,\" dated August 21, 2024. This isn't a modification to an existing policy but rather the official introduction of a comprehensive stance on these issues.\n\n### Summary for Product Manager: Whatnot's New Hate and Harassment Policy\n\nThis new policy clearly defines and prohibits hateful conduct and harassment to ensure a safe and respectful environment on Whatnot. Key components include:\n\n*   **Broad Scope:** Aims to address behaviors that \"erode trust, disrupt communities, and discourage participation.\"\n*   **Harassment Defined:**\n    *   **Unwanted conduct/contact:** Includes targeting, repeated obscene/insulting language, continued contact after being asked to stop, and misuse of contact info.\n    *   **Personal attacks/disparagement:** Covers attacks based on appearance/intellect, negative doctored content, seller disparaging buyers, and repeated/extended disparagement (e.g., questioning reliability, \"exposing\" DMs, insulting across streams). *Note: Exceptions for newsworthy events/public figures.*\n    *   **Threats/harmful wishes:** Prohibits wishing harm, implied threats, non-consensual exposure of sexual orientation/gender identity, and glorifying traumatic events.\n*   **Sexual Harassment Defined:** Prohibits unwanted sexual advances, sexual objectification (e.g., comments on body parts, encouraging adult content, suggestive posing), disparagement based on sexual practices/morality, and non-consensual sharing/threats of intimate images.\n*   **Hateful Conduct Defined:** Prohibits behavior promoting violence or hatred based on protected characteristics (race, ethnicity, gender, sexual orientation, disability, etc.). Examples include:\n    *   Intolerance, subjugation, sexualizing/demeaning protected groups.\n    *   Mocking other races, encouraging violence, glorifying hate crimes.\n    *   **Specific guidance on symbols/imagery:** Prohibits racial slurs (unless self-referential/positive intent is clear), support for hate groups, harmful stereotypes, Nazi propaganda/Swastikas (with narrow historical exceptions), and grotesque Black Americana/blackface/yellowface/redface/brownface.\n    *   **Confederate Battle Flag:** Permitted *only* on historically accurate miniatures/models, artistic depictions denouncing it/slavery, or Civil War-themed book/video game covers without hateful context.\n*   **Off-Platform Abuse:** Whatnot reserves the right to take action against verifiable off-platform coordination of harassment or hate that targets the platform or its users, especially if it poses a significant threat.\n*   **Enforcement:** Violations \"may result in actions against your account, including removal.\"\n\nThis policy introduces a robust framework for content moderation related to hate and harassment, including detailed examples and specific nuances around sensitive imagery.",
    "last_updated": "2025-07-21T00:27:56.395422Z"
  },
  "whatnot-how-to-report": {
    "policy_name": "Whatnot How To Report",
    "initial_summary": "## Whatnot User Reporting and Investigation Policy Summary\n\n**Key Points:**\n\n* **Reporting Methods:** Users can report suspicious behavior via in-app reporting features during livestreams, in direct messages (DMs), on product listings, or user profiles (Android & Web).  Email reports to trustandsafety@whatnot.com are also accepted.  All reports are anonymous.\n* **Reporting Locations:** Reporting options are available within livestreams (for buyers and sellers), in-live chat, DMs, product listings, and user profiles (Android/Web).\n* **Investigation Process:** Whatnot's Trust & Safety team investigates reports, analyzing data, reviewing livestreams, and potentially temporarily suspending users during investigations. Outcomes are not publicly disclosed.\n* **Proactive Monitoring:**  The Trust & Safety team proactively investigates potential policy violations based on data analysis and community reports, taking action against users exhibiting patterns of abuse.\n\n",
    "last_update_summary": "Here's a concise summary of the new policy page for a Product Manager:\n\n### New Policy: How To Report A User & How We Investigate\n\nThis new policy page on Whatnot's Help Center clearly outlines the process for users to report violations of community guidelines and details how Whatnot's Trust & Safety team investigates these reports.\n\n**Key Changes/Additions:**\n\n*   **Centralized Reporting Guidance:** Provides a comprehensive guide for users on *where* and *how* to report, standardizing the process across various platform touchpoints.\n*   **Multiple Reporting Channels:** Users can now report from:\n    *   Livestreams (tapping user/seller username, live chat)\n    *   Direct Messages (DMs)\n    *   Product Listings (reporting sellers/listings)\n    *   User Profiles (Android & Web only)\n    *   Direct email to `trustandsafety@whatnot.com`.\n*   **Anonymity Guaranteed:** Explicitly states that all reports are anonymous.\n*   **Investigation Transparency:** Explains Whatnot's investigation process:\n    *   T&S team investigates facts, analyzes history/data, and reviews livestreams.\n    *   Temporary feature suspensions may occur during investigations.\n    *   Outcome of individual investigations is confidential for privacy reasons.\n    *   Highlights **proactive investigations** based on data analysis and community feedback to identify and act on patterns of habitual abuse.\n\nThis page aims to empower users by clarifying reporting mechanisms and building trust by explaining the safety team's investigative approach, including proactive measures.",
    "last_updated": "2025-07-21T00:28:02.627282Z"
  },
  "whatnot-moderator-guidelines": {
    "policy_name": "Whatnot Moderator Guidelines",
    "initial_summary": "## Whatnot Moderator Guidelines Summary\n\n**Key Points:**\n\n* **Goal:** Maintain a safe and fun marketplace by empowering moderators to manage livestream chats effectively.  Moderation should be fair and unbiased, prioritizing community safety and a positive user experience.\n\n* **Moderator Responsibilities:**\n    * Remove users only for violations of Community Guidelines or at the seller's request.  Avoid banning users for differing opinions.\n    * Maintain a respectful and engaging chat environment.\n    * Address inappropriate messages promptly, escalating to warnings before bans.\n    * Seek seller feedback.\n\n* **Moderator Privileges:**\n    * Remove users from a specific livestream (not a platform-wide ban).\n    * View muted chat messages.\n\n* **Adding/Removing Moderators:** Sellers can add moderators during or before a livestream via the scheduling section or by selecting the \"Allow to Moderate\" option from a user's chat profile.  Removal is done similarly using the \"Remove Moderator\" option.\n\n* **Underlying Principle:**  Moderation should be proactive and fair, guided by Whatnot's Community Guidelines and a principle of leading by example, not force.\n",
    "last_update_summary": "As a Trust & Safety analyst, here's a concise summary of the new Moderator Guidelines for a Product Manager:\n\n### Whatnot Moderator Guidelines (New Policy)\n\nThis document outlines a **new comprehensive policy for user-appointed moderators** on Whatnot, effective June 6, 2025. Its primary goal is to ensure a safer and more enjoyable P2P marketplace by establishing clear expectations and responsibilities for moderators.\n\n**Key Takeaways for Product Managers:**\n\n*   **Moderator Ethos:** Emphasizes \"lead by example, not by force\" and unbiased moderation, aligning with Community Guidelines.\n*   **Core Responsibilities:** Moderators are primarily responsible for managing live stream chat to prevent spam and inappropriate content, ensuring a positive community experience.\n*   **Abuse of Power Prevention:**\n    *   **Strict Prohibition:** Moderators are explicitly prohibited from banning users solely based on disagreement or personal opinions.\n    *   **Warning First:** Requires verbal warnings before removing or banning users, and a \"valid cause\" for any such action.\n*   **Defined Privileges:**\n    *   **\"Remove Users From Show\":** This action only removes a user from the *current livestream* and *does not* ban them from Whatnot entirely or from future streams by the same seller. This is a critical distinction from a platform-wide ban.\n    *   **\"View Muted Chat Messages\":** Mods can see messages muted by global filters or seller's muted word lists.\n*   **Clear Management Flow:** Provides straightforward instructions for sellers to add and remove moderators before and during streams.\n\n**Overall Impact:** This policy formalizes the role and limitations of community moderators, aiming to reduce subjective enforcement, prevent mod abuse, and provide a more consistent, safer chat environment without granting platform-wide banning authority to user-appointed roles.",
    "last_updated": "2025-07-21T00:28:07.909473Z"
  },
  "youtube-community-guidelines": {
    "policy_name": "Youtube Community Guidelines",
    "initial_summary": "## YouTube's Trust & Safety Policy Summary:\n\nThis document outlines YouTube's approach to content moderation, creator support, and combating abuse.  Key points include:\n\n* **Content Moderation:**  YouTube uses automated systems and human reporting to identify and remove content violating Community Guidelines and Advertiser-Friendly Content Guidelines. Exceptions are made for content with clear educational, documentary, scientific, or artistic value (EDSA).\n\n* **Creator Support:**  The YouTube Partner Program (YPP) offers revenue sharing to eligible creators who meet stricter content standards.  Creators have tools to manage comments and their channel's community interactions.  YouTube provides resources to support creator privacy and safety.\n\n* **Combating Abuse:** YouTube actively works to remove content promoting violent extremism or criminal organizations, collaborating with government entities and organizations like the GIFCT.\n\n* **Appeals Process:** Creators can appeal decisions regarding content removal or YPP suspension.\n\n\n",
    "last_update_summary": "As a Trust & Safety analyst, here's a concise summary of the provided policy page, which appears to be a *new* or comprehensively revised version of YouTube's \"Our Policies\" page.\n\n---\n\n### Policy Page Summary for Product Managers: YouTube's \"Our Policies\" (2025-07-21)\n\nThis new policy page outlines YouTube's approach to platform governance, emphasizing openness and free expression while maintaining a responsible ecosystem for users, creators, and advertisers.\n\n**Key Policy Frameworks:**\n\n1.  **Community Guidelines:**\n    *   Focus: Preventing violative content (e.g., violent extremism).\n    *   Detection: Primarily through automated systems and human reporting.\n    *   Enforcement: Swift removal, with efforts to prevent wide viewership.\n    *   Exceptions: Recognizes \"EDSA\" (Educational, Documentary, Scientific, Artistic) context.\n\n2.  **Advertiser-Friendly Content Guidelines:**\n    *   Focus: Protecting brand interests and ensuring suitable content for monetization.\n    *   Eligibility: Creators in the YouTube Partner Program (YPP) must adhere to these guidelines to earn revenue.\n    *   Enforcement: Demonetization of violative videos, YPP suspension for repeat offenses.\n\n**Enforcement & Appeals:**\n\n*   Acknowledges that \"mistakes happen\" and emphasizes the importance of the appeals process for creators.\n*   Creators are notified of policy violations (content removal, YPP suspension) and can appeal decisions.\n\n**Creator Support & Incentives:**\n\n*   **YouTube Partner Program (YPP):** A cornerstone, incentivizing creators to adhere to policies for long-term revenue sharing. High bar for entry and continued adherence required.\n*   **Creator Tools:** Provides various tools to help creators manage their content and communities, including:\n    *   Channel Guidelines: To set conversation norms.\n    *   Comment Moderation: Holding inappropriate comments for review, blocking words/users.\n    *   Privacy & Safety Resources.\n\n**Combating Abuse through Partnerships:**\n\n*   Highlights collaboration with industry experts, specifically mentioning the **Global Internet Forum to Counter Terrorism (GIFCT)**, to combat violent extremist and criminal organization content.\n\n**Emerging Areas & Transparency:**\n\n*   Features sections on new initiatives, including:\n    *   Tools to protect creators and artists.\n    *   Guidance on **disclosing altered or synthetic (AI-generated) content**.\n    *   Efforts to offer viewers more context and information on videos.\n\n**Overall Implication:** The page clearly articulates YouTube's dual responsibility for content safety and business viability, showcasing a mature policy framework that combines automated and human moderation, creator incentives, external partnerships, and a forward-looking approach to new content challenges like AI.",
    "last_updated": "2025-07-21T00:28:15.014067Z"
  },
  "youtube-harassment-policy": {
    "policy_name": "Youtube Harassment Policy",
    "initial_summary": "## YouTube Harassment & Cyberbullying Policy Summary\n\nThis policy prioritizes the safety of creators, viewers, and partners.  Key prohibitions include:\n\n* **Harassment:** Prolonged insults or slurs targeting individuals based on protected group status, physical attributes, or victimhood (sexual assault, abuse, etc.).  A stricter approach is taken for content targeting minors.\n* **Doxxing & PII Sharing:** Sharing or threatening to share non-public personally identifiable information (PII),  except for widely available public information or clearly marked fake PII used for educational purposes.\n* **Abusive Behavior:** Encouraging brigading or other forms of coordinated abuse. Promoting harmful conspiracy theories linked to threats or violence.\n* **Threats & Violence:**  Threats against individuals or their property (including implicit threats), depictions of staged meet-ups to falsely accuse individuals, vigilante violence, or content glorifying or mocking death/injury.  This also includes realistic simulations of violence or death.\n* **Stalking & Sexualization:** Stalking, unwanted sexualization, sharing non-consensual intimate imagery, or fantasizing about/threatening sexual assault.\n\n**Exceptions:**  Content may be allowed if the primary purpose is educational, documentary, scientific, or artistic (e.g., debates, scripted performances, harassment awareness content). However, these exceptions do not excuse malicious harassment, especially based on protected group status.\n\n**Enforcement:** Violations result in content removal and email notification.  First-time offenders receive a warning with a policy training option.  Multiple violations or severe abuse can lead to strikes, channel suspension, or termination.  Repeat offenders may be prevented from accessing future policy trainings.  The policy applies to videos, comments, livestreams, and external links.\n",
    "last_update_summary": "As a Trust & Safety analyst, here's a concise summary of YouTube's updated Harassment & Cyberbullying policy for a product manager:\n\n---\n\n### YouTube Harassment & Cyberbullying Policy Update (2025-07-21)\n\nThis policy represents a comprehensive and stricter stance on harassment and cyberbullying, with a heightened focus on the safety of all users, particularly minors.\n\n**Key Changes & Additions:**\n\n*   **Expanded Definition of Harassment:**\n    *   Explicitly prohibits prolonged insults/slurs based on **physical traits** or **protected group status**, and now includes **survivor status** (e.g., sexual assault, domestic abuse, child abuse).\n    *   Introduces a **stricter approach for content targeting minors**, specifically prohibiting content intended to shame, deceive, or insult them.\n*   **Doxxing & Privacy:** Clearly bans sharing, threatening to share, or encouraging the sharing of non-public Personally Identifiable Information (PII).\n*   **Harmful Behaviors:**\n    *   Prohibits **brigading** (coordinated abuse) and the promotion of **harmful conspiracy theories** linked to real-world threats or violence.\n    *   Bans content depicting **staged meet-ups** to accuse individuals of child misconduct without law enforcement.\n    *   Forbids content that **revels in or mocks** the death/serious injury of identifiable individuals.\n    *   Adds prohibitions on **realistic simulations of deceased individuals** describing their death/violence, and creators simulating **serious violence** against others (e.g., executions, torture).\n    *   Includes **stalking** and content that **denies or minimizes** someone's victim role in major violent events.\n    *   Expands \"unwanted sexualization\" to include lewd descriptions, sharing/requesting/distributing **non-consensual intimate imagery**, and fantasizing/threatening sexual assault.\n*   **Scope & External Links:** The policy explicitly applies to all YouTube products/features (videos, comments, live streams) and extends to **external links** in content.\n*   **Enforcement & Penalties:**\n    *   Introduces a **warning system** for first-time violations, which can expire after 90 days if the user completes a policy training.\n    *   Specifies that **repeated encouragement of abusive audience behavior**, persistent targeting of individuals based on intrinsic attributes, exposing users to physical harm risks, or inciting creator hostility for financial gain, can lead to content removal or other penalties (e.g., demonetization).\n    *   Reiterates the existing 3-strike policy leading to channel termination, with provisions for immediate termination in cases of severe abuse or channels dedicated to policy violations.\n\nThis update indicates a significant effort to define and address a wider range of harmful behaviors and to provide more nuanced enforcement mechanisms.",
    "last_updated": "2025-07-21T00:28:24.961192Z"
  },
  "youtube-shopping-ads-policy": {
    "policy_name": "Youtube Shopping Ads Policy",
    "initial_summary": "## Google Shopping Ads Policies: Summary for Product Managers\n\nThis document outlines Google's policies for Shopping ads, aiming for a trustworthy and transparent advertising ecosystem.  Key areas covered are:\n\n**1. Prohibited Content:**  This includes counterfeit goods, dangerous products (drugs, weapons, explosives), products enabling dishonest behavior (hacking tools, fake documents), and inappropriate content (hate speech, violence, cruelty).  Certain content lacks optimal support and is therefore unsupported in Shopping ads, though this doesn't affect other Google platforms.\n\n**2. Prohibited Practices:** This section addresses abuse of the ad network (malicious content, unfair advantages, bypassing reviews), irresponsible data collection and use (insecure data handling), and misrepresentation (misleading promotions, inaccurate product portrayal).\n\n**3. Restricted Content:**  This category covers legally or culturally sensitive content allowed with limitations and potential additional requirements. Examples include adult-oriented content, alcoholic beverages, copyrighted material, gambling, healthcare products, political content, and High Fat Sugar Salt (HFSS) food & beverages (prohibited from targeting minors).\n\n**4. Editorial & Technical Requirements:**  Ads must meet high professional and editorial standards, be clear, and lead to relevant, user-friendly landing pages. Technical requirements ensure ad functionality across various formats.\n\n**Enforcement:** Google uses AI and human review to enforce policies, taking actions ranging from disapproving ads to suspending accounts for violations.  Advertisers can appeal decisions.  Compliance with all applicable laws and regulations is mandatory.\n",
    "last_update_summary": "This diff introduces a **new YouTube Shopping Ads Policy page**.\n\n### Summary for Product Manager:\n\nThis diff creates a comprehensive policy framework specifically for **Shopping ads and local inventory ads on Google Merchant Center**, including their promotion on YouTube.\n\n**Key Changes/Additions Introduced by This Policy:**\n\n*   **New Dedicated Policy:** Establishes a standalone policy center for Shopping ads, differentiating it from general Google Ads policies, while noting alignment with them.\n*   **Policy Structure:** Organizes rules into four clear categories:\n    1.  **Prohibited Content:** Content never allowed (e.g., counterfeit goods, dangerous products, inappropriate content).\n    2.  **Prohibited Practices:** Actions never allowed (e.g., abuse of ad network, irresponsible data collection, misrepresentation).\n    3.  **Restricted Content:** Content allowed with limitations (e.g., adult, alcohol, copyrighted, gambling, healthcare, political, trademarks, HFSS food/beverage). These may have geo-restrictions, age-targeting, or pre-authorization requirements.\n    4.  **Editorial and Technical:** Quality standards for ads and websites.\n*   **Enforcement Mechanism:** Details that enforcement uses a combination of Google AI and human evaluation.\n*   **Enforcement Actions:** Specifies actions for violations, including ad disapproval, temporary impression caps, and account suspension for egregious/repeat offenses.\n*   **Appeals Process:** Provides clear paths for advertisers to fix disapproved ads or appeal account suspensions.\n*   **Russia Ad Suspension:** Includes a temporary notice regarding the pausing of ads for advertisers based in Russia due to the war in Ukraine.\n\nThis policy aims to ensure a trustworthy, transparent, and safe advertising ecosystem for users, advertisers, and publishers, while adhering to applicable laws.",
    "last_updated": "2025-07-21T00:28:34.050954Z"
  },
  "instagram-community-guidelines": {
    "policy_name": "Instagram Community Guidelines",
    "initial_summary": "# Competitor Policy Summary:\n\nThis document outlines Meta's Community Standards, encompassing policies for Facebook, Instagram, Messenger, and Threads.  Key areas covered include:\n\n* **Content Moderation:**  Policies define acceptable and unacceptable content, addressing issues like hate speech, violence, harassment, misinformation, and illegal activities.  A three-part enforcement approach (remove, reduce, inform) is used.  Newsworthiness and public interest are considered when evaluating potentially violating content.\n\n* **Account Integrity:** Policies cover authentic identity, inauthentic behavior, and account security.\n\n* **Safety & Well-being:**  Emphasis is placed on user safety, privacy, and dignity.  Specific attention is given to protecting minors, addressing issues like child exploitation and suicide/self-harm.\n\n* **Transparency & Enforcement:**  The document details how Meta detects and addresses policy violations, including technological solutions and human review.  Transparency reports on enforcement, intellectual property, government data requests, and content restrictions are publicly available.\n\n* **Governance & Appeals:**  Information is provided about Meta's Oversight Board, its role in policy appeals, and its impact.\n\n* **Research & Data:** Access to research tools and datasets related to content and advertising is highlighted.\n\n\nThe policy aims to balance freedom of expression with the need to maintain a safe and respectful online environment.  The US English version is considered the primary and most up-to-date document.\n",
    "last_update_summary": "As a Trust & Safety analyst, here is a concise summary of the provided competitor policy page for a product manager:\n\n---\n\n### Instagram Community Guidelines Policy (New Snapshot: 2025-07-21)\n\nThis diff indicates the introduction of a new snapshot of Instagram's (Meta's) Community Guidelines.\n\n**Key Summary Points:**\n\n*   **Comprehensive Scope:** The guidelines apply to all content across Meta's core platforms: Facebook, Instagram, Messenger, and Threads, aiming to provide a consistent framework.\n*   **Core Values:** Policy is explicitly anchored in four key values: **Authenticity, Safety, Privacy,** and **Dignity**, which guide content moderation decisions.\n*   **Balancing Act:** Emphasizes a commitment to free expression while actively preventing abuse. Notes exceptions for \"newsworthy\" content and outlines conditions for content allowed with warnings or age restrictions.\n*   **AI-Generated Content:** Explicitly states that the Community Standards apply to **AI-generated content**, indicating proactive policy alignment with emerging content types.\n*   **Policy Structure:** Each policy section will feature a \"Policy Rationale\" explaining its aims, followed by specific rules for disallowed content or content requiring additional context/restrictions.\n*   **Transparency Hub:** The policy page is part of a larger \"Transparency Center,\" which consolidates information on Meta's policies, enforcement actions, security efforts, governance, research tools, and public reports (e.g., Community Standards Enforcement Report, Widely Viewed Content Report). This signals a strong focus on demonstrating their moderation processes.\n*   **Global Application:** Standards apply universally across all regions and content types.\n\n---",
    "last_updated": "2025-07-21T00:26:54.285675Z"
  },
  "instagram-appeal-process": {
    "policy_name": "Instagram Appeal Process",
    "initial_summary": "Here's a concise summary of Instagram's Oversight Board appeal policy for a Product Manager:\n\n### Instagram Oversight Board Appeal Policy Summary\n\n**Key Points:**\n\n*   **Purpose:** Allows users to appeal Instagram's content decisions (both on their own content or content they reported) to an independent Oversight Board (OB).\n*   **Prerequisite:** Users **must** first exhaust Instagram's internal review process, including two internal reviews of the decision, before becoming eligible to appeal to the OB.\n*   **Appeal Types:**\n    *   Decisions to take down a user's content.\n    *   Decisions not to remove content a user reported.\n*   **Eligibility & Selection:** Not all content decisions are eligible for OB appeal. The OB itself selects only a limited number of eligible appeals for review and may not choose a specific case.\n*   **Timeline:** Appeals to the OB must be submitted within **15 days** of Instagram's final decision.\n*   **Status Check:** Users can track their appeal status on the Oversight Board's website using a reference number.",
    "last_update_summary": "As a Trust & Safety analyst, here's a concise summary of the competitor's new policy page for a Product Manager:\n\n### Instagram's New Oversight Board Appeal Policy\n\nThis new policy page outlines Instagram's formal process for users to appeal content decisions directly to the Oversight Board, expanding the scope of eligible appeals.\n\n**Key Changes/Additions:**\n\n*   **Formalized Appeal Process:** Instagram is clearly documenting how users can appeal content decisions to the Oversight Board.\n*   **Expanded Scope for Appeals:** Users can now appeal two types of decisions:\n    1.  **Content *they posted* that was taken down.**\n    2.  **Content *they reported* from others that was *not* taken down.**\n*   **Two-Tiered Review Requirement:** Before appealing to the Oversight Board, users must first exhaust Instagram's internal \"request a review\" process. This implies they must have gone through two rounds of internal review and still disagree with the decision.\n*   **Time Limit:** Appeals to the Oversight Board must be submitted within 15 days of the decision.\n*   **Oversight Board Discretion:** The Board itself retains the discretion to select which eligible appeals it will review, meaning not all appeals will be heard.\n*   **Transparency:** Users can check their appeal status on the Oversight Board's website using a reference number.\n\nThis page signifies Instagram's commitment to external accountability for content moderation decisions, particularly by extending the appeal mechanism to content that was *not* actioned despite user reports.",
    "last_updated": "2025-07-21T00:26:33.771347Z"
  },
  "instagram-blocking-people": {
    "policy_name": "Instagram Blocking People",
    "initial_summary": "Here's a concise summary of the provided policy text for a Product Manager:\n\n### Instagram \"Blocking People\" Policy Summary\n\nThis policy details Instagram's \"Blocking People\" feature, a core safety and privacy control.\n\n**Key Points:**\n\n*   **Core Functionality:** Explains how users can block and unblock other accounts.\n*   **Impact of Blocking:**\n    *   Removes all past comments and likes from the blocked user.\n    *   Clarifies that a blocked user generally cannot see the blocker's content, message them, or mention them.\n    *   Provides guidance on how to view and manage a list of blocked accounts.\n*   **Related Privacy & Safety Controls:** The document also references other related user controls available in the \"Privacy, Security & Reporting\" section, including:\n    *   Making an account private.\n    *   Removing followers.\n    *   Restricting users (a softer form of control than blocking).\n    *   Temporarily limiting interactions from others.\n    *   Reporting messages or accounts.\n\nThis policy emphasizes user control over their interactions and visibility on the platform.",
    "last_update_summary": "As a Trust & Safety analyst, here's a concise summary of the competitor's new policy page for a product manager:\n\n---\n\n### Competitor Policy Analysis: Instagram's \"Blocking People\" Page\n\n**Source:** Instagram Help Center (New Policy Page)\n**Topic:** Comprehensive guide on user blocking functionalities and related safety controls.\n\n**Key Summary & Implication (from `new file mode` diff):**\n\nThis diff indicates the **introduction of a new, dedicated policy page** on Instagram's Help Center specifically addressing \"Blocking People.\" While it's a new file and not a change to existing content, its presence signifies a clear, centralized resource for users on this critical safety feature.\n\nThe page details various aspects of blocking, including:\n\n*   **Core Blocking Mechanics:** How to block/unblock accounts and manage your blocked list.\n*   **Impact of Blocking:** Clarifies what happens to comments, likes, and mentions when a user is blocked.\n*   **Related Safety Features:** Includes information on associated privacy controls like removing followers, restricting accounts, and temporarily limiting interactions.\n\n**Implication for Product:** This new, comprehensive resource demonstrates a clear emphasis on user control over their interactions and safety, providing transparent information on how blocking and related features function.",
    "last_updated": "2025-07-21T00:26:39.648276Z"
  },
  "instagram-commerce-policies": {
    "policy_name": "Instagram Commerce Policies",
    "initial_summary": "### Competitor Policy Page Analysis: Unavailable Page\n\nThe provided text is an error message from Instagram's Help Center, indicating that a specific page is unavailable.\n\n**Key Points:**\n\n*   **Core Message:** \"This Page Isn't Available.\"\n*   **Reasons for Unavailability:** The page may be unavailable due to a broken link or because it has been removed.\n*   **User Guidance:** Users are advised to check if the link they are trying to open is correct.\n*   **Navigation Options:** The page provides clear calls to action to return to the Help Center Home or go back to the previous page.\n*   **T&S Relevance:** This page demonstrates how a competitor handles missing or removed content (potentially policy or help documentation), which impacts user experience and trust. It emphasizes the need for clear communication and alternative navigation when users encounter inaccessible information.",
    "last_update_summary": "**Trust & Safety Analyst Summary for Product Manager**\n\n**Subject:** Instagram Commerce Policies - July 21, 2025 Snapshot\n\n**Key Changes from Diff:**\n\n*   **Policy Inaccessibility:** A new file snapshot for `instagram-commerce-policies` dated `2025-07-21T002558Z` has been added, but its entire content is a \"This Page Isn't Available\" error page.\n*   **Implication:** This indicates that the Instagram Commerce Policies intended for or captured on July 21, 2025, are now explicitly inaccessible or have been removed/never published at this specific URL. Users attempting to access this particular version of the policies will encounter an error page.\n\n**Impact:** This change signifies that a specific, likely future-dated, version of Instagram's Commerce Policies is not live or accessible as part of their official documentation. This could be due to a policy removal, a delay in publication, or an intentional decision to make certain past/future versions unavailable.",
    "last_updated": "2025-07-21T00:26:46.393738Z"
  },
  "tiktok-blocking-users": {
    "policy_name": "Tiktok Blocking Users",
    "initial_summary": "Here's a concise summary of the competitor's policy page for a Product Manager:\n\n### Competitor Policy Page Summary\n\nThe competitor's policy documentation serves as a comprehensive help center, detailing an exceptionally broad range of platform functionalities, from core features to advanced creator tools and monetization.\n\n**Key Trust & Safety Takeaways:**\n\n*   **Robust User Control & Safety Tools:** A significant focus is placed on empowering users with safety mechanisms. Detailed instructions for blocking (individual users, multiple users from comments, unblocking) are prominently featured, alongside mentions of a \"Safety Center,\" \"Community Guidelines,\" and \"Report a problem\" functionality.\n*   **Comprehensive Feature & Content Coverage:** The policies span an extensive array of content types and features including user-generated videos, AI-generated content, creator tools, live streaming, e-commerce (\"TikTok Shop\"), messaging, and content discovery, indicating a complex ecosystem requiring broad T&S oversight.\n*   **Creator Monetization & Ecosystem:** Policies extend to creator monetization features (LIVE, Gifts, promotion tools), necessitating guidelines for commercial activities, fraud prevention, and responsible content creation related to earning.\n*   **Legal & Policy Framework:** The document points to a foundational set of legal and policy resources, including Terms of Use, Privacy, Copyright, and Law Enforcement guidelines, signifying a structured approach to compliance and trust.\n*   **Algorithmic Transparency & Global Reach:** It touches on content recommendation algorithms (\"How TikTok recommends content\") and highlights a vast global operational scope through an extensive list of supported languages, implying a need for culturally nuanced and legally compliant T&S policies worldwide.",
    "last_update_summary": "**Subject: New TikTok Help Center Policy Page: User Blocking Functionality**\n\n**Key Changes Based on this Diff:**\nThis diff represents the *introduction* of a new help center page titled \"Blocking someone\" (`tiktok-blocking-users/2025-07-21T002543Z.html`). This is not an update to an existing page, but rather the creation of a new resource for users.\n\n**Summary for Product Manager:**\nThis new policy page on TikTok's Help Center provides comprehensive guidance on the platform's user blocking functionality. It details:\n*   **Definition of Blocking:** Explains that blocking prevents users from viewing posts and engaging via direct messages, comments, follows, or likes.\n*   **How to Block/Unblock (Individual):** Step-by-step instructions for single-user blocking and unblocking via their profile.\n*   **How to Block Multiple Users (from Comments):** A significant addition is the clear instruction on how to block multiple users simultaneously by managing comments on a video (via \"Manage multiple comments\" or \"Filters\"), which streamlines moderation for creators.\n\n**Implications:**\nThis new page enhances user education on safety features and improves clarity on managing unwanted interactions. The inclusion of bulk-blocking instructions from comments is particularly beneficial for creators, offering a more efficient tool for content moderation and maintaining a positive community environment.",
    "last_updated": "2025-07-21T00:27:02.331422Z"
  },
  "youtube-hiding-users": {
    "policy_name": "Youtube Hiding Users",
    "initial_summary": "As a Trust & Safety analyst, here is a concise summary of the provided policy document on YouTube's \"Hide users from your channel\" feature for a Product Manager:\n\n---\n\n### YouTube: \"Hide Users from Your Channel\" Policy Summary\n\nThis policy outlines a channel moderation feature allowing content creators to control who can interact with their content.\n\n**Key Functionality:**\n\n*   **Purpose:** Channel owners can \"hide\" specific viewers to prevent their comments from appearing on the channel and to stop them from creating clips from videos or live streams.\n*   **Impact on Hidden User:**\n    *   All previous comments from the hidden user on the channel will be hidden within 48 hours.\n    *   Future comments from the hidden user will not appear.\n    *   The hidden user will **not** receive a notification that they have been hidden.\n*   **Methods to Hide:**\n    1.  **From a Comment:** Select \"More\" next to a user's comment, then \"Hide user from channel.\"\n    2.  **Via YouTube Studio:** In \"Settings\" > \"Community\" > \"Automated Filters,\" paste the user's channel URL into the \"Hidden users\" box.\n*   **Managing Hidden Users:**\n    *   A list of hidden users is available in YouTube Studio under \"Settings\" > \"Community\" > \"Automated Filters.\"\n    *   Users can be \"shown\" (unhidden) from this list, which allows their *future* comments to appear. Previous comments remain hidden.\n*   **Scope:** This is a **channel moderation tool** for managing audience interaction. It is distinct from reporting abuse, harassment, or policy violations, which should be directed to the Safety Center.\n\n---",
    "last_update_summary": "This diff indicates the *creation* of a new policy page titled \"Hide users from your channel.\"\n\n### Summary for Product Manager:\n\nThe new policy page outlines a feature allowing channel owners to \"hide\" specific users.\n\n**Key Features:**\n\n*   **Comment Moderation:** Hiding a user prevents their comments from appearing on the channel, including the YouTube Studio Comments page. All *previous* comments from that user will be hidden within 48 hours.\n*   **Clip Prevention:** Hidden users are prevented from creating clips from the channel's videos or live streams.\n*   **User Experience:** Hidden users are *not* notified when they are hidden.\n*   **Unhiding:** Channel owners can \"unhide\" users, which will allow *future* comments to appear, but *previous* hidden comments remain hidden.\n*   **Management:** Users can be hidden directly from a comment or by adding their channel URL to a \"Hidden users\" list within YouTube Studio (Settings > Community). This list also allows owners to review and remove hidden users.",
    "last_updated": "2025-07-21T00:28:28.846072Z"
  }
}