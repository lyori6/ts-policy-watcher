{
  "tiktok-community-guidelines": {
    "policy_name": "Tiktok Community Guidelines",
    "initial_summary": "## TikTok Competitor Community Guidelines Summary\n\nThis document outlines a comprehensive set of community guidelines for a TikTok-like platform, effective May 17, 2024.  Key areas covered include:\n\n* **Content Moderation:**  The platform employs a three-pronged approach: removing violating content, restricting age-inappropriate content (for users under 18), and making ineligible for recommendation (For You feed) content that doesn't meet platform standards.\n\n* **Prohibited Content:**  A wide range of prohibited content is detailed, encompassing: violence, hate speech, sexual abuse, harassment, self-harm, dangerous activities, misinformation, scams, regulated goods (alcohol, firearms, etc.), and violations of privacy and security.  Specific examples are provided within each category, though the document notes that these are not exhaustive.\n\n* **Community Empowerment:** The platform provides users with tools and resources to manage their experience, including safety settings, filtering options, and reporting mechanisms.\n\n* **Enforcement:** While the specifics of enforcement aren't detailed, the document implies a combination of automated and human moderation to address policy violations.\n\nThe guidelines aim to create a safe and welcoming environment while balancing creative expression and the prevention of harm.  The full guidelines are categorized for easier navigation, with additional information and examples available for each section.\n",
    "last_update_summary": "Here's a concise summary of the competitor's (TikTok's) new Community Guidelines policy for a Product Manager:\n\n### Competitor Policy Update: TikTok Community Guidelines (Effective May 17, 2024)\n\nThis diff introduces TikTok's updated Community Guidelines, effective May 17, 2024. The document outlines a comprehensive framework for content moderation, emphasizing user safety, well-being, and platform integrity.\n\n**Key Highlights & Changes:**\n\n*   **Holistic Content Moderation Strategy:** The policy explicitly details a multi-layered approach beyond simple removal, including:\n    *   **Remove:** Content violating rules (public or private).\n    *   **Restrict:** Content not suitable for youth (18+ only).\n    *   **Make Ineligible for FYF:** Content not meeting recommendation standards (a distinct category from outright violations).\n    *   **Empower:** Users with information, tools (labels, opt-in screens, warnings), and safety resources.\n*   **Structured & Detailed Categories:** The guidelines are organized into clear, actionable sections, with bolded rules and \"More information\" links for definitions and examples.\n*   **Emphasis on Specific Harms:** Dedicated sections and sub-categories highlight increased focus on:\n    *   **Youth Safety & Well-Being:** A top-level section alongside general safety.\n    *   **Separation of Abuse Categories:** Distinct sections for \"Youth Sexual and Physical Abuse\" and \"Adult Sexual and Physical Abuse.\"\n    *   **Emerging Harm Types:** Specific callouts for \"Disordered Eating and Body Image\" and \"Dangerous Activity and Challenges.\"\n    *   **AI-Generated Content (AIGC):** A new sub-category under \"Integrity and Authenticity\" for \"Edited Media and AI-Generated Content (AIGC),\" indicating a proactive stance on new media forms.\n    *   **Unoriginal Content:** A specific category addresses content that lacks originality.\n    *   **Frauds and Scams:** Included under Regulated Goods and Commercial Activities.\n*   **Clear FYF Eligibility Standards:** A dedicated top-level section (\"For You feed Eligibility Standards\") signifies clear distinction between content violations and content unsuitable for broad recommendation.\n*   **Transparency in Enforcement:** A dedicated \"Enforcement\" section outlines \"Public Interest Exceptions,\" \"Detection and Reporting\" mechanisms, and \"Notice and Appeals\" processes, indicating a commitment to due process.\n*   **Application to Features:** Guidelines extend to specific platform features like TikTok LIVE, Search, External Links, Comments/Direct Messages, and Monetization.\n\n**Implication for Product:** This comprehensive policy demonstrates a strong focus on granular content moderation, user-empowerment tools, and addressing emerging risks like AIGC. It also clearly separates content that is outright prohibited from content that is merely restricted or ineligible for recommendation, which could influence product features related to content filtering, age-gating, and algorithmic distribution.",
    "last_updated": "2025-07-22T00:27:54.057444Z"
  },
  "tiktok-live-moderation": {
    "policy_name": "Tiktok Live Moderation",
    "initial_summary": "# TikTok LIVE Moderation Policy Summary\n\nThis document details TikTok's approach to content moderation during LIVE streams.  Key features include:\n\n* **Creator Controls:** Creators can add moderators, control audience age (18+), filter comments, block keywords, mute, and block viewers directly from the LIVE settings or chat.  This applies to both mobile app and web browser access (via LIVE Studio or OBS Studio for broadcasting; not required for moderation).\n\n* **Moderator Permissions:** Moderators, granted permission by the creator, can mute, block viewers, and report comments violating Community Guidelines.  The level of control a moderator has is determined by the creator.\n\n* **User Actions:**  Viewers can be reported, muted (temporarily), or blocked (preventing future LIVE viewership and other interactions with the creator).  Notifications are sent to muted/blocked users.\n\n* **Accessibility:** Moderation tools are accessible both within the LIVE settings and directly from the LIVE chat interface on both the mobile app and web browser.\n",
    "last_update_summary": "This document outlines TikTok's comprehensive policy for moderating LIVE streams, detailing the tools available to both creators and their assigned moderators.\n\n### TikTok LIVE Moderation Policy Overview (2025-07-22)\n\nThis new policy page defines the roles and functionalities for managing viewer behavior and comments during TikTok LIVE streams.\n\n**Key Moderation Capabilities:**\n\n*   **For Creators & Moderators:**\n    *   **Report:** Flag viewer comments for violations.\n    *   **Mute:** Temporarily prevent a viewer from commenting. Viewers are notified and remain muted until the duration expires or they are unmuted.\n    *   **Block:** Permanently prevent a viewer from watching the LIVE and interacting with the creator's content (posts, profile, DMs). Viewers are notified and cannot watch the current or future LIVEs of that creator unless unblocked.\n    *   **Comment Settings:** Filter comments, block specific keywords and their variations.\n*   **For Creators Only:**\n    *   **Moderator Management:** Add or remove moderators before or during a LIVE.\n    *   **Audience Controls:** Restrict the LIVE to viewers 18 years or older.\n*   **Moderator Permissions:** Creators grant specific permissions to moderators, allowing them to manage comment settings and blocked/muted account lists.\n\n**Access & Workflow:**\n\n*   **TikTok App:** Moderation tools are accessible from LIVE settings (before starting) and directly from the LIVE chat (during the stream).\n*   **Web Browser:** Tools are available via the LIVE chat panel's settings or by clicking on a viewer's profile/comment.\n\n**Key Takeaway for Product:**\n\nTikTok emphasizes granular control for creators and empowers designated moderators with significant capabilities (muting, blocking, reporting, comment management). The policy clearly defines the immediate and communicated impact of moderation actions on viewers (notifications for mute/block, comprehensive blocking). This level of detail and control could inform our own LIVE moderation feature development and policy.",
    "last_updated": "2025-07-22T00:28:01.807079Z"
  },
  "tiktok-shop-prohibited-products": {
    "policy_name": "Tiktok Shop Prohibited Products",
    "initial_summary": "## Competitor Policy Summary: TikTok Shop Academy (US)\n\nThis document appears to be incomplete or broken.  The provided text only shows a heading related to boosting sales on TikTok Shop Academy and a JavaScript error message.  **No actual policy information is present.**  Therefore, no meaningful summary of their policy can be provided.  Further investigation is needed to obtain the actual policy document.\n",
    "last_update_summary": "**Summary for Product Manager: Competitor Policy Page Analysis**\n\nThis diff indicates the creation of a *new file* for a competitor's \"prohibited products\" policy page (dated 2025-07-20).\n\n**Key Changes:**\n\n*   **New Page Created:** A new policy page `tiktok-shop-prohibited-products` has been added.\n*   **Placeholder Content:** The page's content is currently a generic \"JavaScript not enabled\" message, suggesting it's an unpopulated placeholder or a technical error page, rather than an active policy.\n*   **No Policy Content Detected:** There are no actual policy rules or guidelines present in this version of the page.\n\n**Impact:**\n\nCurrently, there is no substantive policy information to analyze. This appears to be a technical setup or placeholder for a future policy page. We should monitor this URL for updates to identify actual policy content when it becomes available.",
    "last_updated": "2025-07-20T23:50:56.579760Z"
  },
  "whatnot-blocking-a-user": {
    "policy_name": "Whatnot Blocking A User",
    "initial_summary": "## Whatnot User Blocking Policy Summary\n\nThis document details Whatnot's user blocking functionality.  Users can block others to prevent:\n\n* Following\n* Direct messaging\n* Profile viewing\n* Livestream interaction (bookmarking, joining, chatting)\n* Future purchases from listings\n\nExisting orders are unaffected by blocking.  Blocking is currently permanent.  There's no list of blocked users.  Being removed from a livestream is different from being blocked by a user.  Users can report violations of Community Guidelines separately.\n",
    "last_update_summary": "## Whatnot: Blocking a User Policy Analysis\n\n**Summary for Product Manager:**\n\nThis new policy page outlines Whatnot's user blocking feature, detailing its functionality and user experience.\n\n**Key Functionality & Impact:**\n\n*   **Comprehensive Blocking:** Users can block others to prevent them from:\n    *   Following them.\n    *   Direct messaging within the app.\n    *   Viewing their profile.\n    *   Bookmarking, joining, or chatting in their livestreams.\n    *   Making *future* purchases from their marketplace listings (existing orders are honored).\n*   **Distinction from Bans:** The policy clarifies that blocking is different from being temporarily removed from a livestream by a host or mod.\n*   **User Action:** Blocking is done via the three-dot menu on a user's profile.\n*   **Unblocking Capability:** Users *can* unblock someone by searching for their profile and selecting \"Unblock.\"\n*   **Current Limitation:** There is currently no central list for users to view all the accounts they have blocked. The policy notes that without such a list, blocking is \"permanent\" in the sense that managing multiple blocks can be difficult, not that the block itself cannot be undone.\n\n**Key Changes based on this Diff:**\n\nThis diff represents the **introduction of a *new* policy page** detailing the \"Blocking a User\" feature. There are no incremental changes to an existing document. The significance is that Whatnot has now formally documented and published its user blocking capabilities and how they function.",
    "last_updated": "2025-07-22T00:28:08.475266Z"
  },
  "whatnot-buyer-protection": {
    "policy_name": "Whatnot Buyer Protection",
    "initial_summary": "# Whatnot Buyer Protection Policy Summary\n\n**Key Points:**\n\n* **Refund Eligibility:** Whatnot offers buyer protection for incomplete/incorrect items, items not as described/inauthentic, and packages not received.  Refunds are generally granted within 30 days of purchase or 14 days of delivery (7 days for certain categories like coins, sneakers, luxury goods; 2 days for plants).  Whatnot may require item return in original condition.  German buyers pay return shipping.\n\n* **Refund Exclusions:**  Consumables (opened/consumed items, breaks except for missing/damaged items), tips, refused deliveries, uncollected packages, unpaid customs fees, exchange rate losses, chargebacks, digital content, off-platform transactions, and instances of suspected fraud are excluded.  Returning the wrong item also voids a refund.\n\n* **Time Limits & Exceptions:**  Specific shorter deadlines apply for certain high-value categories and counterfeit claims (30 days from receipt). Extensions may be granted for international orders, pre-orders, custom orders, and due to natural disasters.  \"Delivered\" but not received items require contact within 14 days.\n\n* **EU/UK Right of Withdrawal:** EU/UK buyers have a 14-day right of withdrawal, requiring item return within 14 days of cancellation.  Buyers are responsible for return shipping costs. This right doesn't apply to breaks, surprise products, or certain unsuitable goods (hygiene, mixed, sealed software/media, customized items, perishable goods).\n\n\n* **High-Value Loss Reimbursement:** A separate policy exists for high-value card losses in breaks, potentially reimbursing market value.\n\n",
    "last_update_summary": "This document introduces Whatnot's comprehensive **Buyer Protection Policy**, effective May 16, 2025. It outlines the conditions under which buyers are eligible for refunds for purchases made on the platform.\n\n**Key Components & Changes Introduced:**\n\n*   **Covered Issues:** Buyers are entitled to refunds for `incomplete/incorrect items`, `items not as described or inauthentic` (damaged, expired, defective, counterfeit), and `packages not received` (lost, delayed, misdelivered). A detailed list of covered issues is provided.\n*   **Refund Request Timelines:**\n    *   **General:** Submit requests within the **earlier of 30 days from purchase or 14 days from delivery**.\n    *   **Category-Specific:**\n        *   **7 days from delivery or 30 days from purchase (earlier of):** Coins & Money, Sports Cards, Sneakers & Streetwear, Trading Card Games, Luxury Goods.\n        *   **2 days from delivery or 30 days from purchase (earlier of):** Plants.\n    *   **Counterfeit Claims:** Must be submitted within **30 days of receiving the order**.\n    *   **\"Marked Delivered, Not Received\":** Contact support within **14 days** of delivery scan.\n*   **Return Requirements:** Whatnot may require item returns in the same received condition. Opening products or removing tags may disqualify or reduce refunds. For Germany, return shipping costs will be deducted from the refund.\n*   **Key Exclusions from Protection:** Refunds are **not** provided for:\n    *   Most `consumable products` once opened/consumed (except for missing/damaged items in \"Breaks\").\n    *   `Tips` to sellers.\n    *   `Refusing delivery` or `failing to pick up` packages.\n    *   `Refusal to pay customs fees` or duties paid.\n    *   `Exchange rate fluctuations`.\n    *   `Orders disputed with financial institutions` (chargebacks).\n    *   `Digital Content`.\n    *   `Potential fraud or abuse of policy` (at Whatnot's discretion).\n    *   `Returning an incorrect item`.\n    *   `Off-platform transactions`.\n*   **Special Policies:**\n    *   **High Value Loss Reimbursement:** Specific policy referenced for missing Sports Cards/Trading Cards in \"Breaks\" based on market value.\n    *   **EU/UK Right of Withdrawal:** Consumers from professional sellers have a statutory right to cancel within 14 days of receipt and return items within 14 days of cancellation, subject to specific conditions and exclusions (e.g., no refunds for \"Breaks\" or \"Surprise Products\", unsealed hygiene items, customized goods). Return shipping costs are the buyer's responsibility.\n\nThis policy emphasizes a structured approach to buyer protection with clear timelines, exclusions, and specific handling for various item categories and international regions.",
    "last_updated": "2025-07-22T00:28:19.690967Z"
  },
  "whatnot-enforcement-actions": {
    "policy_name": "Whatnot Enforcement Actions",
    "initial_summary": "## Whatnot's Trust & Safety Policy: Summary for Product Managers\n\nWhatnot's policy enforces Community Guidelines with penalties escalating based on violation severity and account history.  Violations are cumulative, meaning repeated offenses, even minor ones, can lead to a permanent ban.\n\n**Key Actions & Penalties:**\n\n* **Warnings:** For minor infractions, with guidance provided.\n* **Suspensions:** Temporary account access loss (2 or 7 days).\n* **Selling Access Revoked:**  Loss of ability to sell or go live.\n* **Ban:** Permanent account termination for serious or repeated violations.\n* **Discovery Restriction:** Temporary reduced visibility in feeds/recommendations.\n* **Other Penalties:** Loss of access to features like Direct Messages.\n\n**Account Health & Performance:**\n\n* An Account Health dashboard tracks Seller Performance Rates (fulfillment, shipping) and Policy Standing.\n* Poor performance in either area can result in warnings and penalties.\n* Policy Standing has five levels (Excellent, Good, Fair, Poor, Very Poor), reflecting penalty history.\n\n**Violation Expiration:**\n\n* Most violations expire after 180 days, except for bans and offboarding, which are permanent.\n\n**Appeals:**  Users can appeal penalties via email.\n",
    "last_update_summary": "As a Trust & Safety analyst, here is a concise summary of the new policy page for a Product Manager:\n\n### **New Policy: What Actions We Take (2025-07-22)**\n\nThis document introduces a new, detailed policy outlining Whatnot's enforcement actions for Community Guidelines violations, aiming for transparency and a trusted platform.\n\n**Key Changes (as this is a new file):**\n\n*   **Formalized Enforcement Framework:** Establishes a clear, graduated system of penalties for policy violations.\n*   **Tiered Penalties:** Outlines a progression of consequences:\n    *   **Warning:** Guidance on policy.\n    *   **Suspension:** Temporary account access loss (2 or 7 days).\n    *   **Revoke Selling Access:** For sellers.\n    *   **Ban:** Permanent account removal for serious/repeated violations.\n    *   **New \"Discovery Restricted\" Penalty:** Temporarily reduces account visibility in Feeds/Recommendations, allowing users to improve compliance without full suspension. This is a notable addition impacting product discoverability.\n    *   **Other Penalties:** Loss of features (e.g., DMs), ongoing investigation suspensions.\n*   **Cumulative Violations:** Emphasizes that even less severe violations contribute to a user's Trust & Safety record and can lead to eventual bans.\n*   **Account Health Integration:** Introduces \"Policy Standing\" states (Excellent, Good, Fair, Poor, Very Poor) directly linked to the penalty tiers, visible in the Account Health dashboard (Beta).\n*   **Seller Performance Link:** Explicitly states that consistent underperformance in Fulfillment Success Rate or On Time Shipment Rate can lead to warnings and penalties.\n*   **Violation Expiry & Appeals:** Most violations expire after 180 days, with clear instructions for appeals.\n\n**Impact for Product:**\n\nThis policy provides clear guidelines for user behavior and outlines the consequences within the product, particularly the new \"Discovery Restricted\" state which directly impacts user experience and discoverability without a full ban. It also reinforces the value of the Account Health Dashboard for seller self-management.",
    "last_updated": "2025-07-22T00:28:26.761407Z"
  },
  "whatnot-hate-and-harassment": {
    "policy_name": "Whatnot Hate And Harassment",
    "initial_summary": "## Whatnot Hate and Harassment Policy Summary\n\nThis policy prohibits hateful conduct and harassment on the Whatnot platform, including sexual harassment and off-platform abuse that impacts the Whatnot community.  Key prohibited behaviors include:\n\n* **Harassment:**  Repeated unwanted contact, personal attacks, targeted obscene language,  using contact information for non-transactional purposes, and disparaging others (sellers disparaging buyers in streams, for example).  Exceptions may be made for newsworthy events or public figures.\n\n* **Threats & Harmful Wishes:** Wishing harm, making threats (implied or explicit), and exposing someone's sexual orientation or gender identity without consent.\n\n* **Sexual Harassment:** Unwanted sexual advances, objectification, degrading comments about sexual practices, sharing intimate images without consent.\n\n* **Hateful Conduct:** Any behavior promoting violence or hatred based on protected characteristics (race, ethnicity, religion, gender, sexual orientation, etc.). This includes using slurs (unless used self-referentially and with clearly indicated positive intent), supporting hate groups, and displaying hateful symbols (with exceptions for historical context, like pre-1933 artifacts). Specific allowances are made for the Confederate battle flag under very specific historical and non-hateful contexts.\n\n* **Off-Platform Abuse:**  Whatnot may take action against users coordinating harassment or hate off-platform that impacts the Whatnot community, even in rare instances where the off-platform behavior poses a significant threat to the platform.\n\nEnforcement actions against accounts may include removal.  The severity and persistence of the behavior are considered when evaluating violations.\n",
    "last_update_summary": "As a Trust & Safety analyst, here's a summary of the provided competitor policy for a Product Manager:\n\n### Whatnot Hate and Harassment Policy - Summary for Product Manager\n\n**Key Change from Diff:**\nThis diff represents the *introduction* of a new, comprehensive **Hate and Harassment Policy** by Whatnot, dated August 21, 2024. This is not an update to an existing policy, but rather the establishment of formal guidelines on these critical safety topics.\n\n**Policy Overview:**\nWhatnot has established a clear and strict policy prohibiting hateful conduct and harassment to foster a safe and respectful environment. Violations may result in account actions, including removal.\n\n**Key Prohibited Behaviors:**\n\n1.  **Harassment:** Content or patterns of behavior that demean or threaten individuals.\n    *   **Unwanted Conduct & Contact:** Targeting individuals with dedicated accounts, repeated obscene/insulting language, continued contact after being asked to stop, or misuse of contact information.\n    *   **Personal Attacks & Repeated Disparagement:** Attacks based on appearance, hygiene, intellect, personality; targeting with negative doctored content; sellers disparaging buyers/others in streams; or repeated/extended disparagement across multiple streams/DMs (e.g., questioning reliability, \"exposing\" others). *Note: Exceptions for newsworthy events or public figures.*\n    *   **Threats & Harmful Wishes:** Wishing death, disease, or physical harm; implied/hypothetical threats; exposing sexual orientation/gender identity without consent; or glorifying/endorsing traumatic events (self-injury, eating disorders, medical history).\n\n2.  **Sexual Harassment:** Unwanted sexual advances, sexual objectification, or degrading attacks about an individual\u2019s sexual practices.\n    *   **Unwanted Romantic Approaches:** Sexual objectification (comments on body parts, encouraging adult content, asking for sexually suggestive poses).\n    *   **Disparagement:** Based on perceived sexual practices or morality (of person or family member).\n    *   **Image/Audio Misuse:** Sharing or threatening to share intimate images/audio without consent; threats, blackmail, or forced coercion for intimate images.\n\n3.  **Hateful Conduct:** Behavior promoting violence or hatred based on protected characteristics (race, ethnicity, color, caste, national origin, immigration status, religion, sex, gender, gender identity, sexual orientation, disability, serious medical condition, veteran status).\n    *   **General:** Intolerance, hatred, subjugation, sexualizing, demeaning, dehumanizing, or suggesting inferiority against protected groups.\n    *   **Specific Examples:** Mimicking race to mock, encouraging violence/harm, mocking/celebrating/denying hate crimes, racial slurs (with allowance for clearly self-referential/positive use), support for known hate groups/ideologies, harmful stereotypes/theories.\n    *   **Hateful Images/Symbols:** Prohibits symbols from known hate organizations, Nazi propaganda, Swastikas (with specific historical exceptions), grotesque/derogatory Black Americana (e.g., Gollywog dolls, blackface), and live/recorded blackface/yellowface/redface/brownface.\n    *   **Confederate Battle Flag Nuance:** Permitted only if historically accurate miniatures/models, artistic denunciation, or on book/video game covers without hateful context.\n\n4.  **Off-Platform Abuse:**\n    *   **Coordination:** Action may be taken if verifiable evidence exists of off-platform coordination of harassment or hate *to occur on Whatnot* (e.g., encouraging followers to send hateful messages, creating fake accounts for insult/impersonation).\n    *   **Severe Off-Platform Behavior:** In rare instances, action may be taken for verifiable hate/harassment occurring off-platform if it poses a significant threat to the Whatnot community or individuals, considering severity and persistence.\n\nThis policy outlines a comprehensive framework for addressing harmful behaviors, including detailed examples and specific nuances for visual content and off-platform conduct.",
    "last_updated": "2025-07-22T00:28:34.642708Z"
  },
  "whatnot-how-to-report": {
    "policy_name": "Whatnot How To Report",
    "initial_summary": "## Whatnot User Reporting and Investigation Policy Summary\n\n**Key Points:**\n\n* **Reporting Methods:** Users can report suspicious behavior via in-app reporting features during livestreams, in direct messages (DMs), on product listings, or user profiles (Android & Web).  Email reports to trustandsafety@whatnot.com are also accepted.  All reports are anonymous.\n* **Reporting Locations:** Reporting options are available within livestreams (for buyers and sellers), in-live chat, DMs, product listings, and user profiles (Android/Web).\n* **Investigation Process:** Whatnot's Trust & Safety team investigates reports, analyzing data, reviewing livestreams, and potentially temporarily suspending users during investigations. Outcomes are not publicly disclosed.\n* **Proactive Monitoring:**  The Trust & Safety team proactively investigates potential policy violations based on data analysis and community reports, taking action against users exhibiting patterns of abuse.\n\n",
    "last_update_summary": "As a Trust & Safety analyst, here's a concise summary of the competitor's new policy page for a product manager:\n\n---\n\n### **Whatnot: How To Report A User & How We Investigate Policy - Summary for PMs**\n\n**Overview:**\nThis new policy page from Whatnot outlines a comprehensive user reporting system and their internal investigation process, emphasizing user anonymity and proactive safety measures.\n\n**Key Information:**\n\n1.  **Multiple Reporting Channels:** Users can report directly within the platform:\n    *   **During a Livestream:** Via user's username (for buyers, live sellers, or chat participants).\n    *   **In Direct Messages (DMs):** Via the \"More Options\" menu.\n    *   **On a Product Listing:** To report a seller or the listing itself.\n    *   **On User's Profile:** (Android and Web only).\n    *   **Email:** `trustandsafety@whatnot.com` for general reports or when unsure.\n2.  **Anonymity:** All user reports are explicitly stated to be anonymous.\n3.  **Investigation Process:**\n    *   Whatnot's Trust & Safety team investigates reports by reviewing facts, relevant history/data, and livestreams.\n    *   Reported users may face temporary suspension of features (e.g., ability to go live) during an investigation.\n    *   Outcomes of individual investigations are not disclosed due to privacy.\n4.  **Proactive Monitoring:** The Trust & Safety team also initiates investigations proactively based on data analysis and community reports, actively monitoring seller/buyer data for patterns of policy abuse and taking action when evidence is found.\n\n**Key Changes Based on This Diff:**\nThis diff represents the **introduction** of a dedicated, detailed policy page for \"How To Report A User & How We Investigate.\" This signifies Whatnot's formalization and public communication of their user reporting mechanisms and the internal review process, moving towards greater transparency and setting clear expectations for user safety and enforcement.\n\n---",
    "last_updated": "2025-07-22T00:28:40.500535Z"
  },
  "whatnot-moderator-guidelines": {
    "policy_name": "Whatnot Moderator Guidelines",
    "initial_summary": "## Whatnot Moderator Guidelines Summary\n\n**Key Points:**\n\n* **Goal:** Maintain a safe and fun marketplace by empowering moderators to manage livestream chats effectively.  Moderation should be fair and unbiased, prioritizing community safety and a positive user experience.\n\n* **Moderator Responsibilities:**\n    * Remove users only for violations of Community Guidelines or at the seller's request.  Avoid banning users for differing opinions.\n    * Maintain a respectful and engaging chat environment.\n    * Address inappropriate messages promptly, escalating to warnings before bans.\n    * Seek seller feedback.\n\n* **Moderator Privileges:**\n    * Remove users from a specific livestream (not a platform-wide ban).\n    * View muted chat messages.\n\n* **Adding/Removing Moderators:** Sellers can add moderators during or before a livestream via the scheduling section or by selecting the \"Allow to Moderate\" option from a user's chat profile.  Removal is done similarly using the \"Remove Moderator\" option.\n\n* **Underlying Principle:**  Moderation should be proactive and fair, guided by Whatnot's Community Guidelines and a principle of leading by example, not force.\n",
    "last_update_summary": "### Whatnot - New Moderator Guidelines Policy (2025-07-22)\n\n**Summary of Key Changes (New Policy Introduced):**\n\nThis diff indicates the **creation** of a comprehensive \"Moderator Guidelines\" policy for Whatnot. As a `new file`, it establishes the foundational expectations and procedures for livestream moderators, where none were formally documented in this manner before.\n\n**Core Aspects of the New Policy:**\n\n*   **Purpose:** To make Whatnot the \"safest P2P marketplace\" by providing clear guidance for local moderators. The overarching principle is to \"lead by example, not by force,\" ensuring unbiased actions and compliance with Whatnot's Community Guidelines.\n*   **Moderator Expectations:**\n    *   Avoid abuse of power; only remove/report users if actions warrant it or if the seller requests.\n    *   **Do not ban users for mere disagreement or opinions.**\n    *   Maintain an unbiased stance to keep communities safe.\n    *   Primary responsibility in chat is to ensure content standards and address offending users/spam.\n*   **Best Practices Emphasized:**\n    *   Treat all users with respect and without bias.\n    *   Engage with chat and answer user questions.\n    *   Delete inappropriate messages promptly.\n    *   **Crucially, \"Issue a verbal warning first and do not ban users without a valid cause.\"**\n*   **Moderator Privileges:**\n    *   **Remove Users From Show:** Removes a user *only from the current livestream*. This action **does not ban them from Whatnot** or prevent them from joining future streams from the same seller.\n    *   **View Muted Chat Messages:** Allows moderators to see messages that are hidden from regular users due to global settings or the seller's \"Muted Words\" list.\n*   **Management:** Provides clear instructions for sellers on how to add and remove moderators both before and during a livestream.\n\n**Implication for Product Managers:**\n\nThis new policy signals Whatnot's commitment to a structured and responsible approach to user-led moderation. The emphasis on unbiased action, verbal warnings before bans, and the limited scope of the \"Remove from Show\" privilege suggests a focus on fostering community and maintaining a less punitive environment, while still empowering sellers with tools to manage their immediate livestream experience. The ability for mods to view muted messages provides a critical layer for content oversight.",
    "last_updated": "2025-07-22T00:28:51.105342Z"
  },
  "youtube-community-guidelines": {
    "policy_name": "Youtube Community Guidelines",
    "initial_summary": "## YouTube's Trust & Safety Policy Summary:\n\nThis document outlines YouTube's approach to content moderation, creator support, and combating abuse.  Key points include:\n\n* **Content Moderation:**  YouTube uses automated systems and human reporting to identify and remove content violating Community Guidelines and Advertiser-Friendly Content Guidelines. Exceptions are made for content with clear educational, documentary, scientific, or artistic value (EDSA).\n\n* **Creator Support:**  The YouTube Partner Program (YPP) offers revenue sharing to eligible creators who meet stricter content standards.  Creators have tools to manage comments and their channel's community interactions.  YouTube provides resources to support creator privacy and safety.\n\n* **Combating Abuse:** YouTube actively works to remove content promoting violent extremism or criminal organizations, collaborating with government entities and organizations like the GIFCT.\n\n* **Appeals Process:** Creators can appeal decisions regarding content removal or YPP suspension.\n\n\n",
    "last_update_summary": "As a Trust & Safety analyst, here's a summary of the new policy page for a product manager:\n\n---\n\n## Competitor Policy Page Analysis: YouTube Community Guidelines (New Page)\n\nThis diff indicates the **introduction of a new, comprehensive policy page** titled \"Our Policies\" on YouTube's \"How YouTube Works\" microsite. This page serves as a central hub outlining their approach to content moderation, creator support, and industry partnerships.\n\n### Key Aspects Introduced by This New Policy Page:\n\n*   **Core Philosophy:** Reinforces YouTube's mission of openness and free expression while emphasizing the need for a \"responsible business\" that viewers, creators, and advertisers can trust.\n*   **Policy Mechanisms Explained:**\n    *   **Community Guidelines:** Focus on content integrity and user safety, with content flagged by a mix of automated detection and human review. Explicitly mentions **EDSA (Educational, Documentary, Scientific, or Artistic) exceptions**.\n    *   **Advertiser-Friendly Content Guidelines:** Focus on brand safety and apply specifically to creators in the YouTube Partner Program (YPP) for monetization eligibility.\n    *   **Appeals Process:** Highlights the importance of the appeals system for creators disagreeing with content removal or YPP suspension decisions.\n*   **Creator Support & Responsibility:**\n    *   Details the **YouTube Partner Program (YPP)** as a revenue-sharing model that incentivizes creators to adhere to policies (requiring a \"higher bar\" for eligibility and ongoing adherence).\n    *   Showcases **Creator Tools** designed for self-management, including:\n        *   Channel Guidelines (setting conversation norms).\n        *   Comment Moderation (holding inappropriate comments, blocking users/words).\n        *   Privacy & Safety Resources.\n*   **Combating Abuse through Partnerships:**\n    *   States a clear prohibition on content promoting violent extremist or criminal organizations, relying on government/international designations.\n    *   Highlights **collaboration with industry experts**, specifically mentioning YouTube's role as a founding member of the **Global Internet Forum to Counter Terrorism (GIFCT)** to combat terrorist content across the web.\n*   **Transparency & Further Reading:** Links to related blog posts regarding new tools (e.g., AI-generated content disclosure, responsible AI tools), demonstrating ongoing efforts and transparency in policy evolution.\n\n**For a Product Manager:** This new page centralizes and clarifies YouTube's multi-layered approach to Trust & Safety, balancing free expression with platform integrity and monetization needs. It underscores the importance of both automated and human review, creator accountability, and strategic external partnerships in maintaining a healthy content ecosystem. It also highlights an emphasis on providing creators with tools to manage their own content and communities.",
    "last_updated": "2025-07-22T00:29:00.491266Z"
  },
  "youtube-harassment-policy": {
    "policy_name": "Youtube Harassment Policy",
    "initial_summary": "## YouTube Harassment & Cyberbullying Policy Summary\n\nThis policy prioritizes the safety of creators, viewers, and partners.  Key prohibitions include:\n\n* **Harassment:** Prolonged insults or slurs targeting individuals based on protected group status, physical attributes, or victimhood (sexual assault, abuse, etc.).  A stricter approach is taken for content targeting minors.\n* **Doxxing & PII Sharing:** Sharing or threatening to share non-public personally identifiable information (PII),  except for widely available public information or clearly marked fake PII used for educational purposes.\n* **Abusive Behavior:** Encouraging brigading or other forms of coordinated abuse. Promoting harmful conspiracy theories linked to threats or violence.\n* **Threats & Violence:**  Threats against individuals or their property (including implicit threats), depictions of staged meet-ups to falsely accuse individuals, vigilante violence, or content glorifying or mocking death/injury.  This also includes realistic simulations of violence or death.\n* **Stalking & Sexualization:** Stalking, unwanted sexualization, sharing non-consensual intimate imagery, or fantasizing about/threatening sexual assault.\n\n**Exceptions:**  Content may be allowed if the primary purpose is educational, documentary, scientific, or artistic (e.g., debates, scripted performances, harassment awareness content). However, these exceptions do not excuse malicious harassment, especially based on protected group status.\n\n**Enforcement:** Violations result in content removal and email notification.  First-time offenders receive a warning with a policy training option.  Multiple violations or severe abuse can lead to strikes, channel suspension, or termination.  Repeat offenders may be prevented from accessing future policy trainings.  The policy applies to videos, comments, livestreams, and external links.\n",
    "last_update_summary": "Here's a concise summary for a product manager regarding the YouTube Harassment & Cyberbullying Policy page update:\n\n**Harassment & Cyberbullying Policy Page Update**\n\n**Specific Changes:**\n*   **No substantive changes to the Harassment & Cyberbullying policy content itself.**\n*   Added a \"Was this helpful?\" survey and \"Need more help?\" links section to the policy page footer.\n*   Extensive, non-functional updates to the underlying JavaScript code (variable and function renaming/obfuscation), likely due to a build system or minification process update.\n\n**Impact:**\n*   **Users:** Enhanced feedback mechanism and improved navigation to support resources directly on the policy page.\n*   **Trust & Safety Operations:** No impact on policy interpretation, enforcement, or content review processes, as the policy text remains unchanged.\n*   **Product:** Improved user experience for those seeking clarity or additional help after viewing the policy. The JS changes are likely internal maintenance, with no direct product feature impact.",
    "last_updated": "2025-08-20T01:58:32.514132Z"
  },
  "youtube-shopping-ads-policy": {
    "policy_name": "Youtube Shopping Ads Policy",
    "initial_summary": "## Google Shopping Ads Policies: Summary for Product Managers\n\nThis document outlines Google's policies for Shopping ads, aiming for a trustworthy and transparent advertising ecosystem.  Key areas covered are:\n\n**1. Prohibited Content:**  This includes counterfeit goods, dangerous products (drugs, weapons, explosives), products enabling dishonest behavior (hacking tools, fake documents), and inappropriate content (hate speech, violence, cruelty).  Certain content lacks optimal support and is therefore unsupported in Shopping ads, though this doesn't affect other Google platforms.\n\n**2. Prohibited Practices:** This section addresses abuse of the ad network (malicious content, unfair advantages, bypassing reviews), irresponsible data collection and use (insecure data handling), and misrepresentation (misleading promotions, inaccurate product portrayal).\n\n**3. Restricted Content:**  This category covers legally or culturally sensitive content allowed with limitations and potential additional requirements. Examples include adult-oriented content, alcoholic beverages, copyrighted material, gambling, healthcare products, political content, and High Fat Sugar Salt (HFSS) food & beverages (prohibited from targeting minors).\n\n**4. Editorial & Technical Requirements:**  Ads must meet high professional and editorial standards, be clear, and lead to relevant, user-friendly landing pages. Technical requirements ensure ad functionality across various formats.\n\n**Enforcement:** Google uses AI and human review to enforce policies, taking actions ranging from disapproving ads to suspending accounts for violations.  Advertisers can appeal decisions.  Compliance with all applicable laws and regulations is mandatory.\n",
    "last_update_summary": "**Summary for Product Manager: YouTube Shopping Ads Policy (Initial Publication)**\n\nThis document represents the *initial publication* of Google's YouTube Shopping Ads Policy, dated 2025-07-22. It outlines a comprehensive framework for acceptable content and practices within their shopping ad ecosystem.\n\n**Key Policy Areas:**\n\n1.  **Overview & Enforcement:**\n    *   Aims for a trustworthy, transparent, and safe digital advertising ecosystem, aligning with broader Google Ads policies.\n    *   Enforced through a combination of Google AI and human review.\n    *   Violations can lead to ad disapproval, impression caps, or account suspension, with clear appeal processes.\n\n2.  **Prohibited Content (Not Allowed):**\n    *   **Counterfeit Goods:** Products mimicking trademarks/brands.\n    *   **Dangerous Products:** Recreational drugs, weapons, explosives, tobacco.\n    *   **Dishonest Behavior:** Hacking software, fake documents, academic cheating.\n    *   **Inappropriate Content:** Shocking content, hate, discrimination, violence, self-harm, animal cruelty.\n    *   **Unsupported Shopping Ads Content:** Content where an optimal user experience cannot be provided within Shopping Ads (specific to this product, not other Google platforms).\n\n3.  **Prohibited Practices (Cannot Do):**\n    *   **Ad Network Abuse:** Malicious content, low-value sites, unfair advantage, bypassing review systems.\n    *   **Irresponsible Data Collection & Use:** Misusing user information, collecting PII without proper security (e.g., over non-SSL connections).\n    *   **Misrepresentation:** Misleading promotions, lack of explicit consent, inaccurate or untruthful product/retailer representation.\n\n4.  **Restricted Content (Allowed with Limitations):**\n    *   **Adult-Oriented Content:** Merchandise, suggestive content, exposed skin/nudity (strict prohibitions on targeting minors, explicit content, non-consensual themes).\n    *   **Alcoholic Beverages:** Restrictions based on legal drinking age, implied benefits, excessive drinking, or consumption with dangerous activities.\n    *   **Copyrighted Content:** Requires legal authorization or specific reporting via Google forms.\n    *   **Gambling-related Content:** Limited promotion.\n    *   **Healthcare-related Content:** Includes OTC, prescription drugs, unapproved supplements, pregnancy/fertility products (may require preauthorization, some universally prohibited).\n    *   **Political Content:** Must comply with laws and election \"silence periods.\"\n    *   **Trademarks:** Generally allowed in titles/descriptions for relevant products, but subject to review for consumer confusion.\n    *   **High Fat Sugar Salt (HFSS) Food & Beverage:** Allowed if compliant with specific (implied) policies.\n\n**Key Takeaway for PM:**\nThis policy establishes a robust content moderation framework covering a wide range of sensitive categories and potentially harmful practices. It emphasizes user safety, legal compliance, and a fair advertising ecosystem, using a hybrid AI/human enforcement model. Be aware of the specific geopolitical notes regarding ad pauses in/to Russia, indicating responsiveness to global events.",
    "last_updated": "2025-07-22T00:29:21.453232Z"
  },
  "meta-community-guidelines": {
    "policy_name": "Meta Community Guidelines",
    "initial_summary": "# Competitor Policy Summary:\n\nThis document outlines Meta's Community Standards, encompassing policies for Facebook, Instagram, Messenger, and Threads.  Key areas covered include:\n\n* **Content Moderation:**  Policies define acceptable and unacceptable content, addressing issues like hate speech, violence, harassment, misinformation, and illegal activities.  A three-part enforcement approach (remove, reduce, inform) is used.  Newsworthiness and public interest are considered when evaluating potentially violating content.\n\n* **Account Integrity:** Policies cover authentic identity, inauthentic behavior, and account security.\n\n* **Safety & Well-being:**  Emphasis is placed on user safety, privacy, and dignity.  Specific attention is given to protecting minors, addressing issues like child exploitation and suicide/self-harm.\n\n* **Transparency & Enforcement:**  The document details how Meta detects and addresses policy violations, including technological solutions and human review.  Transparency reports on enforcement, intellectual property, government data requests, and content restrictions are publicly available.\n\n* **Governance & Appeals:**  Information is provided about Meta's Oversight Board, its role in policy appeals, and its impact.\n\n* **Research & Data:** Access to research tools and datasets related to content and advertising is highlighted.\n\n\nThe policy aims to balance freedom of expression with the need to maintain a safe and respectful online environment.  The US English version is considered the primary and most up-to-date document.\n",
    "last_update_summary": "Here's a concise summary for a Product Manager:\n\n*   **Specific Change:** This diff represents the **initial publication** of the comprehensive Meta Community Guidelines document (`meta-community-guidelines/snapshot.html`), not an update to an existing policy. This new policy applies universally across Facebook, Instagram, Messenger, and Threads.\n*   **Key Impacts for Product Managers:**\n    *   **Unified Standard:** Establishes a foundational and consistent set of content policies for all core Meta platforms, simplifying cross-platform policy alignment.\n    *   **AI Content Inclusion:** Explicitly states that the Community Standards apply to **AI-generated content**, providing a clear policy boundary for product features leveraging AI.\n    *   **Enforcement Clarity:** Defines the structure for how policies are articulated (e.g., policy rationale, content allowed with warnings/age restrictions), directly informing the design and logic of enforcement mechanisms and user-facing experiences.\n    *   **Increased Transparency:** Provides a public-facing resource for users and external stakeholders to understand content rules, which may impact user support and communication strategies.",
    "last_updated": "2025-08-15T06:09:34.738495Z"
  },
  "meta-appeal-process": {
    "policy_name": "Meta Appeal Process",
    "initial_summary": "Here's a concise summary of Instagram's Oversight Board appeal policy for a Product Manager:\n\n### Instagram Oversight Board Appeal Policy Summary\n\n**Key Points:**\n\n*   **Purpose:** Allows users to appeal Instagram's content decisions (both on their own content or content they reported) to an independent Oversight Board (OB).\n*   **Prerequisite:** Users **must** first exhaust Instagram's internal review process, including two internal reviews of the decision, before becoming eligible to appeal to the OB.\n*   **Appeal Types:**\n    *   Decisions to take down a user's content.\n    *   Decisions not to remove content a user reported.\n*   **Eligibility & Selection:** Not all content decisions are eligible for OB appeal. The OB itself selects only a limited number of eligible appeals for review and may not choose a specific case.\n*   **Timeline:** Appeals to the OB must be submitted within **15 days** of Instagram's final decision.\n*   **Status Check:** Users can track their appeal status on the Oversight Board's website using a reference number.",
    "last_update_summary": "**Concise Summary for Product Manager:**\n\n**Specific Changes:**\n\n*   **New Policy Page:** A new Help Center policy page has been deployed, formalizing the process for appealing Instagram content decisions to the Oversight Board.\n*   **Expanded Appeal Scope:** Users can now appeal decisions about *both* their own content that was removed *and* content they reported that was *not* removed.\n*   **Internal Review Prerequisite:** Users are explicitly required to go through the internal \"request a review\" process *twice* before becoming eligible to appeal to the Oversight Board.\n*   **Appeal Window:** A 15-day window is established for users to submit an appeal to the Oversight Board after the final internal decision.\n\n**Impact:**\n\n*   **Increased Transparency & User Empowerment:** Provides a clear, formalized pathway for users to escalate content moderation disputes to an external body, significantly expanding options for reported content.\n*   **Potential for Increased Internal Review Volume:** Users will be required to engage with our internal review process more thoroughly (twice) as a prerequisite for OB appeal, potentially increasing the demand on our internal review teams.\n*   **Clarified User Journey:** Defines the steps and limitations for external appeals, potentially reducing ad-hoc inquiries about the OB process.\n*   **Operational Streamlining:** Aims to resolve more cases internally before they reach the Oversight Board by requiring comprehensive internal appeals first.",
    "last_updated": "2025-08-15T06:09:10.740995Z"
  },
  "meta-blocking-people": {
    "policy_name": "Meta Blocking People",
    "initial_summary": "Here's a concise summary of the provided policy text for a Product Manager:\n\n### Instagram \"Blocking People\" Policy Summary\n\nThis policy details Instagram's \"Blocking People\" feature, a core safety and privacy control.\n\n**Key Points:**\n\n*   **Core Functionality:** Explains how users can block and unblock other accounts.\n*   **Impact of Blocking:**\n    *   Removes all past comments and likes from the blocked user.\n    *   Clarifies that a blocked user generally cannot see the blocker's content, message them, or mention them.\n    *   Provides guidance on how to view and manage a list of blocked accounts.\n*   **Related Privacy & Safety Controls:** The document also references other related user controls available in the \"Privacy, Security & Reporting\" section, including:\n    *   Making an account private.\n    *   Removing followers.\n    *   Restricting users (a softer form of control than blocking).\n    *   Temporarily limiting interactions from others.\n    *   Reporting messages or accounts.\n\nThis policy emphasizes user control over their interactions and visibility on the platform.",
    "last_update_summary": "Here's a concise summary for a product manager:\n\n*   **Specific Change:** A new Help Center article, \"Blocking People,\" has been deployed to production. This consolidates information regarding blocking, unblocking, and related privacy/safety features on Instagram (e.g., restricting, removing followers).\n*   **Impact:**\n    *   **User Empowerment:** Enhances user understanding and control over their privacy and safety by providing clear, centralized guidance on managing unwanted interactions.\n    *   **Reduced Support Load:** Aims to decrease user support inquiries related to blocking functionality by making comprehensive information readily accessible.\n    *   **Transparency:** Improves transparency around a core safety feature, aligning with T&S goals for user education.",
    "last_updated": "2025-08-15T06:09:14.451622Z"
  },
  "meta-commerce-policies": {
    "policy_name": "Meta Commerce Policies",
    "initial_summary": "### Competitor Policy Page Analysis: Unavailable Page\n\nThe provided text is an error message from Instagram's Help Center, indicating that a specific page is unavailable.\n\n**Key Points:**\n\n*   **Core Message:** \"This Page Isn't Available.\"\n*   **Reasons for Unavailability:** The page may be unavailable due to a broken link or because it has been removed.\n*   **User Guidance:** Users are advised to check if the link they are trying to open is correct.\n*   **Navigation Options:** The page provides clear calls to action to return to the Help Center Home or go back to the previous page.\n*   **T&S Relevance:** This page demonstrates how a competitor handles missing or removed content (potentially policy or help documentation), which impacts user experience and trust. It emphasizes the need for clear communication and alternative navigation when users encounter inaccessible information.",
    "last_update_summary": "Here's a concise summary for a product manager:\n\n**Policy Update: New Commerce Policy Deployment**\n\n*   **Specific Change:** A new, comprehensive Commerce Policy document (`snapshot.html`) has been deployed, establishing a unified set of rules for all commerce activities across Facebook, Instagram, WhatsApp, and Messenger services (e.g., Marketplace, Shops, WhatsApp Business Catalog).\n*   **Key Policy Elements Introduced:**\n    *   **Prohibited Content (24 categories):** Explicitly lists items/activities banned from sale (e.g., alcohol, weapons, drugs, adult content, stolen goods, discrimination).\n    *   **Restricted Content (4 categories):** Defines items/services allowed only under specific conditions or by approved sellers (e.g., event tickets, gift cards, services, pet adoption matching).\n    *   **Marketplace Business Restrictions:** Formalizes that Facebook Marketplace is primarily for consumer-to-consumer sales, with businesses/commercial entities in the **European Economic Area (EEA), Philippines, and India** subject to restrictions, including potential suspension or removal of listings.\n    *   **Enforcement & Appeals:** Outlines consequences for violations (e.g., listing removal, account suspension) and the process for appealing decisions.\n*   **Impact:**\n    *   **For Product:** Provides a centralized and consistent rulebook for commerce features, enabling more standardized enforcement. The specific Marketplace restriction for businesses in EEA, PH, and India may require product or tooling adjustments to identify and manage these entities effectively.\n    *   **For Users:** Offers clear guidelines on what can and cannot be sold across Meta's commerce surfaces, potentially increasing user understanding and compliance, but also introducing new restrictions for businesses in specific regions.\n    *   **For T&S Operations:** Streamlines policy training and enforcement efforts by consolidating previously disparate or implied rules into a single, comprehensive document.",
    "last_updated": "2025-08-15T06:09:25.217645Z"
  },
  "tiktok-blocking-users": {
    "policy_name": "Tiktok Blocking Users",
    "initial_summary": "Here's a concise summary of the competitor's policy page for a Product Manager:\n\n### Competitor Policy Page Summary\n\nThe competitor's policy documentation serves as a comprehensive help center, detailing an exceptionally broad range of platform functionalities, from core features to advanced creator tools and monetization.\n\n**Key Trust & Safety Takeaways:**\n\n*   **Robust User Control & Safety Tools:** A significant focus is placed on empowering users with safety mechanisms. Detailed instructions for blocking (individual users, multiple users from comments, unblocking) are prominently featured, alongside mentions of a \"Safety Center,\" \"Community Guidelines,\" and \"Report a problem\" functionality.\n*   **Comprehensive Feature & Content Coverage:** The policies span an extensive array of content types and features including user-generated videos, AI-generated content, creator tools, live streaming, e-commerce (\"TikTok Shop\"), messaging, and content discovery, indicating a complex ecosystem requiring broad T&S oversight.\n*   **Creator Monetization & Ecosystem:** Policies extend to creator monetization features (LIVE, Gifts, promotion tools), necessitating guidelines for commercial activities, fraud prevention, and responsible content creation related to earning.\n*   **Legal & Policy Framework:** The document points to a foundational set of legal and policy resources, including Terms of Use, Privacy, Copyright, and Law Enforcement guidelines, signifying a structured approach to compliance and trust.\n*   **Algorithmic Transparency & Global Reach:** It touches on content recommendation algorithms (\"How TikTok recommends content\") and highlights a vast global operational scope through an extensive list of supported languages, implying a need for culturally nuanced and legally compliant T&S policies worldwide.",
    "last_update_summary": "**New Policy Page: Blocking Users**\n\nThis diff introduces a completely new help center policy page for TikTok's user blocking features, indicating a formalization and enhancement of user safety controls.\n\n**Key Content:**\n*   **Comprehensive Blocking Guide:** Provides clear, step-by-step instructions for users to block and unblock individual accounts directly from a person's profile.\n*   **New Multi-Block Functionality:** Crucially, it outlines a new method for users to block *multiple accounts simultaneously from their video comments*. This is a significant addition, allowing users to efficiently manage and mitigate harassment, spam, or unwanted engagement from multiple sources at once.\n\n**Impact for Product Managers (T&S Lens):**\nThis new page clarifies and expands user self-service safety tools. The addition of multi-user blocking from comments is a key feature enhancement that empowers users to more effectively manage negative interactions, potentially reducing the burden on reporting systems and improving overall user experience and trust.",
    "last_updated": "2025-07-22T00:27:47.015162Z"
  },
  "youtube-hiding-users": {
    "policy_name": "Youtube Hiding Users",
    "initial_summary": "As a Trust & Safety analyst, here is a concise summary of the provided policy document on YouTube's \"Hide users from your channel\" feature for a Product Manager:\n\n---\n\n### YouTube: \"Hide Users from Your Channel\" Policy Summary\n\nThis policy outlines a channel moderation feature allowing content creators to control who can interact with their content.\n\n**Key Functionality:**\n\n*   **Purpose:** Channel owners can \"hide\" specific viewers to prevent their comments from appearing on the channel and to stop them from creating clips from videos or live streams.\n*   **Impact on Hidden User:**\n    *   All previous comments from the hidden user on the channel will be hidden within 48 hours.\n    *   Future comments from the hidden user will not appear.\n    *   The hidden user will **not** receive a notification that they have been hidden.\n*   **Methods to Hide:**\n    1.  **From a Comment:** Select \"More\" next to a user's comment, then \"Hide user from channel.\"\n    2.  **Via YouTube Studio:** In \"Settings\" > \"Community\" > \"Automated Filters,\" paste the user's channel URL into the \"Hidden users\" box.\n*   **Managing Hidden Users:**\n    *   A list of hidden users is available in YouTube Studio under \"Settings\" > \"Community\" > \"Automated Filters.\"\n    *   Users can be \"shown\" (unhidden) from this list, which allows their *future* comments to appear. Previous comments remain hidden.\n*   **Scope:** This is a **channel moderation tool** for managing audience interaction. It is distinct from reporting abuse, harassment, or policy violations, which should be directed to the Safety Center.\n\n---",
    "last_update_summary": "Here's a concise summary for the product manager:\n\n*   **Change:** The user feedback form, including options for issue reporting (e.g., \"Inaccurate,\" \"Hard to understand,\" \"Missing info\") and a free-text suggestion box, has been completely removed from the `youtube-hiding-users/snapshot.html` page.\n*   **Impact:** This change eliminates a direct user feedback channel for the \"hiding users\" feature. This removes a valuable source of user signal that could inform T&S policy enforcement, identify product usability issues, or highlight potential areas of user friction related to content moderation tools. We will lose insight into user-perceived problems with this specific functionality.",
    "last_updated": "2025-08-22T12:53:01.868389Z"
  },
  "whatnot-community-guidelines": {
    "policy_name": "Whatnot Community Guidelines",
    "initial_summary": "This policy establishes community guidelines for Whatnot platform users, covering acceptable behavior, prohibited content, and enforcement mechanisms for maintaining a safe marketplace environment.",
    "last_update_summary": "Here's a summary of the competitor's policy change based on the provided diff:\n\n*   The competitor's Community Guidelines policy document is currently inaccessible.\n*   Accessing the page intended for the Community Guidelines now results in a \"page not found\" error message.\n*   This suggests the policy is either temporarily unavailable, undergoing revision, or has been moved.",
    "last_updated": "2025-08-04T16:16:37.599257Z"
  },
  "whatnot-prohibited-items": {
    "policy_name": "Whatnot Prohibited Items",
    "initial_summary": "This policy defines items and content that are prohibited from being sold, promoted, or distributed on the Whatnot marketplace platform, including safety guidelines and compliance requirements.",
    "last_update_summary": "Initial version.",
    "last_updated": "2025-08-04T16:02:34.677017Z"
  },
  "twitch-community-guidelines": {
    "policy_name": "Twitch Community Guidelines",
    "initial_summary": "Here's a concise summary for a product manager, highlighting key aspects of Twitch's Trust & Safety policy framework:\n\n*   **Core Policy Framework:** A comprehensive set of Community Guidelines, alongside specific policies for Content Classification, Advertiser-Friendly content, and Emotes, governed by overarching Twitch Terms.\n*   **Enforcement Mechanisms:** Clearly defined processes for user reporting, a formal appeals system for enforcement decisions, and a commitment to transparency reporting.\n*   **Moderation & User Controls:** Extensive in-platform tools for chat management, viewer controls to personalize experiences, and resources dedicated to combating targeted attacks and managing harassment.\n*   **User Empowerment & Education:** Provides detailed guides for creators on building and managing moderation teams, as well as general safety resources for users (e.g., media literacy, crisis prevention).\n*   **Platform & Account Security:** Strong emphasis on preventing and combating account takeovers, crucial for maintaining user trust and data integrity.\n*   **Proactive Safety & Harm Prevention:** Addresses severe issues like real-world harm, offers resources for parents/educators, and engages external experts through a Safety Advisory Collective.\n*   **External Relations & Compliance:** Outlines procedures for responding to law enforcement requests and ensuring overall legal compliance.",
    "last_update_summary": "Here's a concise summary of the Community Guidelines update for a product manager:\n\nThis update represents a comprehensive release of our Community Guidelines, introducing new sections and significant clarifications, rather than minor edits.\n\n**Specific Changes:**\n\n*   **New \"Introduction to Safety\" Section:** Outlines Twitch's overall safety philosophy, enforcement actions (warnings, content removal, monetization suspension, account suspension), and the appeals process.\n*   **New \"Enforcement Notes\" Sections:** Added to clarify existing policies with specific examples, particularly for:\n    *   **Self-Destructive Behavior:** Prohibits selling activities for harm (e.g., shots for subs), clarifies allowed vs. prohibited drinking goal streams, and explicitly defines dangerous/distracted driving.\n    *   **Youth Safety:** Specifically bans sexualized depictions of child-like anime characters (\"lolis\"/\"shotas\") even with adult operators, prohibits humor related to sexualizing minors, and states that claiming to be under 13 will lead to account deactivation.\n*   **New \"Off-Service Conduct\" Policy (Significant):** Twitch will now enforce against specific, severe harms that occur *off* our service when committed by community members. This includes deadly violence, violent extremism, sexual exploitation of youth, hate group leadership, doxxing, and swatting. A dedicated reporting channel (`OSIT@twitch.tv`) and specific evidence requirements are introduced.\n\n**Impact for Product Manager:**\n\n*   **Enhanced Clarity & Safety:** Provides much more specific examples and definitions, aiding user understanding of acceptable behavior and streamlining content moderation decisions. This can reduce user friction and improve the perceived safety of the platform.\n*   **Expanded Trust & Safety Scope & Investment:** The \"Off-Service Conduct\" policy is a major expansion, requiring the T&S team to develop new processes for investigating and verifying off-platform evidence, potentially increasing operational costs and the need for specialized personnel.\n*   **Potential for User Feedback/Perception:** Enforcement of off-service conduct can be controversial; be prepared for potential community discussion or questions about Twitch's reach beyond the platform.\n*   **Content Creator Impact:** Stricter guidelines on monetized harmful behaviors, sexualized virtual avatars, and dangerous driving activities may lead some creators to adjust their content strategies.\n*   **Moderation Training:** New explicit examples (e.g., for drinking streams, driving, avatar content) will require thorough training for moderators to ensure consistent and fair application of policies.",
    "last_updated": "2025-08-25T18:38:55.447909Z"
  },
  "twitch-dmca-guidelines": {
    "policy_name": "Twitch Dmca Guidelines",
    "initial_summary": "Here's a concise summary of the DMCA Notification Guidelines for a Product Manager, from a Trust & Safety perspective:\n\n**Key Aspects of Twitch's DMCA Policy**\n\n*   **Core Compliance & Role:** Twitch operates as an intermediary (\"go-between\") under the Digital Millennium Copyright Act (DMCA), facilitating copyright claims and disputes. We do not make legal judgments on infringement; our role is procedural.\n*   **Claim & Consequence:**\n    *   **Rights Holders** submit notifications of claimed infringement (webform preferred, with specific required details). Incomplete notices may be rejected. Submitter's name/email is shared with the account holder.\n    *   Upon a valid notification, Twitch generally **removes or disables access to the content** (VODs, Clips, Channel Artwork). Live streams can be disabled **immediately**.\n    *   The streamer's account receives a **copyright strike**.\n*   **Streamer Recourse & Mitigation:**\n    *   Streamers can submit a **counter-notification** (via email, all details shared with the claimant) if they believe the claim was a mistake or misidentification.\n    *   Streamers can also seek a **retraction** directly from the rights holder.\n    *   Successful counter-notifications or retractions prevent or remove a strike, and may lead to content restoration (though not always guaranteed due to technical/timing factors).\n*   **Repeat Infringer Policy:**\n    *   Accruing **three copyright strikes** leads to account termination.\n    *   Strikes are not permanent but remain long enough to assess repeat infringement.\n    *   **Copyright School:** Eligible streamers can complete Copyright School to remove one strike every 12 months, serving as an educational rehabilitation tool.\n*   **Operational Note:** While infringement claims utilize a webform, counter-notifications and retractions primarily rely on email, which could be a point of friction or confusion for users.",
    "last_update_summary": "Initial version.",
    "last_updated": "2025-08-19T02:24:58.006910Z"
  },
  "twitch-monetized-streamer-agreement": {
    "policy_name": "Twitch Monetized Streamer Agreement",
    "initial_summary": "As a Trust & Safety analyst, here's a concise summary of the Monetized Streamer Agreement for a product manager:\n\nThis agreement outlines the terms for streamers to access Twitch's monetization tools (Program) and receive associated fees.\n\n**Key Aspects for Product Managers:**\n\n*   **Integration with ToS:** The Agreement incorporates and is governed by Twitch's overarching Terms of Service (ToS). Any violation of the ToS or this Agreement can lead to severe consequences.\n*   **Eligibility & Compliance:**\n    *   Streamers must apply and be approved by Twitch (sole discretion).\n    *   Requires complete, accurate, and up-to-date contact/tax information.\n    *   Strict compliance with *all* Twitch policies (ToS, Bits Acceptable Use Policy) is mandatory.\n    *   Prohibits fraudulent means to generate ad impressions/clicks.\n    *   **T&S Implication:** Product features facilitating accurate info collection (KYC/KYB), fraud detection for ad/bit interactions, and robust compliance checks are vital.\n*   **Content Responsibility:**\n    *   Streamers are \"executive producers\" of their content, with sole discretion over what they stream (within ToS).\n    *   **Crucially, streamers are fully liable for obtaining and maintaining *all necessary rights, consents, and licenses* for their content.** They must immediately remove violating content.\n    *   **T&S Implication:** Direct link to copyright, IP, and content moderation enforcement workflows. Product needs to support content reporting and removal.\n*   **Monetization & Payout Rules:**\n    *   Twitch retains exclusive monetization rights; Program Fees are for using Twitch-provided tools (Bits, Subs, Ads, Offers).\n    *   **Payouts are contingent on being a Twitch Affiliate or Partner AND meeting a Payment Threshold.** Otherwise, earnings are only accessible via a \"Spendable Balance\" for Twitch purchases.\n    *   **T&S Implication:** Financial penalties are key enforcement levers: Twitch can **withhold Program Fees** for any violation of the Agreement or ToS. Failure to provide tax info within 180 days forfeits fees.\n*   **Enforcement & Termination:**\n    *   Twitch can **reject applications, disable ads, withhold fees, terminate the Agreement, and disable/ban channels** for non-compliance (e.g., ToS violation, fraudulent activity, repeat infringer, being a Sanctioned Person).\n    *   **T&S Implication:** Clear pathways for policy enforcement, account sanctions, and financial leverage are built into the agreement.\n*   **Dynamic Nature:** Twitch retains the right to add/remove Program Tools and modify the Agreement at any time.\n\nIn essence, this agreement formalizes the rules of engagement for monetization, emphasizing streamer accountability for content and conduct, and providing Twitch with clear enforcement mechanisms, particularly financial ones, for non-compliance.",
    "last_update_summary": "Here's a concise summary for the product manager:\n\n*   **Specific Changes:** The heading levels for sections 1 (\"Eligibility and Compliance\"), 2 (\"Content\"), 3 (\"Program Revenue\"), and 4 (\"Payment and Reporting\") within the Twitch Monetized Streamer Agreement have been changed from an `<h2>` (double hash `##`) to an `<h3>` (triple hash `###`).\n*   **Impact:** This is a purely cosmetic/formatting update to the document's structure. There are **no substantive policy changes** that affect streamer eligibility, program terms, revenue calculations, payment processes, or any rights/obligations for either Twitch or its monetized streamers.",
    "last_updated": "2025-08-23T01:54:50.583822Z"
  },
  "twitch-privacy-policy": {
    "policy_name": "Twitch Privacy Policy",
    "initial_summary": "Here's a concise summary of the Twitch Privacy Notice for a Product Manager, from a Trust & Safety perspective:\n\n**Twitch Privacy Notice - Key Aspects for Product Management**\n\nThe Twitch Privacy Notice (Last modified: 06/30/2023) outlines data collection, use, and disclosure practices, emphasizing Twitch's role as a data controller and an Amazon subsidiary.\n\n*   **Data Collection & Public Nature:**\n    *   **Comprehensive Collection:** Gathers user-provided data (account info, billing, content like voice/image), automatically collected data (IP, device, usage metrics via cookies), and data from linked third-party services (social media, games) or live events (recordings, badge scans).\n    *   **Social & Public Activities:** Highlights that many Twitch Services are inherently public (broadcasting, chat, profile info), meaning user-provided data in these contexts is designed to be seen and potentially collected by others.\n\n*   **Data Use & Disclosure:**\n    *   **Core Functions & Security:** Data is used for operating, maintaining, securing services, managing accounts, personalizing content (including ads), and preventing fraud/abuse.\n    *   **Amazon & Affiliates:** Personal data is shared within Amazon.com, Inc. and its subsidiaries (under equivalent privacy standards) to operate, provide, and improve both Twitch and Amazon products/services.\n    *   **Service Providers & Legal Obligations:** Data is shared with service providers (hosting, analytics) under strict confidentiality. Twitch also reserves the right to disclose data to comply with legal requirements (e.g., court orders) or to protect Twitch, its users, or others from liability, fraud, or harm.\n    *   **No Sale of Data:** Explicitly states Twitch is \"not in the business of selling our users\u2019 personal information.\"\n\n*   **User Rights & Controls (Data Subject Rights):**\n    *   **Broad Rights:** Users are granted rights to access, update, delete, restrict processing, object to direct marketing, and revoke consent. Mechanisms are provided via account settings and support.\n    *   **Retention Post-Deletion:** Notes that Twitch may retain \"certain information\" post-account closure for legitimate interests or legal obligations.\n    *   **Identity Verification:** Twitch may verify identity before fulfilling data requests.\n\n*   **Third-Party Integrations & Accountability:**\n    *   **External Links:** Emphasizes that third-party websites/services linked from Twitch are *not* governed by this policy, requiring users to review external privacy policies.\n    *   **Linked Accounts:** Connecting Twitch to third-party services (e.g., Discord, Xbox) *explicitly authorizes Twitch to share specific data* (username, activity) with those third parties.\n    *   **Extensions & Applications:** Third-party Extension developers receive \"automatically collected information\" from viewer interaction, but Twitch requires explicit user \"Grant Access\" for username/ID. Users are responsible for data provided directly to developers. Developers are contractually required to process data only for defined purposes, but users are encouraged to review the developer's privacy policy.\n    *   **Live Event Exhibitors:** Allowing exhibitors to scan badges explicitly transfers personal information to them, after which *their* privacy policy applies.\n\n**Key Trust & Safety Considerations for PMs:**\n\n1.  **Transparency & Consent:** Ensure product features clearly communicate when user data (especially public data or data shared via integrations) is being collected or shared, and obtain appropriate consent.\n2.  **Third-Party Risk:** Be acutely aware that integrating with third-party services, extensions, or allowing in-person badge scans shifts data responsibility to the third party, requiring clear user disclosure and strong developer/partner agreements.\n3.  **Data Subject Rights:** Design features and data flows with robust processes to easily accommodate user requests for access, modification, and deletion of their data in compliance with global privacy laws.\n4.  **Fraud & Abuse Prevention:** Understand that data collection and disclosure powers are explicitly used for security, fraud, and abuse prevention, supporting Trust & Safety operations.\n5.  **Data Retention:** Consider the implications of data retention policies, particularly for deleted accounts, and ensure legal and legitimate interest justifications are documented.",
    "last_update_summary": "Initial version.",
    "last_updated": "2025-08-19T02:25:30.399510Z"
  },
  "twitch-terms-of-sale": {
    "policy_name": "Twitch Terms Of Sale",
    "initial_summary": "Here's a concise summary of the Terms of Sale for a Product Manager, from a Trust & Safety perspective:\n\n**Trust & Safety Summary: Twitch Terms of Sale**\n\nThis document outlines the binding terms for purchasing \"Ancillary Products and Services\" on Twitch, explicitly incorporating the broader Terms of Service (including dispute resolution). Key T&S aspects include:\n\n*   **User Responsibility & Account Security:** Users are fully responsible for account security, all purchases made under their account, and maintaining accurate billing information. Purchases by minors (13-legal majority) require parental consent.\n*   **Payment & Fraud Prevention:**\n    *   Users authorize charges and accept that payment partners may require **Know Your Customer (KYC)** data (e.g., ID, address) for compliance.\n    *   Twitch can suspend/cancel orders or terminate accounts for payment failures, chargebacks, or suspected fraudulent activity.\n    *   \"Spendable Balance\" (for streamers) can be revoked if obtained or used fraudulently or in violation of terms.\n*   **Digital Content (Bits, Tokens, Rewards) - **_Critical Area_**:\n    *   **No Monetary Value & Non-Transferable:** Digital Content *has no monetary value*, is *not cash or property*, *cannot be sold, traded, or transferred* (including to other users), and *cannot be exchanged for cash or external goods/services*. This prohibits secondary markets and mitigates virtual currency regulatory risks.\n    *   **Non-Refundable & Forfeitable:** Generally non-refundable. Twitch retains full ownership and can unilaterally modify, suspend, or *terminate* Digital Content offerings at any time without compensation, meaning users have **no property rights and bear full risk of forfeiture**.\n    *   Use is subject to the **Bits Acceptable Use Policy**.\n*   **Policy Enforcement & Modifications:** Twitch reserves the right to refuse/cancel orders, terminate accounts in its sole discretion, and unilaterally modify these terms. For active recurring subscriptions, reasonable prior notice is given (with specific consent mechanisms for EU/UK/CH consumers).",
    "last_update_summary": "Initial version.",
    "last_updated": "2025-08-19T02:25:50.834281Z"
  },
  "twitch-terms-of-service": {
    "policy_name": "Twitch Terms Of Service",
    "initial_summary": "Here's a concise summary of the Twitch Terms of Service, highlighting key aspects for a Product Manager from a Trust & Safety perspective:\n\n*   **Binding Agreement & Scope:** The ToS is a legally binding contract for all users (registered or not), incorporating the Community Guidelines and Terms of Sale as foundational policies for user behavior and content.\n*   **User Eligibility & Safety:**\n    *   Minors: Users must be at least 13 years old. Those 13 to the age of legal majority require parental/guardian supervision and agreement to the ToS.\n    *   Blocked Users: Services are not available to users previously removed by Twitch or legally prohibited from receiving them (e.g., due to export restrictions).\n*   **Account Security & Responsibility:** Users are solely responsible for their account security and information accuracy. Selling, renting, or transferring accounts is prohibited, and users are liable for all activity under their account. Twitch reserves rights to combat unauthorized use.\n*   **User Content Ownership & Licensing:**\n    *   **Broad License Grant:** Users grant Twitch an unrestricted, worldwide, irrevocable, perpetual, sublicensable, and royalty-free license to use, reproduce, modify, distribute, display, and monetize their User Content.\n    *   **User Warranties:** Users are solely responsible for their content and must warrant they have the necessary rights, and that content does not infringe third-party IP, defame, or contain malicious code.\n    *   **Content Security Disclaimer (Critical):** Twitch uses \"reasonable security measures\" for User Content but **explicitly disclaims guarantees against unauthorized copying, use, or distribution by third parties.** Users agree Twitch is not liable for such events and waive claims. This represents a significant risk transfer to the user regarding content security.\n*   **Platform IP & User License:** Twitch retains ownership of its platform IP. Users are granted a limited, non-transferable license to access and use the services for personal or internal business use only, with strict prohibitions on commercial resale, distribution, or data mining.\n*   **Promotions:** Users running promotions on Twitch are **solely responsible** for ensuring legal compliance, administration, and all associated liabilities.",
    "last_update_summary": "Initial version.",
    "last_updated": "2025-08-19T02:26:03.200044Z"
  }
}