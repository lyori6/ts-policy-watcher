{
  "tiktok-community-guidelines": {
    "policy_name": "Tiktok Community Guidelines",
    "initial_summary": "## TikTok Competitor Community Guidelines Summary\n\nThis document outlines a comprehensive set of community guidelines for a TikTok-like platform, effective May 17, 2024.  Key areas covered include:\n\n* **Content Moderation:**  The platform employs a three-pronged approach: removing violating content, restricting age-inappropriate content (for users under 18), and making ineligible for recommendation (For You feed) content that doesn't meet platform standards.\n\n* **Prohibited Content:**  A wide range of prohibited content is detailed, encompassing: violence, hate speech, sexual abuse, harassment, self-harm, dangerous activities, misinformation, scams, regulated goods (alcohol, firearms, etc.), and violations of privacy and security.  Specific examples are provided within each category, though the document notes that these are not exhaustive.\n\n* **Community Empowerment:** The platform provides users with tools and resources to manage their experience, including safety settings, filtering options, and reporting mechanisms.\n\n* **Enforcement:** While the specifics of enforcement aren't detailed, the document implies a combination of automated and human moderation to address policy violations.\n\nThe guidelines aim to create a safe and welcoming environment while balancing creative expression and the prevention of harm.  The full guidelines are categorized for easier navigation, with additional information and examples available for each section.\n",
    "last_update_summary": "**Competitor Policy Analysis: TikTok Community Guidelines (Effective May 17, 2024)**\n\nThis document represents TikTok's updated Community Guidelines, released April 17, 2024, and effective May 17, 2024. The policy defines both content \"rules\" (what is allowed) and \"standards\" (For You feed eligibility) to maintain a safe and engaging platform.\n\n**Key Changes/Content Moderation Approach:**\nTikTok articulates a clear, multi-layered content moderation strategy to balance creative expression and harm prevention. This approach is summarized by four distinct pillars:\n\n1.  **Remove:** Direct removal of content (public or private) that violates platform rules.\n2.  **Restrict:** Age-gating content unsuitable for youth, limiting its visibility to users 18+.\n3.  **Make Ineligible for FYF:** Demoting content that does not meet For You Feed recommendation standards, thereby reducing its discoverability.\n4.  **Empower:** Providing users with tools and information (e.g., labels, opt-in screens, warnings, safety toolkits, account controls) to manage their own experience.\n\nThe guidelines are comprehensively organized into categories such as Youth Safety, Safety & Civility, Mental & Behavioral Health, Sensitive & Mature Themes, Integrity & Authenticity, Regulated Goods & Commercial Activities, Privacy & Security, and detailed sections on Accounts & Features, For You Feed Eligibility Standards, and Enforcement.",
    "last_updated": "2025-07-21T18:41:13.282319Z"
  },
  "tiktok-live-moderation": {
    "policy_name": "Tiktok Live Moderation",
    "initial_summary": "# TikTok LIVE Moderation Policy Summary\n\nThis document details TikTok's approach to content moderation during LIVE streams.  Key features include:\n\n* **Creator Controls:** Creators can add moderators, control audience age (18+), filter comments, block keywords, mute, and block viewers directly from the LIVE settings or chat.  This applies to both mobile app and web browser access (via LIVE Studio or OBS Studio for broadcasting; not required for moderation).\n\n* **Moderator Permissions:** Moderators, granted permission by the creator, can mute, block viewers, and report comments violating Community Guidelines.  The level of control a moderator has is determined by the creator.\n\n* **User Actions:**  Viewers can be reported, muted (temporarily), or blocked (preventing future LIVE viewership and other interactions with the creator).  Notifications are sent to muted/blocked users.\n\n* **Accessibility:** Moderation tools are accessible both within the LIVE settings and directly from the LIVE chat interface on both the mobile app and web browser.\n",
    "last_update_summary": "As a Trust & Safety Analyst, here's a summary of the competitor's policy for a Product Manager:\n\n### **Competitor Policy Analysis: TikTok LIVE Moderation**\n\nThis newly introduced policy page details the comprehensive moderation capabilities available for TikTok LIVE streams, empowering both creators and designated moderators to manage content and viewer behavior in real-time.\n\n**Key Features:**\n\n*   **Comprehensive Moderation Actions:** Both creators and moderators can block specific messages, report users, **mute accounts** (for a specified duration, with user notification), and **block accounts** (preventing viewing of current/future LIVEs and interaction with the creator, with user notification).\n*   **Creator-Specific Controls:** Creators retain ultimate control, able to:\n    *   Add and remove moderators before or during a LIVE.\n    *   Enable **Audience Controls** to limit LIVEs to viewers aged 18+.\n    *   Manage detailed **Comment Settings**, including allowing/filtering comments, blocking specific keywords and their variations, and muting users.\n    *   View and manage lists of muted and blocked accounts.\n*   **Platform Consistency:** Detailed instructions are provided for moderation via both the TikTok app and web browser, with largely consistent features across platforms.\n*   **Delegated Authority:** Creators can grant moderators permissions to assist with comment management and account actions, enhancing real-time safety and enforcement.\n\nThis policy underscores TikTok's focus on providing granular control over LIVE environments to foster a safer community experience.\n\n---\n\n### **Key Changes Based on This Diff:**\n\n*   **New Policy Page Introduced:** This `diff` indicates the **initial creation and publication** of the \"Moderating on TikTok LIVE\" policy page. There are no prior versions to compare against; this document establishes the official guidelines and tools for LIVE moderation.",
    "last_updated": "2025-07-21T18:41:21.667105Z"
  },
  "tiktok-shop-prohibited-products": {
    "policy_name": "Tiktok Shop Prohibited Products",
    "initial_summary": "## Competitor Policy Summary: TikTok Shop Academy (US)\n\nThis document appears to be incomplete or broken.  The provided text only shows a heading related to boosting sales on TikTok Shop Academy and a JavaScript error message.  **No actual policy information is present.**  Therefore, no meaningful summary of their policy can be provided.  Further investigation is needed to obtain the actual policy document.\n",
    "last_update_summary": "**Summary for Product Manager: Competitor Policy Page Analysis**\n\nThis diff indicates the creation of a *new file* for a competitor's \"prohibited products\" policy page (dated 2025-07-20).\n\n**Key Changes:**\n\n*   **New Page Created:** A new policy page `tiktok-shop-prohibited-products` has been added.\n*   **Placeholder Content:** The page's content is currently a generic \"JavaScript not enabled\" message, suggesting it's an unpopulated placeholder or a technical error page, rather than an active policy.\n*   **No Policy Content Detected:** There are no actual policy rules or guidelines present in this version of the page.\n\n**Impact:**\n\nCurrently, there is no substantive policy information to analyze. This appears to be a technical setup or placeholder for a future policy page. We should monitor this URL for updates to identify actual policy content when it becomes available.",
    "last_updated": "2025-07-20T23:50:56.579760Z"
  },
  "whatnot-blocking-a-user": {
    "policy_name": "Whatnot Blocking A User",
    "initial_summary": "## Whatnot User Blocking Policy Summary\n\nThis document details Whatnot's user blocking functionality.  Users can block others to prevent:\n\n* Following\n* Direct messaging\n* Profile viewing\n* Livestream interaction (bookmarking, joining, chatting)\n* Future purchases from listings\n\nExisting orders are unaffected by blocking.  Blocking is currently permanent.  There's no list of blocked users.  Being removed from a livestream is different from being blocked by a user.  Users can report violations of Community Guidelines separately.\n",
    "last_update_summary": "As a Trust & Safety analyst, here's a summary of the competitor's new policy page for a Product Manager:\n\n---\n\n### Whatnot: New \"Blocking a User\" Policy Page Summary\n\nThis diff indicates the introduction of a new, dedicated policy page on Whatnot detailing their user blocking functionality.\n\n**Key Features & Takeaways:**\n\n*   **Comprehensive Blocking Functionality:**\n    *   Users can block others to prevent them from: following, direct messaging, viewing their profile, bookmarking/joining/chatting in livestreams, and making *future* marketplace purchases.\n    *   Existing orders with a blocked user will still be honored.\n*   **Clear Blocking Mechanism:** The policy provides simple, step-by-step instructions for blocking a user directly from their profile via the 3-dot menu.\n*   **Unblocking Capability:** Users can unblock by searching for the user and selecting \"Unblock\" from their profile menu.\n*   **CRITICAL LIMITATION: No Block List & Implied Permanence:** The policy explicitly states: \"We currently do not have a way for users to see a list of all the users they have blocked. Make sure you want to block someone because currently blocking is permanent!\" This suggests a strong, potentially irreversible, user-initiated action with limited oversight for the blocker.\n*   **Distinction from T&S Actions:** The policy clarifies that blocking is distinct from reporting a user (which triggers a Trust & Safety investigation for Community Guideline violations) and from being temporarily removed/banned from a livestream by a host or mod.\n\n**Key Change Based on Diff:**\n\n*   This is a **newly published policy page** (`new file mode`). Whatnot has formalized and made public their user blocking guidelines and functionalities, emphasizing user control over their interactions while highlighting the current lack of a block list and the \"permanent\" nature of the action from the user's perspective.",
    "last_updated": "2025-07-21T18:41:27.876890Z"
  },
  "whatnot-buyer-protection": {
    "policy_name": "Whatnot Buyer Protection",
    "initial_summary": "# Whatnot Buyer Protection Policy Summary\n\n**Key Points:**\n\n* **Refund Eligibility:** Whatnot offers buyer protection for incomplete/incorrect items, items not as described/inauthentic, and packages not received.  Refunds are generally granted within 30 days of purchase or 14 days of delivery (7 days for certain categories like coins, sneakers, luxury goods; 2 days for plants).  Whatnot may require item return in original condition.  German buyers pay return shipping.\n\n* **Refund Exclusions:**  Consumables (opened/consumed items, breaks except for missing/damaged items), tips, refused deliveries, uncollected packages, unpaid customs fees, exchange rate losses, chargebacks, digital content, off-platform transactions, and instances of suspected fraud are excluded.  Returning the wrong item also voids a refund.\n\n* **Time Limits & Exceptions:**  Specific shorter deadlines apply for certain high-value categories and counterfeit claims (30 days from receipt). Extensions may be granted for international orders, pre-orders, custom orders, and due to natural disasters.  \"Delivered\" but not received items require contact within 14 days.\n\n* **EU/UK Right of Withdrawal:** EU/UK buyers have a 14-day right of withdrawal, requiring item return within 14 days of cancellation.  Buyers are responsible for return shipping costs. This right doesn't apply to breaks, surprise products, or certain unsuitable goods (hygiene, mixed, sealed software/media, customized items, perishable goods).\n\n\n* **High-Value Loss Reimbursement:** A separate policy exists for high-value card losses in breaks, potentially reimbursing market value.\n\n",
    "last_update_summary": "As a Trust & Safety analyst, here's a concise summary of Whatnot's new Buyer Protection Policy for a product manager:\n\n---\n\n### Whatnot Buyer Protection Policy - Key Policy Overview\n\nThis document introduces Whatnot's comprehensive Buyer Protection Policy, outlining buyer rights and refund eligibility. Since this is a new file, it represents the full scope of their updated policy.\n\n**Key Provisions:**\n\n1.  **Scope of Coverage:**\n    *   Covers issues such as incomplete/incorrect items, items not as described (damaged, defective, counterfeit, wrong condition/size/color), and package delivery issues (lost, delayed, not shipped, misdelivered, or marked \"delivered\" but not received).\n    *   Also includes incorrect sales tax charges and additional postage paid by the buyer.\n\n2.  **Refund Request Timelines:**\n    *   **General:** Buyers must submit requests within the **earlier of 30 days from purchase or 14 days from delivery**.\n    *   **Category-Specific Deadlines:**\n        *   **7 days from delivery / 30 days from purchase:** Coins & Money, Sports Cards, Sneakers & Streetwear, Trading Card Games, Luxury Goods.\n        *   **2 days from delivery / 30 days from purchase:** Plants.\n    *   **Special Cases:** Extensions for international orders, pre-orders/custom orders, and specific 30-day window for counterfeit claims. For items marked delivered but not received, buyers must contact support within 14 days.\n\n3.  **Return Requirements:**\n    *   Whatnot *may* require item returns, which must be in the same condition as received (e.g., unopened, tags attached).\n    *   **Germany-Specific:** Buyers are required to pay return shipping costs, which will be deducted from their refund.\n\n4.  **Key Exclusions:** Refunds are **not** provided for:\n    *   **Consumable products** once consumed or opened (e.g., breaks, unless missing/damaged; other consumables).\n    *   Tips to sellers, refused deliveries, failure to pick up packages, refusal to pay customs fees (or refund of customs fees), exchange rate fluctuations, chargebacks (disputed with financial institutions), and digital content.\n    *   Incorrect items returned by the buyer.\n    *   Off-platform transactions.\n    *   Indications of refund/return fraud or abuse of policy (at Whatnot's discretion).\n\n5.  **High Value Loss Reimbursement:**\n    *   A separate policy is noted for missing high-value Sports Cards or Trading Cards obtained in \"breaks,\" allowing for reimbursement based on market value as assessed by Whatnot.\n\n6.  **EU/UK Right of Withdrawal:**\n    *   Acknowledges the statutory 14-day right for EU/UK consumers to cancel purchases from professional sellers without reason, provided they return the item within 14 days of cancellation.\n    *   **Conditions Apply:** Buyer pays return shipping, must have taken possession of the item, and specific product types (e.g., breaks, surprise products, unsealed health/hygiene, customized, perishable goods) are excluded. Refund amount may be reduced for diminished value.\n\n**Implications for Product Managers:**\n\nThis policy provides clear, structured guidelines for buyer protection, with defined timelines and exclusions. It emphasizes in-app support for issues and sets specific conditions for returns and refunds across various product categories, including provisions for high-value items and regional consumer rights. Key areas to note are the stricter timelines for certain categories and the explicit list of refund exclusions, which aim to reduce policy abuse.",
    "last_updated": "2025-07-21T18:41:39.890788Z"
  },
  "whatnot-enforcement-actions": {
    "policy_name": "Whatnot Enforcement Actions",
    "initial_summary": "## Whatnot's Trust & Safety Policy: Summary for Product Managers\n\nWhatnot's policy enforces Community Guidelines with penalties escalating based on violation severity and account history.  Violations are cumulative, meaning repeated offenses, even minor ones, can lead to a permanent ban.\n\n**Key Actions & Penalties:**\n\n* **Warnings:** For minor infractions, with guidance provided.\n* **Suspensions:** Temporary account access loss (2 or 7 days).\n* **Selling Access Revoked:**  Loss of ability to sell or go live.\n* **Ban:** Permanent account termination for serious or repeated violations.\n* **Discovery Restriction:** Temporary reduced visibility in feeds/recommendations.\n* **Other Penalties:** Loss of access to features like Direct Messages.\n\n**Account Health & Performance:**\n\n* An Account Health dashboard tracks Seller Performance Rates (fulfillment, shipping) and Policy Standing.\n* Poor performance in either area can result in warnings and penalties.\n* Policy Standing has five levels (Excellent, Good, Fair, Poor, Very Poor), reflecting penalty history.\n\n**Violation Expiration:**\n\n* Most violations expire after 180 days, except for bans and offboarding, which are permanent.\n\n**Appeals:**  Users can appeal penalties via email.\n",
    "last_update_summary": "As a Trust & Safety analyst, I've reviewed the provided diff.\n\n**Summary for Product Manager:**\n\nThis diff represents the **introduction of a new comprehensive policy page titled \"What Actions We Take\"** (dated June 10, 2025), which outlines Whatnot's enforcement framework for Community Guidelines violations.\n\n**Key Points:**\n\n*   **Enforcement Philosophy:** Actions are proportional to the violation, considering a user's existing Trust & Safety record. Violations are cumulative, leading to stronger penalties over time, even for less severe infractions.\n*   **Types of Penalties:** The policy clearly defines a range of enforcement actions:\n    *   **Warning:** Notification and policy guidance.\n    *   **Suspension:** Temporary loss of access (2 or 7 days).\n    *   **Revoke Selling Access:** For sellers, loss of ability to sell/go live.\n    *   **Ban:** Permanent account termination for repeated or serious violations.\n    *   **Discovery Restricted:** Temporary reduction in visibility in feeds/recommendations.\n    *   **Other Penalties:** Loss of specific features (e.g., Direct Messages).\n    *   **Ongoing Investigation Suspensions:** Temporary access suspension during reviews.\n*   **Violation Expiry:** Most violations expire after 180 days, but bans and offboarding are permanent.\n*   **Appeals Process:** Users can appeal by responding directly to the enforcement email.\n*   **Account Health Dashboard (Beta):**\n    *   **Seller Performance Rates:** Mentions monitoring Fulfillment Success Rate and On Time Shipment Rate, with warnings and penalties for consistent underperformance.\n    *   **Policy Standing:** Introduces five states (`Excellent`, `Good`, `Fair`, `Poor`, `Very Poor`) directly correlating to cumulative warnings and suspension levels, providing transparency on account status.\n\n**Impact:** This new policy page aims to increase transparency around Whatnot's enforcement practices, provide clear expectations for users, and detail the mechanisms for sellers to monitor their compliance via the Account Health dashboard.",
    "last_updated": "2025-07-21T18:41:45.534519Z"
  },
  "whatnot-hate-and-harassment": {
    "policy_name": "Whatnot Hate And Harassment",
    "initial_summary": "## Whatnot Hate and Harassment Policy Summary\n\nThis policy prohibits hateful conduct and harassment on the Whatnot platform, including sexual harassment and off-platform abuse that impacts the Whatnot community.  Key prohibited behaviors include:\n\n* **Harassment:**  Repeated unwanted contact, personal attacks, targeted obscene language,  using contact information for non-transactional purposes, and disparaging others (sellers disparaging buyers in streams, for example).  Exceptions may be made for newsworthy events or public figures.\n\n* **Threats & Harmful Wishes:** Wishing harm, making threats (implied or explicit), and exposing someone's sexual orientation or gender identity without consent.\n\n* **Sexual Harassment:** Unwanted sexual advances, objectification, degrading comments about sexual practices, sharing intimate images without consent.\n\n* **Hateful Conduct:** Any behavior promoting violence or hatred based on protected characteristics (race, ethnicity, religion, gender, sexual orientation, etc.). This includes using slurs (unless used self-referentially and with clearly indicated positive intent), supporting hate groups, and displaying hateful symbols (with exceptions for historical context, like pre-1933 artifacts). Specific allowances are made for the Confederate battle flag under very specific historical and non-hateful contexts.\n\n* **Off-Platform Abuse:**  Whatnot may take action against users coordinating harassment or hate off-platform that impacts the Whatnot community, even in rare instances where the off-platform behavior poses a significant threat to the platform.\n\nEnforcement actions against accounts may include removal.  The severity and persistence of the behavior are considered when evaluating violations.\n",
    "last_update_summary": "As a Trust & Safety analyst, I've reviewed the provided policy text.\n\n## New Hate and Harassment Policy - Key Points\n\nThis document outlines Whatnot's new comprehensive policy on Hate and Harassment, effective August 21, 2024, designed to foster a safe and respectful environment. It clearly defines and prohibits a broad range of harmful behaviors, including sexual harassment, and specifies conditions for enforcement.\n\n**Key Policy Elements:**\n\n1.  **Harassment:** Prohibits content or patterns of behavior that demean or threaten individuals.\n    *   **Examples:** Unwanted contact (e.g., targeting accounts, repeated insults, continued contact after being asked to stop, misuse of contact info), personal attacks (e.g., based on appearance, intellect, or seller disparagement in streams), and threats (e.g., wishing harm, implied threats, non-consensual disclosure of sexual orientation/gender identity, glorifying traumatic events).\n    *   **Note:** Exceptions exist for discussing newsworthy events or public figures.\n\n2.  **Sexual Harassment:** Specifically prohibits unwanted sexual advances, sexual objectification, or degrading attacks related to sexual practices.\n    *   **Examples:** Unwanted romantic approaches, comments about body parts, encouraging adult content sites, requesting sexually suggestive poses, disparagement based on perceived sexual practices/morality, non-consensual sharing or threats of intimate images/audio, and blackmail for intimate images.\n\n3.  **Hateful Conduct:** Prohibits any behavior promoting violence or hatred based on protected characteristics (race, ethnicity, religion, gender, sexual orientation, disability, etc.).\n    *   **Examples:** Expressions of intolerance/hatred, dehumanizing or demeaning protected groups, racial mimicry for mockery, encouraging violence, mocking hate crimes, racial slurs (with nuance for self-referential use), support for hate groups, harmful stereotypes, and hateful symbols/images (e.g., Nazi propaganda, specific derogatory Black Americana depictions, blackface).\n    *   **Confederate Battle Flag:** Permitted *only* in specific historical, non-hateful contexts (e.g., historical miniatures, art denouncing it, or Civil War-themed book/game covers without hateful celebration).\n\n4.  **Off-platform Abuse:** The policy extends to verifiable off-platform coordination of harassment or hate that impacts the Whatnot platform (e.g., directing followers to harass on Whatnot). In rare, severe, and persistent cases, action may also be taken for hate or harassment occurring entirely off-platform if it poses a significant threat to the Whatnot community or individuals.\n\n**Enforcement:** Violations may result in actions against the account, including removal.",
    "last_updated": "2025-07-21T18:41:54.487891Z"
  },
  "whatnot-how-to-report": {
    "policy_name": "Whatnot How To Report",
    "initial_summary": "## Whatnot User Reporting and Investigation Policy Summary\n\n**Key Points:**\n\n* **Reporting Methods:** Users can report suspicious behavior via in-app reporting features during livestreams, in direct messages (DMs), on product listings, or user profiles (Android & Web).  Email reports to trustandsafety@whatnot.com are also accepted.  All reports are anonymous.\n* **Reporting Locations:** Reporting options are available within livestreams (for buyers and sellers), in-live chat, DMs, product listings, and user profiles (Android/Web).\n* **Investigation Process:** Whatnot's Trust & Safety team investigates reports, analyzing data, reviewing livestreams, and potentially temporarily suspending users during investigations. Outcomes are not publicly disclosed.\n* **Proactive Monitoring:**  The Trust & Safety team proactively investigates potential policy violations based on data analysis and community reports, taking action against users exhibiting patterns of abuse.\n\n",
    "last_update_summary": "## Competitor Policy Analysis: Whatnot's New 'How to Report' Page (Dated July 21, 2025)\n\nThis `diff` indicates the creation of a brand new policy page on Whatnot's Help Center titled \"How To Report A User & How We Investigate,\" dated for publication on July 21, 2025.\n\n### Key Changes/New Information:\n\n1.  **Comprehensive Reporting Channels:** The policy outlines multiple ways users can report misconduct, specifying the UI/UX flows:\n    *   **During a Livestream:** Directly via a user's username (seller or viewer) in the top left or in live chat, with prompts for details.\n    *   **In Direct Messages (DMs):** Via the \"...\" (More Options) button in the conversation.\n    *   **On a Product Listing:** By clicking the seller's 'Shop' icon > product listing > 'Report Listing', or from a pinned item > 'Report Listing'.\n    *   **On User's Profile:** Via the \"...\" (More Options) button (Android and Web only).\n    *   **Email Fallback:** Users can always email `trustandsafety@whatnot.com` with details.\n2.  **Anonymity Guaranteed:** All reports are explicitly stated to remain anonymous.\n3.  **Detailed Investigation Process:** The policy details how Whatnot's Trust & Safety team investigates reports:\n    *   Reviewing facts, relevant history, data, and livestreams.\n    *   Potential for **temporary suspension** of reported user's access to features (including going live) during an investigation.\n    *   Confidentiality: Outcomes of individual investigations are not disclosed for privacy reasons.\n4.  **Proactive Enforcement:** Beyond reactive reports, the T&S team also initiates investigations proactively based on data analysis and community reports, actively monitoring for patterns and habitual abuse to take action.\n\n**Summary for PM:** Whatnot is formalizing and publicizing its user reporting and investigation process with a new, detailed policy page. This page highlights various in-product reporting touchpoints (livestream, DMs, listings, profiles) and explicitly outlines their T&S team's reactive investigation steps (data review, livestream analysis, temporary suspensions) and proactive monitoring efforts. A key point is the explicit guarantee of reporter anonymity.",
    "last_updated": "2025-07-21T18:42:03.654056Z"
  },
  "whatnot-moderator-guidelines": {
    "policy_name": "Whatnot Moderator Guidelines",
    "initial_summary": "## Whatnot Moderator Guidelines Summary\n\n**Key Points:**\n\n* **Goal:** Maintain a safe and fun marketplace by empowering moderators to manage livestream chats effectively.  Moderation should be fair and unbiased, prioritizing community safety and a positive user experience.\n\n* **Moderator Responsibilities:**\n    * Remove users only for violations of Community Guidelines or at the seller's request.  Avoid banning users for differing opinions.\n    * Maintain a respectful and engaging chat environment.\n    * Address inappropriate messages promptly, escalating to warnings before bans.\n    * Seek seller feedback.\n\n* **Moderator Privileges:**\n    * Remove users from a specific livestream (not a platform-wide ban).\n    * View muted chat messages.\n\n* **Adding/Removing Moderators:** Sellers can add moderators during or before a livestream via the scheduling section or by selecting the \"Allow to Moderate\" option from a user's chat profile.  Removal is done similarly using the \"Remove Moderator\" option.\n\n* **Underlying Principle:**  Moderation should be proactive and fair, guided by Whatnot's Community Guidelines and a principle of leading by example, not force.\n",
    "last_update_summary": "Here's a concise summary of the Whatnot Moderator Guidelines for a Product Manager:\n\n---\n\n### **Summary: Whatnot Moderator Guidelines (New Policy Page)**\n\nThis diff indicates the **introduction of a new policy page** detailing guidelines for livestream moderators on Whatnot, effective as of June 6, 2025.\n\n**Key Changes/New Information:**\n\n*   **Formalization of Moderator Expectations:** The policy sets clear standards, emphasizing a \"lead by example, not by force\" approach.\n*   **Preventing Abuse of Power:** Explicitly states moderators should not ban users for personal disagreements or opinions, but only for actions that warrant removal or if requested by the seller.\n*   **Core Responsibilities:**\n    *   Ensure chat adheres to seller's behavior and content standards.\n    *   Take action against offending users and spam.\n    *   Maintain an unbiased stance.\n*   **Defined Privileges:**\n    *   **\"Remove Users From Show\"**: This is a show-specific removal, *not* a platform-wide ban, and does not prevent the user from joining future streams from the same seller. This is a critical distinction.\n    *   **\"View Muted Chat Messages\"**: Moderators can see messages muted by the system or the seller's custom muted word list.\n*   **Moderator Management:** Clear instructions are provided for sellers on how to add and remove moderators, both when scheduling a show and during a live stream.\n*   **Best Practices:** Guidelines include treating users with respect, keeping chat engaged, answering questions, avoiding spam, deleting inappropriate messages, being firm with rude users, and issuing verbal warnings before any bans.\n\n**Impact for Product:** This new policy provides a structured framework for moderator behavior and tools, potentially increasing consistency in moderation and user safety. The specific limitation of the \"Remove Users From Show\" privilege (not a platform ban) is important for user experience and moderation enforcement understanding.",
    "last_updated": "2025-07-21T18:42:10.349517Z"
  },
  "youtube-community-guidelines": {
    "policy_name": "Youtube Community Guidelines",
    "initial_summary": "## YouTube's Trust & Safety Policy Summary:\n\nThis document outlines YouTube's approach to content moderation, creator support, and combating abuse.  Key points include:\n\n* **Content Moderation:**  YouTube uses automated systems and human reporting to identify and remove content violating Community Guidelines and Advertiser-Friendly Content Guidelines. Exceptions are made for content with clear educational, documentary, scientific, or artistic value (EDSA).\n\n* **Creator Support:**  The YouTube Partner Program (YPP) offers revenue sharing to eligible creators who meet stricter content standards.  Creators have tools to manage comments and their channel's community interactions.  YouTube provides resources to support creator privacy and safety.\n\n* **Combating Abuse:** YouTube actively works to remove content promoting violent extremism or criminal organizations, collaborating with government entities and organizations like the GIFCT.\n\n* **Appeals Process:** Creators can appeal decisions regarding content removal or YPP suspension.\n\n\n",
    "last_update_summary": "**New Policy Page: YouTube Community Guidelines Overview (2025-07-21)**\n\nThis diff indicates the **creation of an entirely new, comprehensive, public-facing policy page** titled \"Our Policies\" for YouTube. This document consolidates and clarifies key aspects of YouTube's content moderation framework and its relationship with creators and industry partners.\n\n**Key Takeaways for a Product Manager:**\n\n*   **Centralized Policy Communication:** This page now serves as a single source detailing YouTube's approach to content policy, aiming to enhance transparency and user understanding.\n*   **Detailed Enforcement Mechanisms:** It explains how Community Guidelines (CG) and Advertiser-Friendly Content (AFC) Guidelines are applied, emphasizing a mix of automated detection and human reporting, the appeals process, and exceptions for Educational, Documentary, Scientific, or Artistic (EDSA) content.\n*   **Creator Ecosystem & Incentives:** It highlights the YouTube Partner Program (YPP) as a mechanism to incentivize policy adherence through revenue sharing, detailing monetization policies and the tools provided to creators for channel management and community moderation.\n*   **Strategic Partnerships:** The page explicitly states YouTube's collaboration with industry experts, notably as a founding member of the Global Internet Forum to Counter Terrorism (GIFCT), to combat abusive content.\n*   **Messaging on Balance:** The policy clearly articulates YouTube's mission to balance free expression with platform responsibility, acknowledging the potential for mistakes and the importance of the appeals process.",
    "last_updated": "2025-07-21T18:42:18.624048Z"
  },
  "youtube-harassment-policy": {
    "policy_name": "Youtube Harassment Policy",
    "initial_summary": "## YouTube Harassment & Cyberbullying Policy Summary\n\nThis policy prioritizes the safety of creators, viewers, and partners.  Key prohibitions include:\n\n* **Harassment:** Prolonged insults or slurs targeting individuals based on protected group status, physical attributes, or victimhood (sexual assault, abuse, etc.).  A stricter approach is taken for content targeting minors.\n* **Doxxing & PII Sharing:** Sharing or threatening to share non-public personally identifiable information (PII),  except for widely available public information or clearly marked fake PII used for educational purposes.\n* **Abusive Behavior:** Encouraging brigading or other forms of coordinated abuse. Promoting harmful conspiracy theories linked to threats or violence.\n* **Threats & Violence:**  Threats against individuals or their property (including implicit threats), depictions of staged meet-ups to falsely accuse individuals, vigilante violence, or content glorifying or mocking death/injury.  This also includes realistic simulations of violence or death.\n* **Stalking & Sexualization:** Stalking, unwanted sexualization, sharing non-consensual intimate imagery, or fantasizing about/threatening sexual assault.\n\n**Exceptions:**  Content may be allowed if the primary purpose is educational, documentary, scientific, or artistic (e.g., debates, scripted performances, harassment awareness content). However, these exceptions do not excuse malicious harassment, especially based on protected group status.\n\n**Enforcement:** Violations result in content removal and email notification.  First-time offenders receive a warning with a policy training option.  Multiple violations or severe abuse can lead to strikes, channel suspension, or termination.  Repeat offenders may be prevented from accessing future policy trainings.  The policy applies to videos, comments, livestreams, and external links.\n",
    "last_update_summary": "As a Trust & Safety analyst, here's a summary of the new YouTube Harassment & Cyberbullying Policy for a Product Manager:\n\n---\n\n### YouTube Harassment & Cyberbullying Policy (2025-07-21) - Key Summary for Product Manager\n\nThis policy introduces a comprehensive framework for addressing harassment and cyberbullying on YouTube, with a strong emphasis on protecting vulnerable individuals and maintaining community safety.\n\n**Key Policy Highlights:**\n\n*   **Broadened Scope of Prohibited Harassment:**\n    *   **Intrinsic Attributes & Protected Groups:** Explicitly prohibits prolonged insults or slurs based on physical traits or protected group status (e.g., race, gender, sexual orientation, disability).\n    *   **Minors:** Stricter approach on content intended to shame, deceive, or insult minors (under 18).\n    *   **Doxxing & PII:** Prohibits sharing, threatening to share, or encouraging others to share non-public personally identifiable information (PII), including own PII and accidental sharing, with clear exceptions for widely available public information.\n    *   **Brigading & Coordinated Abuse:** Prohibits content that encourages coordinated abuse of identifiable individuals, on or off platform.\n    *   **Harmful Conspiracy Theories:** Bans content that promotes or targets individuals based on harmful conspiracy theories linked to direct threats or violence.\n    *   **New Threat & Violence Categories:** Includes explicit bans on implicit threats, staged meet-ups to accuse minors (without law enforcement), vigilante depictions, mocking death/injury, realistic simulations of deceased individuals' deaths, and creators simulating serious violence against others.\n    *   **Victim Minimization:** Prohibits denying or minimizing someone\u2019s role as a victim of a well-documented, major violent event.\n    *   **Unwanted Sexualization:** Expands on this to include lewd/degrading descriptions, non-consensual intimate imagery (NCII) distribution/requests, and support for sexual assault.\n\n*   **Policy Applicability:** Applies across all YouTube products and features, including videos, descriptions, comments, live streams, and crucially, **external links**.\n\n*   **Defined Exceptions (EDSA):** Allows for harassment-related content if its primary purpose is Educational, Documentary, Scientific, or Artistic. Specific examples include:\n    *   Debates/discussions about high-profile officials/leaders.\n    *   Scripted artistic performances (satire, stand-up, diss tracks), with a caveat that \"joking\" is not a blanket pass.\n    *   Harassment education/awareness content with willing participants.\n    *   *Note:* A harder line is taken on content maliciously insulting protected groups, even for high-profile individuals.\n\n*   **Enhanced Monetization & Channel Penalties:**\n    *   Beyond standard Community Guideline strikes, additional penalties (content removal, channel termination) may be applied for creators who:\n        *   Repeatedly encourage abusive audience behavior.\n        *   Repeatedly target/insult individuals based on intrinsic attributes across multiple uploads.\n        *   Expose individuals to physical harm based on local context.\n        *   Harm the community by persistently inciting hostility between creators for financial gain.\n\n*   **Clear Enforcement Process:**\n    *   Content removal with email notification.\n    *   First violation typically results in a warning, with an option to take a policy training to expire the warning after 90 days.\n    *   Standard strike system applies (3 strikes in 90 days = channel termination).\n    *   Channel/account termination for severe single abuse cases or channels dedicated to violations.\n    *   Repeat offenders may be prevented from taking policy trainings.\n\n**Implications for Product:**\n\nProduct teams should be aware of the expanded scope of prohibited content, especially around protection of minors, PII, and the nuanced handling of threats and simulated violence. The explicit EDSA exceptions provide specific guidelines for content moderation. The new monetization penalties for creators who foster abuse highlight the need for robust creator behavior monitoring and potential product features to disincentivize such behavior. The detailed enforcement flow, including policy training, requires clear communication and a smooth user experience.\n\n---",
    "last_updated": "2025-07-21T18:42:28.432717Z"
  },
  "youtube-shopping-ads-policy": {
    "policy_name": "Youtube Shopping Ads Policy",
    "initial_summary": "## Google Shopping Ads Policies: Summary for Product Managers\n\nThis document outlines Google's policies for Shopping ads, aiming for a trustworthy and transparent advertising ecosystem.  Key areas covered are:\n\n**1. Prohibited Content:**  This includes counterfeit goods, dangerous products (drugs, weapons, explosives), products enabling dishonest behavior (hacking tools, fake documents), and inappropriate content (hate speech, violence, cruelty).  Certain content lacks optimal support and is therefore unsupported in Shopping ads, though this doesn't affect other Google platforms.\n\n**2. Prohibited Practices:** This section addresses abuse of the ad network (malicious content, unfair advantages, bypassing reviews), irresponsible data collection and use (insecure data handling), and misrepresentation (misleading promotions, inaccurate product portrayal).\n\n**3. Restricted Content:**  This category covers legally or culturally sensitive content allowed with limitations and potential additional requirements. Examples include adult-oriented content, alcoholic beverages, copyrighted material, gambling, healthcare products, political content, and High Fat Sugar Salt (HFSS) food & beverages (prohibited from targeting minors).\n\n**4. Editorial & Technical Requirements:**  Ads must meet high professional and editorial standards, be clear, and lead to relevant, user-friendly landing pages. Technical requirements ensure ad functionality across various formats.\n\n**Enforcement:** Google uses AI and human review to enforce policies, taking actions ranging from disapproving ads to suspending accounts for violations.  Advertisers can appeal decisions.  Compliance with all applicable laws and regulations is mandatory.\n",
    "last_update_summary": "As a Trust & Safety analyst, here's a summary of the provided policy update for a Product Manager:\n\n**New Shopping Ads Policy Page Introduced**\n\nThis diff indicates the complete introduction of a new, comprehensive policy page for \"Shopping ads policies\" on Google Merchant Center. Previously, there was no dedicated policy page for YouTube Shopping ads, as inferred from the file path.\n\n**Key Changes/New Content:**\n\n*   **Dedicated Policy Hub:** A new \"Shopping ads Policy Center\" is established, consolidating guidelines for Shopping ads and local inventory ads.\n*   **Four Core Policy Areas:** The policy clearly defines and categorizes guidelines into:\n    1.  **Prohibited Content:** Content never allowed (e.g., counterfeit goods, dangerous products, dishonest behavior enablers, inappropriate content, unsupported types).\n    2.  **Prohibited Practices:** Actions not allowed by advertisers (e.g., ad network abuse, irresponsible data collection/use, misrepresentation).\n    3.  **Restricted Content:** Content allowed with limitations (e.g., adult, alcohol, copyrighted, gambling, healthcare, political, trademarks, and **newly mentioned HFSS Food & Beverage**). These may have geo-restrictions or require pre-authorization.\n    4.  **Editorial and Technical:** Quality standards for ads and websites.\n*   **Enforcement Mechanisms:** Explicitly states the use of a combination of Google AI and human evaluation for policy compliance.\n*   **Enforcement Actions:** Details actions taken for violations, including ad disapproval, temporary impression capping, and account suspension for egregious/repeat violations.\n*   **Appeal Process:** Provides clear instructions and links for advertisers to fix disapproved ads or appeal account suspensions.\n*   **Temporary Russia Ad Pause:** Includes an immediate operational note about pausing ads globally for Russian-based advertisers and pausing ads serving to users in Russia due to the Ukraine war.\n\nThis new policy page significantly formalizes and centralizes the guidelines for advertisers on Google's Shopping ad platforms, providing a clearer framework for what is and isn't permitted.",
    "last_updated": "2025-07-21T18:42:37.796159Z"
  },
  "instagram-community-guidelines": {
    "policy_name": "Instagram Community Guidelines",
    "initial_summary": "# Competitor Policy Summary:\n\nThis document outlines Meta's Community Standards, encompassing policies for Facebook, Instagram, Messenger, and Threads.  Key areas covered include:\n\n* **Content Moderation:**  Policies define acceptable and unacceptable content, addressing issues like hate speech, violence, harassment, misinformation, and illegal activities.  A three-part enforcement approach (remove, reduce, inform) is used.  Newsworthiness and public interest are considered when evaluating potentially violating content.\n\n* **Account Integrity:** Policies cover authentic identity, inauthentic behavior, and account security.\n\n* **Safety & Well-being:**  Emphasis is placed on user safety, privacy, and dignity.  Specific attention is given to protecting minors, addressing issues like child exploitation and suicide/self-harm.\n\n* **Transparency & Enforcement:**  The document details how Meta detects and addresses policy violations, including technological solutions and human review.  Transparency reports on enforcement, intellectual property, government data requests, and content restrictions are publicly available.\n\n* **Governance & Appeals:**  Information is provided about Meta's Oversight Board, its role in policy appeals, and its impact.\n\n* **Research & Data:** Access to research tools and datasets related to content and advertising is highlighted.\n\n\nThe policy aims to balance freedom of expression with the need to maintain a safe and respectful online environment.  The US English version is considered the primary and most up-to-date document.\n",
    "last_update_summary": "Here's a concise summary of the competitor's updated policy page for a Product Manager:\n\n### Instagram Community Guidelines Update Summary (Competitor Analysis)\n\nThis document represents a **new, comprehensive version** of Instagram's (Meta's) Community Guidelines, highlighting an increased focus on transparency and broadened policy scope.\n\n**Key Changes/Additions:**\n\n1.  **Expanded Platform Scope:** Policies explicitly apply across **Facebook, Instagram, Messenger, and Threads**, indicating a unified approach to content governance across Meta's core platforms.\n2.  **Explicit AI-Generated Content Inclusion:** The guidelines now explicitly state they apply to **\"all types of content, including AI-generated content,\"** addressing emerging content challenges.\n3.  **Enhanced Transparency Center:** A detailed \"Transparency Center\" framework is introduced, organizing information into distinct sections: Policies, Enforcement, Security, Features, Governance, Research Tools, and Reports. This suggests a more structured and public-facing approach to T&S operations.\n4.  **Defined Core Values:** Four foundational values guiding content moderation are clearly articulated: **Authenticity, Safety, Privacy, and Dignity**. These provide clear principles behind enforcement decisions.\n5.  **Policy Interpretation Guidance:** It specifies that the **US English version is the primary document** for interpretation and outlines the structure of individual policies (Policy Rationale, prohibited content, and content allowed with warnings/age restrictions).",
    "last_updated": "2025-07-21T18:41:02.086183Z"
  },
  "instagram-appeal-process": {
    "policy_name": "Instagram Appeal Process",
    "initial_summary": "Here's a concise summary of Instagram's Oversight Board appeal policy for a Product Manager:\n\n### Instagram Oversight Board Appeal Policy Summary\n\n**Key Points:**\n\n*   **Purpose:** Allows users to appeal Instagram's content decisions (both on their own content or content they reported) to an independent Oversight Board (OB).\n*   **Prerequisite:** Users **must** first exhaust Instagram's internal review process, including two internal reviews of the decision, before becoming eligible to appeal to the OB.\n*   **Appeal Types:**\n    *   Decisions to take down a user's content.\n    *   Decisions not to remove content a user reported.\n*   **Eligibility & Selection:** Not all content decisions are eligible for OB appeal. The OB itself selects only a limited number of eligible appeals for review and may not choose a specific case.\n*   **Timeline:** Appeals to the OB must be submitted within **15 days** of Instagram's final decision.\n*   **Status Check:** Users can track their appeal status on the Oversight Board's website using a reference number.",
    "last_update_summary": "Here's a concise summary for a Product Manager based on the provided diff:\n\n## Instagram Oversight Board Appeal Policy (New)\n\n**Summary of Key Changes (New Policy Page)**\n\nThis new policy page outlines the process for users to appeal Instagram's content decisions directly to the Oversight Board.\n\n**Key Points:**\n\n*   **Expanded Scope:** Users can now appeal two types of content decisions to the Oversight Board:\n    1.  Decisions about **their own content** that was taken down.\n    2.  Decisions about **content they reported from others** that was *not* taken down.\n*   **Mandatory Internal Review:** Before appealing to the Oversight Board, users must first exhaust Instagram's internal \"request a review\" process. The page indicates this might involve two internal reviews.\n*   **Eligibility & Selection:** Not all content or decisions are eligible for an Oversight Board appeal, and the Board only selects a certain number of eligible appeals for review.\n*   **Timeline:** Users have 15 days from Instagram's final decision to submit an appeal to the Oversight Board.\n*   **Status Tracking:** Users can check their appeal status on the Oversight Board's website using a reference number.\n\nThis page introduces a formalized, user-facing process for escalating content moderation disagreements beyond Instagram's internal review system to the independent Oversight Board.",
    "last_updated": "2025-07-21T18:40:46.212969Z"
  },
  "instagram-blocking-people": {
    "policy_name": "Instagram Blocking People",
    "initial_summary": "Here's a concise summary of the provided policy text for a Product Manager:\n\n### Instagram \"Blocking People\" Policy Summary\n\nThis policy details Instagram's \"Blocking People\" feature, a core safety and privacy control.\n\n**Key Points:**\n\n*   **Core Functionality:** Explains how users can block and unblock other accounts.\n*   **Impact of Blocking:**\n    *   Removes all past comments and likes from the blocked user.\n    *   Clarifies that a blocked user generally cannot see the blocker's content, message them, or mention them.\n    *   Provides guidance on how to view and manage a list of blocked accounts.\n*   **Related Privacy & Safety Controls:** The document also references other related user controls available in the \"Privacy, Security & Reporting\" section, including:\n    *   Making an account private.\n    *   Removing followers.\n    *   Restricting users (a softer form of control than blocking).\n    *   Temporarily limiting interactions from others.\n    *   Reporting messages or accounts.\n\nThis policy emphasizes user control over their interactions and visibility on the platform.",
    "last_update_summary": "As a Trust & Safety analyst, here's a summary for the product manager:\n\n---\n\n### New Policy Page: Instagram \"Blocking People\" (Effective 2025-07-21)\n\nThis diff indicates the **creation of a new Help Center page** dedicated to \"Blocking People\" on Instagram, effective July 21, 2025.\n\n**Key Information on the Page:**\n\nThe new page serves as a comprehensive resource for users to understand and manage interactions with others, covering topics such as:\n\n*   How to block/unblock users.\n*   The impact of blocking (e.g., on comments, likes, mentions).\n*   How to view blocked lists.\n*   Related privacy settings like making an account private.\n*   Distinctions and relationships with other safety features such as:\n    *   Removing followers.\n    *   Restricting users.\n    *   Temporarily limiting interactions.\n*   How to report messages or chats.\n\nThis page consolidates various user safety and privacy actions related to managing unwanted interactions.",
    "last_updated": "2025-07-21T18:40:49.445442Z"
  },
  "instagram-commerce-policies": {
    "policy_name": "Instagram Commerce Policies",
    "initial_summary": "### Competitor Policy Page Analysis: Unavailable Page\n\nThe provided text is an error message from Instagram's Help Center, indicating that a specific page is unavailable.\n\n**Key Points:**\n\n*   **Core Message:** \"This Page Isn't Available.\"\n*   **Reasons for Unavailability:** The page may be unavailable due to a broken link or because it has been removed.\n*   **User Guidance:** Users are advised to check if the link they are trying to open is correct.\n*   **Navigation Options:** The page provides clear calls to action to return to the Help Center Home or go back to the previous page.\n*   **T&S Relevance:** This page demonstrates how a competitor handles missing or removed content (potentially policy or help documentation), which impacts user experience and trust. It emphasizes the need for clear communication and alternative navigation when users encounter inaccessible information.",
    "last_update_summary": "**Trust & Safety Analyst Summary: Instagram Commerce Policies Page Update**\n\n**Date of Policy Snapshot:** 2025-07-21\n\n**Key Changes:**\n\n*   **Policy Page Status:** A new file for the `instagram-commerce-policies` page (dated 2025-07-21) has been created.\n*   **Content:** The content of this newly created file is an \"Error: This Page Isn't Available\" message.\n\n**Summary for Product Manager:**\n\nThe Instagram Commerce Policies page for the snapshot dated 2025-07-21 is currently inaccessible. Instead of policy content, the URL now serves an error page indicating that the link may be broken or the page removed. This suggests that this specific commerce policy document has either been temporarily taken offline, permanently removed, or is undergoing a re-organization by Instagram. Users attempting to access commerce policies via this URL will encounter an error.",
    "last_updated": "2025-07-21T18:40:54.805886Z"
  },
  "tiktok-blocking-users": {
    "policy_name": "Tiktok Blocking Users",
    "initial_summary": "Here's a concise summary of the competitor's policy page for a Product Manager:\n\n### Competitor Policy Page Summary\n\nThe competitor's policy documentation serves as a comprehensive help center, detailing an exceptionally broad range of platform functionalities, from core features to advanced creator tools and monetization.\n\n**Key Trust & Safety Takeaways:**\n\n*   **Robust User Control & Safety Tools:** A significant focus is placed on empowering users with safety mechanisms. Detailed instructions for blocking (individual users, multiple users from comments, unblocking) are prominently featured, alongside mentions of a \"Safety Center,\" \"Community Guidelines,\" and \"Report a problem\" functionality.\n*   **Comprehensive Feature & Content Coverage:** The policies span an extensive array of content types and features including user-generated videos, AI-generated content, creator tools, live streaming, e-commerce (\"TikTok Shop\"), messaging, and content discovery, indicating a complex ecosystem requiring broad T&S oversight.\n*   **Creator Monetization & Ecosystem:** Policies extend to creator monetization features (LIVE, Gifts, promotion tools), necessitating guidelines for commercial activities, fraud prevention, and responsible content creation related to earning.\n*   **Legal & Policy Framework:** The document points to a foundational set of legal and policy resources, including Terms of Use, Privacy, Copyright, and Law Enforcement guidelines, signifying a structured approach to compliance and trust.\n*   **Algorithmic Transparency & Global Reach:** It touches on content recommendation algorithms (\"How TikTok recommends content\") and highlights a vast global operational scope through an extensive list of supported languages, implying a need for culturally nuanced and legally compliant T&S policies worldwide.",
    "last_update_summary": "### Trust & Safety Analyst Summary: TikTok \"Blocking Users\" Policy Page\n\n**Date:** 2025-07-21\n\n**Key Change:** Introduction of a new, dedicated Help Center page on TikTok's support site titled \"Blocking someone.\"\n\n**Summary for Product Manager:**\n\nThis new policy page formalizes and clarifies the user experience around blocking functionality on TikTok. It provides clear, step-by-step instructions for users on:\n\n1.  **Individual Blocking:** How to block or unblock a single user directly from their profile.\n2.  **Bulk Blocking:** A new feature/clarification detailing how users can block multiple accounts simultaneously from the comments section of their own videos. This indicates a focus on empowering creators to manage their comment sections more efficiently.\n3.  **Impact of Blocking:** Clearly defines what happens when a user is blocked (cannot view posts, direct message, comment, follow, or like).\n\n**Implication for Product:** This new page suggests an emphasis on user safety and control, particularly regarding interactions and content consumption. The inclusion of \"bulk blocking\" indicates a potential product enhancement or increased visibility for a feature aimed at improving creator experience and moderation.",
    "last_updated": "2025-07-21T18:41:06.727502Z"
  },
  "youtube-hiding-users": {
    "policy_name": "Youtube Hiding Users",
    "initial_summary": "As a Trust & Safety analyst, here is a concise summary of the provided policy document on YouTube's \"Hide users from your channel\" feature for a Product Manager:\n\n---\n\n### YouTube: \"Hide Users from Your Channel\" Policy Summary\n\nThis policy outlines a channel moderation feature allowing content creators to control who can interact with their content.\n\n**Key Functionality:**\n\n*   **Purpose:** Channel owners can \"hide\" specific viewers to prevent their comments from appearing on the channel and to stop them from creating clips from videos or live streams.\n*   **Impact on Hidden User:**\n    *   All previous comments from the hidden user on the channel will be hidden within 48 hours.\n    *   Future comments from the hidden user will not appear.\n    *   The hidden user will **not** receive a notification that they have been hidden.\n*   **Methods to Hide:**\n    1.  **From a Comment:** Select \"More\" next to a user's comment, then \"Hide user from channel.\"\n    2.  **Via YouTube Studio:** In \"Settings\" > \"Community\" > \"Automated Filters,\" paste the user's channel URL into the \"Hidden users\" box.\n*   **Managing Hidden Users:**\n    *   A list of hidden users is available in YouTube Studio under \"Settings\" > \"Community\" > \"Automated Filters.\"\n    *   Users can be \"shown\" (unhidden) from this list, which allows their *future* comments to appear. Previous comments remain hidden.\n*   **Scope:** This is a **channel moderation tool** for managing audience interaction. It is distinct from reporting abuse, harassment, or policy violations, which should be directed to the Safety Center.\n\n---",
    "last_update_summary": "This is a new policy page for YouTube's \"Hide users from your channel\" feature.\n\n### Summary for Product Manager:\n\n**Key Changes (New Policy Page: \"Hide users from your channel\")**\n\nThis new policy page outlines the functionality and impact of hiding users on a YouTube channel.\n\n**Core Functionality:**\n*   **Hiding a user** prevents their comments from appearing on the channel (including YouTube Studio comments page) and blocks them from creating clips from videos or live streams.\n*   **Methods to Hide:** Users can be hidden directly from a comment on YouTube or by pasting their channel URL into the \"Hidden users\" section in YouTube Studio settings (Community tab).\n*   **Managing Hidden Users:** A list of hidden users is accessible and manageable within YouTube Studio's Community settings.\n*   **Unhiding Users:** Users can be unhidden from the same \"Hidden users\" list in YouTube Studio.\n\n**Impact & Behavior:**\n*   **Comment Visibility:** All *previous* comments from a hidden user will be hidden within 48 hours. When a user is unhidden, *future* comments will appear, but comments posted *before* they were unhidden will remain hidden.\n*   **Notifications:** Hidden users **do not** receive any notification that they have been hidden.",
    "last_updated": "2025-07-21T18:42:32.113355Z"
  }
}